#!/usr/bin/env bash
###############################################################################
#
#                                                
# 88b           d88  88                           
# 888b         d888  ""                           
# 88`8b       d8'88                               
# 88 `8b     d8' 88  88   ,adPPYba,   ,adPPYba,   
# 88  `8b   d8'  88  88  a8"     ""  a8P_____88   
# 88   `8b d8'   88  88  8b          8PP"""""""   
# 88    `888'    88  88  "8a,   ,aa  "8b,   ,aa   
# 88     `8'     88  88   `"Ybbd8"'   `"Ybbd8"'   
#                                                
#                                                
#                                                
# I8,        8        ,8I            88           
# `8b       d8b       d8'            88           
#  "8,     ,8"8,     ,8"             88           
#   Y8     8P Y8     8P   ,adPPYba,  88,dPPYba,   
#   `8b   d8' `8b   d8'  a8P_____88  88P'    "8a  
#    `8a a8'   `8a a8'   8PP"""""""  88       d8  
#     `8a8'     `8a8'    "8b,   ,aa  88b,   ,a8"  
#      `8'       `8'      `"Ybbd8"'  8Y"Ybbd8"'   
#                                                
#
# Depends on:
#  https://docs.ipfs.io/install/command-line/
#  https://www.gnu.org/software/wget/
#  https://curl.se/
#  https://github.com/stedolan/jq/
#  https://github.com/kislyuk/yq
#  https://github.com/mgdm/htmlq/
#  https://github.com/makeworld-the-better-one/gemget/
#  https://github.com/yt-dlp/yt-dlp/
#. https://www.ffmpeg.org/
#  https://gitlab.torproject.org/tpo/core/torsocks/
#  https://github.com/ImportTaste/wayback-machine-downloader/
#  https://git-scm.com/downloads/
#  https://www.gnu.org/software/bash/
#
# MiceWeb: https://github.com/Robotizing/MiceWeb
#
# Copyright (c) 2022 Robotizing Networks â€¢Â robotizing.net
###############################################################################

# Return value of a pipeline is the value of the last (rightmost) command to
# exit with a non-zero status, or zero if all commands in the pipeline exit
# successfully.
set -o pipefail

# Set $IFS to only newline and tab.
#
# http://www.dwheeler.com/essays/filenames-in-shell.html
IFS=$'\n\t'

###############################################################################
# Globals
###############################################################################

# $_ME
#
# This program's basename.
_ME="$(basename "${0}")"

# $_VERSION
#
# Manually set this to to current version of the program. Adhere to the
# semantic versioning specification: http://semver.org
_VERSION="0.3"	#WARNING: affects _upgrade()
_SUB_VERSION="${_VERSION}.2"

# MiceWeb Talks
_SITE_ADDRESS="1MiceWebdn35s6pUd3EM54uNveUJNSHsMr"

# $DEFAULT_SUBCOMMAND
#
# The subcommand to be run by default, when no subcommand name is specified.
# If the environment has an existing $DEFAULT_SUBCOMMAND set, then that value
# is used.
DEFAULT_SUBCOMMAND="${DEFAULT_SUBCOMMAND:-help}"

_REQUESTS_TOPIC="MiceWebRequests"	#TODO: handle MICEWEB_PUBSUB_TOPIC?

_IPFS_FEATURES=""
# [[ $(ipfs help add) == *"--to-files"* ]]

if [[ "$IPFS_PATH" == "" ]]; then
	_IPFS_REPO_PATH="$HOME/.ipfs"
else
	_IPFS_REPO_PATH="$IPFS_PATH"
fi

SAVE_MFS_ADDR=""
SUBDIR=""

###############################################################################
# Debug
###############################################################################

# _debug()
#
# Usage:
#   _debug <command> <options>...
#
# Description:
#   Execute a command and print to standard error. The command is expected to
#   print a message and should typically be either `echo`, `printf`, or `cat`.
#
# Example:
#   _debug printf "Debug info. Variable: %s\\n" "$0"
__DEBUG_COUNTER=0
_debug() {
  if ((${_USE_DEBUG:-0}))
  then
    __DEBUG_COUNTER=$((__DEBUG_COUNTER+1))
    {
      # Prefix debug message with "bug (U+1F41B)"
      printf "ðŸ›  %s " "${__DEBUG_COUNTER}"
      "${@}"
      printf "â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•â€•\\n"
    } 1>&2
  fi
}

###############################################################################
# Error Messages
###############################################################################

# _exit_1()
#
# Usage:
#   _exit_1 <command>
#
# Description:
#   Exit with status 1 after executing the specified command with output
#   redirected to standard error. The command is expected to print a message
#   and should typically be either `echo`, `printf`, or `cat`.
_exit_1() {
  {
    printf "%s " "$(tput setaf 1)!$(tput sgr0)"
    "${@}"
  } 1>&2
  exit 1
}

# _warn()
#
# Usage:
#   _warn <command>
#
# Description:
#   Print the specified command with output redirected to standard error.
#   The command is expected to print a message and should typically be either
#   `echo`, `printf`, or `cat`.
_warn() {
  {
    printf "%s " "$(tput setaf 1)!$(tput sgr0)"
    "${@}"
  } 1>&2
}

###############################################################################
# Utility Functions
###############################################################################

# _command_exists()
#
# Usage:
#   _command_exists <name>
#
# Exit / Error Status:
#   0 (success, true) If a command with <name> is defined in the current
#                     environment.
#   1 (error,  false) If not.
#
# Information on why `hash` is used here:
# http://stackoverflow.com/a/677212
_command_exists() {
  command hash "${1}" 2>/dev/null
}

# _contains()
#
# Usage:
#   _contains <query> <list-item>...
#
# Exit / Error Status:
#   0 (success, true)  If the item is included in the list.
#   1 (error,  false)  If not.
#
# Examples:
#   _contains "${_query}" "${_list[@]}"
_contains() {
  local _query="${1:-}"
  shift

  if [[ -z "${_query}"  ]] ||
     [[ -z "${*:-}"     ]]
  then
    return 1
  fi

  for __element in "${@}"
  do
    [[ "${__element}" == "${_query}" ]] && return 0
  done

  return 1
}

# _join()
#
# Usage:
#   _join <delimiter> <list-item>...
#
# Description:
#   Print a string containing all <list-item> arguments separated by
#   <delimeter>.
#
# Example:
#   _join "${_delimeter}" "${_list[@]}"
#
# More information:
#   https://stackoverflow.com/a/17841619
_join() {
  local _delimiter="${1}"
  shift
  printf "%s" "${1}"
  shift
  printf "%s" "${@/#/${_delimiter}}" | tr -d '[:space:]'
}

# _blank()
#
# Usage:
#   _blank <argument>
#
# Exit / Error Status:
#   0 (success, true)  If <argument> is not present or null.
#   1 (error,  false)  If <argument> is present and not null.
_blank() {
  [[ -z "${1:-}" ]]
}

# _interactive_input()
#
# Usage:
#   _interactive_input
#
# Exit / Error Status:
#   0 (success, true)  If the current input is interactive (eg, a shell).
#   1 (error,  false)  If the current input is stdin / piped input.
_interactive_input() {
  [[ -t 0 ]]
}

# _piped_input()
#
# Usage:
#   _piped_input
#
# Exit / Error Status:
#   0 (success, true)  If the current input is stdin / piped input.
#   1 (error,  false)  If the current input is interactive (eg, a shell).
_piped_input() {
  ! _interactive_input
}

###############################################################################
# describe
###############################################################################

# describe()
#
# Usage:
#   describe <name> <description>
#   describe --get <name>
#
# Options:
#   --get  Print the description for <name> if one has been set.
#
# Examples:
# ```
#   describe "list" <<HEREDOC
# Usage:
#   ${_ME} list
#
# Description:
#   List items.
# HEREDOC
#
# describe --get "list"
# ```
#
# Set or print a description for a specified subcommand or function <name>. The
# <description> text can be passed as the second argument or as standard input.
#
# To make the <description> text available to other functions, `describe()`
# assigns the text to a variable with the format `$___describe_<name>`.
#
# When the `--get` option is used, the description for <name> is printed, if
# one has been set.
#
# NOTE:
#
# The `read` form of assignment is used for a balance of ease of
# implementation and simplicity. There is an alternative assignment form
# that could be used here:
#
# var="$(cat <<'HEREDOC'
# some message
# HEREDOC
# )
#
# However, this form appears to require trailing space after backslases to
# preserve newlines, which is unexpected. Using `read` simply requires
# escaping backslashes, which is more common.
describe() {
  _debug printf "describe() \${*}: %s\\n" "$@"
  [[ -z "${1:-}" ]] && _exit_1 printf "describe(): <name> required.\\n"

  if [[ "${1}" == "--get" ]]
  then # get ------------------------------------------------------------------
    [[ -z "${2:-}" ]] &&
      _exit_1 printf "describe(): <description> required.\\n"

    local _name="${2:-}"
    local _describe_var="___describe_${_name}"

    if [[ -n "${!_describe_var:-}" ]]
    then
      printf "%s\\n" "${!_describe_var}"
    else
      printf "No additional information for \`%s\`\\n" "${_name}"
    fi
  else # set ------------------------------------------------------------------
    if [[ -n "${2:-}" ]]
    then # argument is present
      read -r -d '' "___describe_${1}" <<HEREDOC
${2}
HEREDOC
    else # no argument is present, so assume piped input
      # `read` exits with non-zero status when a delimeter is not found, so
      # avoid errors by ending statement with `|| true`.
      read -r -d '' "___describe_${1}" || true
    fi
  fi
}

###############################################################################
# Program Option Parsing
#
# NOTE: The `getops` builtin command only parses short options and BSD `getopt`
# does not support long arguments (GNU `getopt` does), so use custom option
# normalization and parsing.
#
# For a pure bash `getopt` function, try pure-getopt:
#   https://github.com/agriffis/pure-getopt
#
# More info:
#   http://wiki.bash-hackers.org/scripting/posparams
#   http://www.gnu.org/software/libc/manual/html_node/Argument-Syntax.html
#   http://stackoverflow.com/a/14203146
#   http://stackoverflow.com/a/7948533
#   https://stackoverflow.com/a/12026302
#   https://stackoverflow.com/a/402410
###############################################################################

# Normalize Options ###########################################################

# Source:
#   https://github.com/e36freak/templates/blob/master/options

# Iterate over options, breaking -ab into -a -b and --foo=bar into --foo bar
# also turns -- into --endopts to avoid issues with things like '-o-', the '-'
# should not indicate the end of options, but be an invalid option (or the
# argument to the option, such as wget -qO-)
unset options
# while the number of arguments is greater than 0
while ((${#}))
do
  case "${1}" in
    # if option is of type -ab
    -[!-]?*)
      # loop over each character starting with the second
      for ((i=1; i<${#1}; i++))
      do
        # extract 1 character from position 'i'
        c="${1:i:1}"
        # add current char to options
        options+=("-${c}")
      done
      ;;
    # if option is of type --foo=bar, split on first '='
    --?*=*)
      options+=("${1%%=*}" "${1#*=}")
      ;;
    # end of options, stop breaking them up
    --)
      options+=(--endopts)
      shift
      options+=("${@}")
      break
      ;;
    # otherwise, nothing special
    *)
      options+=("${1}")
      ;;
  esac

  shift
done
# set new positional parameters to altered options. Set default to blank.
set -- "${options[@]:-}"
unset options

# Parse Options ###############################################################

_SUBCOMMAND=""
_SUBCOMMAND_ARGUMENTS=()
_USE_DEBUG=0

while ((${#}))
do
  __opt="${1}"

  shift

  case "${__opt}" in
    -h|--help)
      _SUBCOMMAND="help"
      ;;
    --debug)
      _USE_DEBUG=1
      ;;
    *)
      # The first non-option argument is assumed to be the subcommand name.
      # All subsequent arguments are added to $_SUBCOMMAND_ARGUMENTS.
      if [[ -n "${_SUBCOMMAND}" ]]
      then
        _SUBCOMMAND_ARGUMENTS+=("${__opt}")
      else
        _SUBCOMMAND="${__opt}"
      fi
      ;;
  esac
done

###############################################################################
# Main
###############################################################################

# Declare the $_DEFINED_SUBCOMMANDS array.
_DEFINED_SUBCOMMANDS=()

# _main()
#
# Usage:
#   _main
#
# Description:
#   The primary function for starting the program.
#
#   NOTE: must be called at end of program after all subcommands are defined.
_main() {
  # If $_SUBCOMMAND is blank, then set to `$DEFAULT_SUBCOMMAND`
  if [[ -z "${_SUBCOMMAND}" ]]
  then
    _SUBCOMMAND="${DEFAULT_SUBCOMMAND}"
  fi

  for __name in $(declare -F)
  do
    # Each element has the format `declare -f function_name`, so set the name
    # to only the 'function_name' part of the string.
    local _function_name
    _function_name=$(printf "%s" "${__name}" | awk '{ print $3 }')

    if ! { [[ -z "${_function_name:-}"                      ]] ||
           [[ "${_function_name}" =~ ^_(.*)                 ]] ||
           [[ "${_function_name}" == "bats_readlinkf"       ]] ||
           [[ "${_function_name}" == "describe"             ]] ||
           [[ "${_function_name}" == "shell_session_update" ]]
    }
    then
      _DEFINED_SUBCOMMANDS+=("${_function_name}")
    fi
  done

  # If the subcommand is defined, run it, otherwise return an error.
  if _contains "${_SUBCOMMAND}" "${_DEFINED_SUBCOMMANDS[@]:-}"
  then
    # Pass all comment arguments to the program except for the first ($0).
    ${_SUBCOMMAND} "${_SUBCOMMAND_ARGUMENTS[@]:-}"
  else
	local SOMETHING="${_SUBCOMMAND}"
	local URL=""
	if [[ "$SOMETHING" =~ ^[0-9a-f]{40}$ ]]; then
		#TODO: implement import
		URL=$(url "$SOMETHING")
		if [ "$URL" == "" ]; then
			>&2 printf "\n"
			return 1
		fi
		_snapshots_and_save "$SOMETHING" | awk '!a[$0]++; fflush()' |
			while IFS= read -r I
			do
				_echo_existing_page_snapshot $I
			done
		>&2 printf "\n"
		return 0
	elif [[ "$SOMETHING" =~ ^[0-9a-f]{40}/[0-9]{8}GMT[0-9]{6}-. ]]; then
		local SNAP="$SOMETHING"
		if [[ "$SNAP" =~ ^[0-9a-f]{40}/[0-9]{8}GMT[0-9]{6}-archive$ ]]; then
			if save "$SNAP" >/dev/null; then
				_echo_existing_page_snapshot $SNAP
			fi
		elif [[ "$SNAP" =~ ^[0-9a-f]{40}/[0-9]{8}GMT[0-9]{6}-importing$ ]]; then
			_echo_existing_page_snapshot $SNAP
			>&2 echo "Resuming getting content from IPFS Network"
			check $SNAP 1>&2
		elif [[ "$SNAP" =~ ^[0-9a-f]{40}/[0-9]{8}GMT[0-9]{6}-import$ ]]; then
			if _safe_with_warnings ipfs files ls //MiceWeb/pages/$SNAP &>/dev/null; then
				_echo_existing_page_snapshot $SNAP
			elif _safe_with_warnings ipfs files ls "//MiceWeb/pages/$SNAP"ing >/dev/null; then
				_echo_existing_page_snapshot $SNAP
				>&2 echo "Resuming getting content from IPFS Network"
				check $SNAP 1>&2
			else
				>&2 printf "\n"
				return 1
			fi
		elif _safe_with_warnings ipfs files ls //MiceWeb/pages/$SNAP >/dev/null; then
			_echo_existing_page_snapshot $SNAP
		else
			>&2 printf "\n"
			return 1
		fi
		>&2 printf "\n"
		return 0
	elif [[ "$SOMETHING" =~ ^[13][a-km-zA-HJ-NP-Z1-9]{25,34}$ ]]; then
		_snapshots_and_save "$SOMETHING" |
			while IFS= read -r I
			do
				_echo_existing_zite_snapshot $I
			done
		>&2 printf "\n"
		return 0
	elif [[ "$SOMETHING" =~ ^[13][a-km-zA-HJ-NP-Z1-9]{25,34}/[0-9]{8}GMT[0-9]{6}-zite ]]; then
		local SNAP="$SOMETHING"
		if _safe_with_warnings ipfs files ls //MiceWeb/zites/$SNAP >/dev/null; then
			_echo_existing_zite_snapshot $SNAP
		fi
		>&2 printf "\n"
		return 0
	fi
	URL="$SOMETHING"
	if _check_url "$URL"; then
		_snapshots_and_save "$URL" | awk '!a[$0]++; fflush()' |
			while IFS= read -r I
			do
				_echo_existing_page_snapshot $I
			done
	else
		_exit_1 printf "Unknown command: %s\\n" "${_SUBCOMMAND}"
	fi
  fi
  if [[ "${_SUBCOMMAND_ARGUMENTS[0]}" != "--no-warnings" ]]; then
  	>&2 printf "\n"
  fi
}

# --------------------------------------------------------------------- functions

_addToHistory() {
	mkdir -p "$HOME/.miceweb"
	local DT=$(export TZ=GMT ; date '+%Y-%m-%d GMT %H:%M:%S')
	printf "%s\t%s\n" "$DT" "$1" >> "$HOME/.miceweb/history.txt"
}

_cat_file() {
	local FIL="$1"
	local GREP="$2"
	local ADDR=""
	if [[ "$FIL" == /ipns/* ]]; then
		ADDR=$(_resolve_ipns "${FIL#/ipns/}")
		_safe_with_warnings ipfs cat "$ADDR" | grep -a "$GREP"
	elif [[ "$FIL" == /ipfs/* ]]; then
		ADDR="${FIL#/ipfs/}"
		_safe_with_warnings ipfs cat "$ADDR" | grep -a "$GREP"
	elif [[ "$FIL" == /zeronet/* ]]; then
		ADDR=$(_resolve_zeronet "${FIL#/zeronet/}")
		if [[ $ADDR != "" ]]; then
			local datadir="$(_zeronet_data)"
			if [ -d "$datadir" ]; then
				local filename="$datadir/$ADDR"
				if [ -e "$filename" ]; then
					grep -a "$GREP" "$filename"
				else
					>&2 echo "Error: file not found, visit http://127.0.0.1:43110/$ADDR in a browser and try again"
					return 1
				fi
			else
				>&2 echo "Error: '$datadir' not found,"
				>&2 echo " check ZERONET_PATH environment variable"
				return 1
			fi
		else
			return 1
		fi
	else
		grep -a "$GREP" "$FIL"
	fi
	return $?
}

_cat_json_file() {
	if _command_exists jq; then
		_cat_file "$1" | jq --raw-output '.. | strings'
	else
		>&2 _print_with_hyperlink "Error: jq is not installed (seeing " "https://stedolan.github.io/jq/download/" ")"
		return 1
	fi
}

_cat_xml_file() {
	if _command_exists xq; then
		if _command_exists jq; then
			_cat_file "$1" | xq | jq --raw-output '.. | strings'
		else
			>&2 _print_with_hyperlink "Error: jq is not installed (seeing " "https://stedolan.github.io/jq/download/" ")"
			return 1
		fi
	else
		>&2 _print_with_hyperlink "Error: xq is not installed (seeing " "https://kislyuk.github.io/yq/#installation" ")"
		return 1
	fi
}

_check_free_space_for_temp() {
	if [ $(_free_space $(dirname $(mktemp -u 2>/dev/null || mktemp -u -t 'mytmpdir'))) -gt 102400 ]; then
		return 0
	else
		return 1
	fi
}

_check_url() {
	local URL="$1"
	if [[ "$URL" != http://* && "$URL" != https://* && "$URL" != gopher://* && "$URL" != gemini://* && "$URL" != ipns://* && "$URL" != ipfs://* && "$URL" != ftp://* && "$URL" != ftps://* && "$URL" != git://* ]]; then
		return 1
	else
		return 0
	fi
}

_current_timestamp() {
	export TZ=GMT ; date '+%Y%m%dGMT%H%M%S'
}

#_echo_saved_snapshot() {
#	local GATEWAY=$(_ipfs_gateway)
#	if [[ "$GATEWAY" != "" ]]; then
#		_print_hyperlink "$GATEWAY/ipfs/$1" "$SAVE_HASH/$SUBDIR"
#		echo ""
#	else
#		echo "$SAVE_HASH/$SUBDIR"
#	fi
#}

_echo_existing_page_snapshot() {
	local GATEWAY=$(_ipfs_gateway)
	local SNAP="$1"
	if [[ "$GATEWAY" != "" ]]; then
		local ADDR=$(present --no-warnings "$SNAP")
		if [[ "$ADDR" != "" ]]; then
			_print_hyperlink $GATEWAY"$ADDR" "$SNAP"
			echo ""
		else
			echo "$SNAP"
		fi
	else
		echo "$SNAP"
	fi
}

_echo_existing_zite_snapshot() {
	local GATEWAY=$(_ipfs_gateway)
	local SNAP="$1"
	if [[ "$GATEWAY" != "" ]]; then
		local CID="$(_safe_with_warnings ipfs files stat --hash //MiceWeb/zites/$SNAP 2>/dev/null)"
		_print_hyperlink "$GATEWAY/ipfs/$CID" "$SNAP"
		echo ""
	else
		echo "$SNAP"
	fi
}

_echo_supported_url_prefixes() {
	>&2 echo "Supported URL prefixes:"
	>&2 echo " http://, https://, gopher://, gemini://,"
	>&2 echo " ftp://, ftps://, ipns://, ipfs://, git://"
}

_free_space() {
	echo $(df -Pk $1 | sed 1d | grep -v used | awk '{ print $4 "\t" }')
}

_git() {
	# no checkout, no recursive, no LFS (https://stackoverflow.com/questions/42019529/how-to-clone-pull-a-git-repository-ignoring-lfs)
	# use snapshot with 'git push --mirror <path>' as described in https://blog.plataformatec.com.br/2013/05/how-to-properly-mirror-a-git-repository/
	local URL="$1"
	local MYTMPDIR=$(_temp_directory)
	cd $MYTMPDIR
	GIT_LFS_SKIP_SMUDGE=1 GIT_ASKPASS=false GIT_TERMINAL_PROMPT=0 git clone --quiet --m "$URL" . &>/dev/null
	local GITERR=$?
	local RET=1
	if [[ $GITERR -eq 0 ]]; then
		local CID="$(_safe_with_warnings ipfs add --quieter --pin=false -r --hidden $MYTMPDIR)"
		_safe_with_warnings ipfs files cp //ipfs/$CID /$SAVE_MFS_ADDR/$SUBDIR
		if [ $? -eq 0 ]; then
			echo "$SAVE_HASH/$SUBDIR"
			RET=$GITERR
		fi
	else
		>&2 echo "Error: could not download '${SUBDIR:18}', git clone err. $GITERR"
	fi
	cd ..
	rm -rf $MYTMPDIR
	return $RET
}

_grep_supported_urls() {
	grep -e "^http://" -e "^https://" -e "^gopher://" -e "^gemini://" -e "^ftp://" -e "^ftps://" -e "^ipfs://" -e "^ipns://" -e "^git://"
}

_has_url_fragment() {
	local URL="$1"
	if [[ "$URL" =~ ['#'] ]]; then
		return 0;
	else
		return 1;
	fi
}

_hash() {
	_hash_string "$(_url_but_fragment "$1")"
}

_hash_string() {
	local HASH=$(printf '%s' "$1" | sha1sum 2>/dev/null | cut -d' ' -f1)
	if [[ "$HASH" != "" ]]; then
		echo "$HASH"
	else
		HASH=$(printf '%s' "$1" | openssl sha1 -r 2>/dev/null | cut -d' ' -f1)
		if [[ "$HASH" != "" ]]; then
			echo "$HASH"
		else
			HASH=$(printf '%s' "$1" | shasum -a 1 2>/dev/null | cut -d' ' -f1)
			if [[ "$HASH" != "" ]]; then
				echo "$HASH"
			else
				_exit_1 printf "Installed sha1sum, shasum or openssl is required for MiceWeb\n"
			fi
		fi
	fi
}

_initiate_saving_url() {
	local URL="$1"
	SAVE_HASH=$(hash "$URL")
	if [[ "$SAVE_HASH" != "" ]]; then
		SAVE_MFS_ADDR="/MiceWeb/pages/$SAVE_HASH"
		return 0
	else
		return 1
	fi
}

# for data
_ipfs_add_directory_to_mfs() {
	local path="$1"
	local addr="$2"
	if [[ "$addr" != "" ]]; then
		local CID="$(_safe ipfs add --quieter --pin=false -r $path --to-files /$addr)"
		if [[ "$CID" != "" ]]; then
			if [[ "$CID" == "$(_safe ipfs files stat --hash /$addr)" ]]; then
				echo "$CID"
				return 0
			fi
		else
			CID="$(_safe ipfs add --quieter --pin=false -r $path)"
			if [[ "$CID" != "" ]]; then
				if _safe ipfs files cp //ipfs/$CID /$addr; then
					echo "$CID"
					return 0
				elif [[ "$CID" == "$(_safe ipfs files stat --hash /$addr)" ]]; then
					echo "$CID"
					return 0
				fi
			fi
		fi
		>&2 echo "Error: can't add directory to MFS"
	fi
	return 1
}
_ipfs_add_file_to_mfs() {
	local path="$1"
	local addr="$2"
	if [[ "$addr" != "" ]]; then
		local CID="$(_safe ipfs add --quieter --pin=false $path --to-files /$addr)"
		if [[ "$CID" != "" ]]; then
			if [[ "$CID" == "$(_safe ipfs files stat --hash /$addr)" ]]; then
				echo "$CID"
				return 0
			fi
		else
			CID="$(_safe ipfs add --quieter --pin=false $path)"
			if [[ "$CID" != "" ]]; then
				if _safe ipfs files cp //ipfs/$CID /$addr; then
					echo "$CID"
					return 0
				elif [[ "$CID" == "$(_safe ipfs files stat --hash /$addr)" ]]; then
					echo "$CID"
					return 0
				fi
			fi
		fi
		>&2 echo "Error: can't add file to MFS"
	fi
	return 1
}

# for logs and settings
_ipfs_add_pipe_to_mfs() {
	local addr="$1"
	if [[ "$addr" != "" ]]; then
		_safe_with_warnings ipfs files write --create /$addr
		return $?
	fi
	return 1
}

_ipfs_gateway() {	# Kubo v.0.15.0+
	cat "$_IPFS_REPO_PATH/gateway" 2>/dev/null
	return $?
}

_news() {
	if cat "$(_zeronet_data)/$_SITE_ADDRESS/news.txt" 2>/dev/null; then
		echo ""
		echo ""
	fi
	echo "Invintation:"
	echo "  Run 'miceweb talks' to find answers together"
}

# https://www.rfc-editor.org/rfc/rfc3986#appendix-B
#
readonly URI_REGEX='^(([^:/?#]+):)?(//((([^:/?#]+)@)?([^:/?#]+)(:([0-9]+))?))?(/([^?#]*))(\?([^#]*))?(#(.*))?'
#                    â†‘â†‘            â†‘  â†‘â†‘â†‘            â†‘         â†‘ â†‘            â†‘ â†‘        â†‘  â†‘        â†‘ â†‘
#                    |2 scheme     |  ||6 userinfo   7 host    | 9 port       | 11 rpath |  13 query | 15 fragment
#                    1 scheme:     |  |5 userinfo@             8 :â€¦           10 path    12 ?â€¦       14 #â€¦
#                                  |  4 authority
#                                  3 //â€¦
_parse_scheme () {
    [[ "$@" =~ $URI_REGEX ]] && echo "${BASH_REMATCH[2]}"
}
_parse_authority () {
    [[ "$@" =~ $URI_REGEX ]] && echo "${BASH_REMATCH[4]}"
}
_parse_user () {
    [[ "$@" =~ $URI_REGEX ]] && echo "${BASH_REMATCH[6]}"
}
_parse_host () {
    [[ "$@" =~ $URI_REGEX ]] && echo "${BASH_REMATCH[7]}"
}
_parse_port () {
    [[ "$@" =~ $URI_REGEX ]] && echo "${BASH_REMATCH[9]}"
}
_parse_path () {
    [[ "$@" =~ $URI_REGEX ]] && echo "${BASH_REMATCH[10]}"
}
_parse_rpath () {
    [[ "$@" =~ $URI_REGEX ]] && echo "${BASH_REMATCH[11]}"
}
_parse_query () {
    [[ "$@" =~ $URI_REGEX ]] && echo "${BASH_REMATCH[13]}"
}
_parse_fragment () {
    [[ "$@" =~ $URI_REGEX ]] && echo "${BASH_REMATCH[15]}"
}

_parse_extension() {
	local rpath=$(_parse_rpath "$@")
	local LPC="${rpath##*/}"
	if [[ "$LPC" != "" ]]; then
		local extension="${LPC##*.}"
		if [[ "$LPC" != "$extension" ]]; then
			if [[ "$extension" != "" ]]; then
				echo "$extension"
			fi
		fi
	fi
}

_path_extension() {
	local filename="$@"
	extension="${filename##*.}"
	echo "$extension"
}

_print_hyperlink() {
	local URL="$1"
	local URLTEXT="$2"
	if [[ "$URLTEXT" == "" ]]; then
		URLTEXT="$URL"
	fi
	printf '\e]8;;%s\e\\%s\e]8;;\e\\' "$URL" "$URLTEXT"
}
_print_hyperlink_string() {
	local URL="$1"
	local URLTEXT="$2"
	if [[ "$URLTEXT" == "" ]]; then
		URLTEXT="$URL"
	fi
	printf '\e]8;;%s\e\\%s\e]8;;\e\\\n' "$URL" "$URLTEXT"
}
_print_with_hyperlink() {
	local PREFIX="$1"
	local URL="$2"
	local SUFFIX="$3"
	printf '%s' "$PREFIX"
	_print_hyperlink "$URL"
	printf '%s\n' "$SUFFIX"
}

_random_value() {
	local chars=abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789
	for i in {1..32} ; do
		echo -n "${chars:RANDOM%${#chars}:1}"
	done
	echo
}

_remove_dir() {
	local DIRPATH="$1"
	local CID="$(_safe ipfs files stat --hash /$DIRPATH)"
	if [[ "$CID" != "" ]]; then
		if _safe ipfs files rm -r /$DIRPATH >/dev/null; then
			echo "Removed $DIRPATH, you can try to undo that right now by running 'ipfs files cp /ipfs/$CID $DIRPATH'"
			return 0
		fi
	fi
	return 1
}
_remove_file() {
	local FILEPATH="$1"
	local CID="$(_safe ipfs files stat --hash /$FILEPATH)"
	if [[ "$CID" != "" ]]; then
		if _safe ipfs files rm /$FILEPATH >/dev/null; then
			echo "Removed $FILEPATH, you can try to undo that right now by running 'ipfs files cp /ipfs/$CID $FILEPATH'"
			return 0
		fi
	fi
	return 1
}

_reprovider_strategy() {
	_safe ipfs config Reprovider.Strategy
}

_reproviding_warning() {
	#>&2 echo "Tip: run 'miceweb tune' to control"
	local REPROVIDING=$(_reprovider_strategy)
	if [[ "$REPROVIDING" == "" ]]; then
		>&2 printf '%s' "Warning: "
		>&2 _print_hyperlink "https://github.com/ipfs/kubo/blob/master/docs/config.md#reproviderstrategy" "Reprovider.Strategy"
		>&2 echo " is unset"
	#elif [[ "$REPROVIDING" == "all" ]]; then
	#	>&2 printf '%s' "Warning: "
	#	>&2 _print_hyperlink "https://github.com/ipfs/kubo/blob/master/docs/config.md#reproviderstrategy" "Reprovider.Strategy"
	#	>&2 echo " is set to '$REPROVIDING'"
		#>&2 echo "Warning: the reprovider announces all IPFS data including the MiceWeb Library,"
		#>&2 echo " consider to run 'ipfs config Reprovider.Strategy pinned', seeing"
		#>&2 echo " https://github.com/ipfs/kubo/blob/master/docs/config.md#reproviderstrategy"
	fi
}

_resolve_ipns() {
	local DOMAIN=$(echo "$1" | awk -F/ '{print $1}')
	#local TIMEOUT="60s"
	#if [[ "$2" != "" ]]; then
	#	TIMEOUT="$2"
	#fi
	#local ADDR=$(_safe ipfs name resolve --recursive=true --timeout=$TIMEOUT $DOMAIN)
	local ADDR=$(_safe ipfs name resolve --recursive=true --timeout=60s $DOMAIN)
	local CID="${ADDR#/ipfs/}"
	if [[ $CID != "" ]]; then
		echo "$CID${1#$DOMAIN}"
		local DT=$(_current_timestamp)
		local LOGTXTADDR=""
		for I in $(_safe ipfs files ls //MiceWeb/resolves/ipns/$DOMAIN | sort --reverse); do
			local PREVCID=$(_safe_with_warnings ipfs files read //MiceWeb/resolves/ipns/$DOMAIN/$I | sed -n 2p)
			if [[ $PREVCID == $CID ]]; then
				LOGTXTADDR="/MiceWeb/resolves/ipns/$DOMAIN/$I"
				break
			fi
		done
		if [[ $LOGTXTADDR == "" ]]; then
			LOGTXTADDR="/ipfs/$(printf "%s\n%s\n" "CID $(_random_value)" "$CID" | _safe_with_warnings ipfs add --quieter --pin=false)"
		fi
		if [[ $LOGTXTADDR != "" ]]; then
			_safe ipfs files mkdir //MiceWeb/resolves
			_safe ipfs files mkdir //MiceWeb/resolves/ipns
			_safe ipfs files mkdir //MiceWeb/resolves/ipns/$DOMAIN
			_safe_with_warnings ipfs files cp /$LOGTXTADDR //MiceWeb/resolves/ipns/$DOMAIN/$DT.txt
		fi
		return 0
	else
		for I in $(_safe ipfs files ls //MiceWeb/resolves/ipns/$DOMAIN | sort --reverse); do
			CID=$(_safe_with_warnings ipfs files read //MiceWeb/resolves/ipns/$DOMAIN/$I | sed -n 2p)
			if [[ $CID != "" ]]; then
				>&2 echo "Warning: could not resolve /ipns/$DOMAIN actually"
				echo "$CID${1#$DOMAIN}"
				return 0
			fi
		done
	fi
	>&2 echo "Error: could not resolve /ipns/$DOMAIN"
	return 1
}

_resolve_zeronet() {
	local MAIN=$(echo "$1" | awk -F/ '{print $1}')
	if [[ $MAIN == *.* ]]; then
		if ! _command_exists jq; then
			>&2 _print_with_hyperlink "Error: jq is not installed (seeing " "https://stedolan.github.io/jq/download/" ")"
			return 1
		fi
		local DOMAIN=$MAIN
		MAIN=$(wget http://127.0.0.1:43110/raw/$MAIN/content.json --timeout=1 --tries=1 --output-document=- 2>/dev/null | jq --raw-output '.address' 2>/dev/null)
		if [[ $MAIN == 1* ]]; then
			echo $MAIN"${1#$DOMAIN}"
			return 0
		elif [[ $MAIN == "" ]]; then
			>&2 echo "Error: running ZeroNet node is required to resolve such domains"
			return 1
		else
			>&2 echo "Error: not supported address /zeronet/$MAIN"
			return 1
		fi
	elif [[ $MAIN == 1* ]]; then
		echo $1
		return 0
	fi
	return 1
}

_safe() {
	#local IPFS_REPO_PATH="$IPFS_PATH"
	#if [[ "$IPFS_REPO_PATH" == "" ]]; then
	#	IPFS_REPO_PATH="$HOME/.ipfs"
	#fi
	#local IPFS_REPO_LOCK="$IPFS_REPO_PATH/repo.lock"
	#if [ -e "$IPFS_REPO_LOCK" ]; then
	#	>&2 echo -n "Waiting until removed $IPFS_REPO_LOCK..."
	#	sleep 1
	#	while [ -e "$IPFS_REPO_LOCK" ]; do
	#		>&2 echo -n "."
	#		sleep 1
	#	done
	#	>&2 echo ""
	#fi
	
	#"${@}" 2>/dev/null
	
	#TODO: https://unix.stackexchange.com/questions/716971/bin-sh-capture-stderr-into-a-variable ?
#	(echo $(./outerr.sh) # Collect and flatten the stdout output 
                     # Meanwhile stderr flows through the pipe
#) 2>&1|tac|{         # reverse the output so the stdout line comes first
#        read out
#        err=$(tac)   # reverse lines again, back to the original line order
#        echo "err=$err"
#        echo "out=$out"
#}

	local tmpFN=$(_temp_file_maybe_in_ram)
	local RET=
	if [[ "$tmpFN" != "" ]]; then
		while true; do
			"${@}" 2>$tmpFN
			RET=$?
			if [ $RET -eq 0 ]; then
				rm $tmpFN
				return $RET
			fi
			if [[ $(cat $tmpFN) == "Error: lock "*": someone else has the lock" ]]; then
				sleep 1
			else
				rm $tmpFN
				return $RET
			fi
		done
	else
		"${@}" 2>/dev/null
		RET=$?
	fi
	return $RET
}

_safe_with_warnings() {
	local tmpFN=$(_temp_file_maybe_in_ram)
	local RET=
	if [[ "$tmpFN" != "" ]]; then
		while true; do
			"${@}" 2>$tmpFN
			RET=$?
			if [ $RET -eq 0 ]; then
				>&2 cat $tmpFN
				rm $tmpFN
				return $RET
			fi
			if [[ $(cat $tmpFN) == "Error: lock "*": someone else has the lock" ]]; then
				sleep 1
			else
				>&2 cat $tmpFN
				rm $tmpFN
				return $RET
			fi
		done
	else
		"${@}"
		RET=$?
	fi
	return $RET
}

_save_and_present() {	#TODO: remove the function
	local URL="$1"
	_reproviding_warning
	save --no-warnings $URL |
		while IFS= read -r I
		do
			echo $I
			present --no-warnings $I 1>&2
		done
}

_save_archived() {
	type -P wayback_machine_downloader &>/dev/null && ISINST=1 || ISINST=0
	if [ $ISINST -eq 0 ]
	then
		>&2 echo "Error: wayback_machine_downloader is not installed"
		return 127
	fi
	type -P jq &>/dev/null && ISINST=1 || ISINST=0
	if [ $ISINST -eq 0 ]
	then
		>&2 _print_with_hyperlink "Error: jq is not installed (seeing " "https://stedolan.github.io/jq/download/" ")"
		return 127
	fi
	local ADDR=""
	if [[ $1 == http://* ]]; then
		ADDR="${1#http://}"
	elif [[ $1 == https://* ]]; then
		ADDR="${1#https://}"
	else
		return 1
	fi
	local RET=1
	for I in $(wayback_machine_downloader -s -e -l "$1" 2>/dev/null | jq --raw-output '.. | .timestamp? | strings' | tail -n1); do
		SUBDIR="${I:0:8}GMT${I:8:6}-archive"
		_safe ipfs files ls /$SAVE_MFS_ADDR/$SUBDIR >/dev/null
		if [ $? -ne 0 ]; then
			_wget "https://web.archive.org/web/$I/$ADDR" --cut-dirs=3
			RET=$?
		else
			>&2 echo "Warning: $SUBDIR is already downloaded, doing nothing"
			echo "$SAVE_HASH/$SUBDIR"
			RET=0
		fi
	done
	return $RET
}
_save_archived_snapshot() {
	local URL="$1"
	local ADDR=""
	if [[ $URL == http://* ]]; then
		ADDR="${URL#http://}"
	elif [[ $URL == https://* ]]; then
		ADDR="${URL#https://}"
	else
		return 1
	fi
	local RET=1
	SUBDIR="$2"
	_safe ipfs files ls /$SAVE_MFS_ADDR/$SUBDIR >/dev/null
	if [ $? -ne 0 ]; then
		_wget "https://web.archive.org/web/${SUBDIR:0:8}${SUBDIR:11:6}/$ADDR" --cut-dirs=3
		RET=$?
	else
		>&2 echo "Warning: $SUBDIR is already downloaded, doing nothing"
		echo "$SAVE_HASH/$SUBDIR"
		RET=0
	fi
	return $RET
}
_save_curl() {
	local DT=$(_current_timestamp)
	SUBDIR="$DT-curl"
	_safe ipfs files ls /$SAVE_MFS_ADDR/$SUBDIR >/dev/null
	if [ $? -ne 0 ]; then
		local EMPTY="QmbFMke1KXqnYyBBWxB74N4c5SBnJMVAiMNRcGu6x1AwQH"
		local CID=$(curl --connect-timeout 60 -f "$1" 2>/dev/null | _safe_with_warnings ipfs add --cid-version=0 --quieter --pin=false)
		if [[ "$CID" != "" && "$CID" != "$EMPTY" ]]; then
			_safe_with_warnings ipfs files cp //ipfs/$CID /$SAVE_MFS_ADDR/$SUBDIR
			if [ $? -eq 0 ]; then
				echo "$SAVE_HASH/$SUBDIR"
				#TODO: make it better
				local sz=$(_safe_with_warnings ipfs files stat --size /$SAVE_MFS_ADDR/$SUBDIR)
				if [ $sz -le 1024 ]; then
					local content=$(_safe_with_warnings ipfs files read /$SAVE_MFS_ADDR/$SUBDIR)
					if [[ "$content" == "<meta http-equiv=\"refresh\" content=\"0; url="*"\">" ]]; then
						content="${content#<meta http-equiv=\"refresh\" content=\"0; url=}"
						content="${content%\">}"
						>&2 echo "Found redirect to $content, saving it"
						#TODO: avoid possible infinite recursions, and use 'save' function (but remember about global variables 'SAVE_MFS_ADDR' and 'SUBDIR')
						"$0" save --no-warnings "$content" #2> >(grep .)
					fi
				fi
				return 0
			fi
		else
			>&2 echo "Error: could not download '${SUBDIR:18}'"
		fi
		return 1
	else
		>&2 echo "Warning: $SUBDIR is already exist, doing nothing"
		echo "$SAVE_HASH/$SUBDIR"
		return 0
	fi
}
_save_curl_tor() {
	local DT=$(_current_timestamp)
	SUBDIR="$DT-curl-tor"
	_safe ipfs files ls /$SAVE_MFS_ADDR/$SUBDIR >/dev/null
	if [ $? -ne 0 ]; then
		local EMPTY="QmbFMke1KXqnYyBBWxB74N4c5SBnJMVAiMNRcGu6x1AwQH"
		local CID=$(torsocks --isolate curl --connect-timeout 60 -f "$1" 2>/dev/null | _safe_with_warnings ipfs add --cid-version=0 --quieter --pin=false)
		if [[ "$CID" != "" && "$CID" != "$EMPTY" ]]; then
			_safe_with_warnings ipfs files cp //ipfs/$CID /$SAVE_MFS_ADDR/$SUBDIR
			if [ $? -eq 0 ]; then
				echo "$SAVE_HASH/$SUBDIR"
				#TODO: handle redirections like in _save_curl
				return 0
			fi
		else
			>&2 echo "Error: could not download '${SUBDIR:18}'"
		fi
		return 1
	else
		>&2 echo "Warning: $SUBDIR is already exist, doing nothing"
		echo "$SAVE_HASH/$SUBDIR"
		return 0
	fi
}
_save_gemget() {
	local DT=$(_current_timestamp)
	SUBDIR="$DT-gemget"
	_safe ipfs files ls /$SAVE_MFS_ADDR/$SUBDIR >/dev/null
	if [ $? -ne 0 ]; then
		local EMPTY="QmbFMke1KXqnYyBBWxB74N4c5SBnJMVAiMNRcGu6x1AwQH"
		local CID=$(gemget --output=- "$1" 2>/dev/null | _safe_with_warnings ipfs add --cid-version=0 --quieter --pin=false)
		if [[ "$CID" != "" && "$CID" != "$EMPTY" ]]; then
			_safe_with_warnings ipfs files cp //ipfs/$CID /$SAVE_MFS_ADDR/$SUBDIR
			if [ $? -eq 0 ]; then
				echo "$SAVE_HASH/$SUBDIR"
				return 0
			fi
		else
			>&2 echo "Error: could not download '${SUBDIR:18}'"
		fi
		return 1
	else
		>&2 echo "Warning: $SUBDIR is already exist, doing nothing"
		echo "$SAVE_HASH/$SUBDIR"
		return 0
	fi
}
_save_git() {
	if [[ $1 == git://* || $1 == *.git || $1 == https://github.com/*/* ]]; then
		if [[ $1 != https://github.com/*/*/?* ]]; then
			local DT=$(_current_timestamp)
			SUBDIR="$DT-git"
			_safe ipfs files ls /$SAVE_MFS_ADDR/$SUBDIR >/dev/null
			if [ $? -ne 0 ]; then
				if _command_exists git; then
					_git $1
					return $?
				else
					>&2 echo "Error: git is required to save git repositories"
				fi
			else
				>&2 echo "Warning: $SUBDIR is already exist, doing nothing"
				echo "$SAVE_HASH/$SUBDIR"
				return 0
			fi
		fi
	fi
	return 1
}
_save_wget_ipfs() {
	local MAIN=$(echo "$1" | awk -F/ '{print $1}')
	local ADDR=$(_safe_with_warnings ipfs resolve --timeout=60s $MAIN)
	if [[ "$ADDR" != "" ]]; then
		local DT=$(_current_timestamp)
		SUBDIR="$DT-wget-ipfs"
		_safe ipfs files ls /$SAVE_MFS_ADDR/$SUBDIR >/dev/null
		if [ $? -ne 0 ]; then
			#TODO: check _ipfs_gateway first
			local GATEWAY=$(_safe_with_warnings ipfs config Addresses.Gateway)
			if [ "$GATEWAY" != "" ]; then
				_wget "http://127.0.0.1:${GATEWAY##*/}/ipfs/$1" --cut-dirs=2
				return $?
			else
				>&2 echo "Error: local IPFS gateway is not set"
			fi
		else
			>&2 echo "Warning: $SUBDIR is already exist, doing nothing"
			echo "$SAVE_HASH/$SUBDIR"
			return 0
		fi
	fi
	return 1
}
_save_wget_ipns() {
	local ADDR=$(_resolve_ipns "$1")
	if [[ "$ADDR" != "" ]]; then
		local DT=$(_current_timestamp)
		SUBDIR="$DT-wget-ipns"
		_safe ipfs files ls /$SAVE_MFS_ADDR/$SUBDIR >/dev/null
		if [ $? -ne 0 ]; then
			#TODO: check _ipfs_gateway first
			local GATEWAY=$(_safe_with_warnings ipfs config Addresses.Gateway)
			if [ "$GATEWAY" != "" ]; then
				_wget "http://127.0.0.1:${GATEWAY##*/}/ipfs/$ADDR" --cut-dirs=2 "Resolved /ipns/$1 to /ipfs/$ADDR"
				return $?
			else
				>&2 echo "Error: local IPFS gateway is not set"
			fi
		else
			>&2 echo "Warning: $SUBDIR is already exist, doing nothing"
			echo "$SAVE_HASH/$SUBDIR"
			return 0
		fi
	fi
	return 1
}
_save_wget() {
	local DT=$(_current_timestamp)
	SUBDIR="$DT-wget"
	_safe ipfs files ls /$SAVE_MFS_ADDR/$SUBDIR >/dev/null
	if [ $? -ne 0 ]; then
		_wget $1
		return $?
	else
		>&2 echo "Warning: $SUBDIR is already exist, doing nothing"
		echo "$SAVE_HASH/$SUBDIR"
		return 0
	fi
}
_save_wget_tor() {
	local DT=$(_current_timestamp)
	SUBDIR="$DT-wget-tor"
	_safe ipfs files ls /$SAVE_MFS_ADDR/$SUBDIR >/dev/null
	if [ $? -ne 0 ]; then
		_wget $1 --torsocks
		return $?
	else
		>&2 echo "Warning: $SUBDIR is already exist, doing nothing"
		echo "$SAVE_HASH/$SUBDIR"
		return 0
	fi
}
_save_media() {
	if [[ $1 == http*://vk.com/video/@* ]]; then
		return 1
	elif [[ $1 == http*://www.youtube.com/*watch?v=* || $1 == http*://m.youtube.com/*watch?v=* || $1 == http*://youtu.be/* || $1 == http*://vk.com/video* || $1 == http*://vk.com/clip* || $1 == http*://ok.ru/video/* || $1 == http*://m.ok.ru/video/* || $1 == http*://vimeo.com/* || $1 == http*://coub.com/view/* || $1 ==  http*://www.instagram.com/p/* || $1 == http*://www.tiktok.com/@*/video/* || $1 == http*://twitter.com/*/status/* || $1 == http*://fb.watch/* || $1 == http*://www.facebook.com/reel/* || $1 == http*://my.mail.ru/mail/*/video/* || $1 == http*://music.yandex.ru/album/*/track/* || $1 == http*://www.youtube.com/shorts/* || $1 == http*://m.youtube.com/shorts/* || $1 == http*://www.youtube.com/clip/* || $1 == http*://m.youtube.com/clip/* ]]; then	#TODO: support share.tube?
		local DT=$(_current_timestamp)
		SUBDIR="$DT-media"
		_safe ipfs files ls /$SAVE_MFS_ADDR/$SUBDIR >/dev/null
		if [ $? -ne 0 ]; then
			if _command_exists yt-dlp; then
				if _command_exists ffmpeg; then
					_ytdlp $1
					return $?
				else
					>&2 echo "Error: ffmpeg is required to save media"
				fi
			else
				>&2 echo "Error: yt-dlp is required to save media"
			fi
		else
			>&2 echo "Warning: $SUBDIR is already exist, doing nothing"
			echo "$SAVE_HASH/$SUBDIR"
			return 0
		fi
	elif [[ $1 == http*://www.twitch.tv/* || $1 == http*://m.twitch.tv/* || $1 == http*://rutube.ru/video/* || $1 == http*://www.dailymotion.com/video/* || $1 == http*://zen.yandex.ru/video/watch/* || $1 == http*://dzen.ru/video/watch/* ]]; then
		>&2 echo "Warning: skipped downloading 'media', promised to be very slow"	#TODO: download just audio?
	#	local DT=$(_current_timestamp)
	#	SUBDIR="$DT-audio"
	#	_safe ipfs files ls /$SAVE_MFS_ADDR/$SUBDIR >/dev/null
	#	if [ $? -ne 0 ]; then
	#		if _command_exists yt-dlp; then
	#			if _command_exists ffmpeg; then
	#				if _command_exists ffprobe; then
	#					_ytdlp_audio $1
	#					return $?
	#				fi
	#			fi
	#			>&2 echo "Error: ffmpeg and ffprobe are required to save audio"
	#		else
	#			>&2 echo "Error: yt-dlp is required to save audio"
	#		fi
	#	else
	#		>&2 echo "Warning: $SUBDIR is already exist, doing nothing"
	#		echo "$SAVE_HASH/$SUBDIR"
	#		return 0
	#	fi
	fi
	return 1
}
_save_playlist() {
	if [[ $1 == http*://www.youtube.com/channel/* || $1 == http*://www.youtube.com/c/* || $1 == http*://www.youtube.com/user/* || $1 == http*://www.youtube.com/@* || $1 == http*://www.youtube.com/*list=* || $1 == http*://m.youtube.com/channel/* || $1 == http*://m.youtube.com/c/* || $1 == http*://m.youtube.com/user/* || $1 == http*://m.youtube.com/@* || $1 == http*://m.youtube.com/*list=* || $1 == http*://rutube.ru/channel/*/videos/ || $1 == http*://rutube.ru/channel/*/videos || $1 == http*://vimeo.com/* || $1 == http*://www.dailymotion.com/* || $1 == http*://music.yandex.ru/album/* || $1 == http*://vk.com/video/@* ]]; then
		local DT=$(_current_timestamp)
		SUBDIR="$DT-playlist"
		_safe ipfs files ls /$SAVE_MFS_ADDR/$SUBDIR >/dev/null
		if [ $? -ne 0 ]; then
			local EMPTY="QmbFMke1KXqnYyBBWxB74N4c5SBnJMVAiMNRcGu6x1AwQH"
			local CID=$(yt-dlp --flat-playlist --print "Title: %(title)s
URL: %(webpage_url)s
Duration: %(duration_string)s
Views: %(view_count)s
Description: %(description)s

" --socket-timeout 10 --no-progress "$URL" 2>/dev/null | _safe_with_warnings ipfs add --cid-version=0 --quieter --pin=false)
			if [[ "$CID" != "" && "$CID" != "$EMPTY" ]]; then
				_safe_with_warnings ipfs files cp //ipfs/$CID /$SAVE_MFS_ADDR/$SUBDIR
				if [ $? -eq 0 ]; then
					echo "$SAVE_HASH/$SUBDIR"
					return 0
				fi
			else
				>&2 echo "Error: could not download '${SUBDIR:18}'"
			fi
			return 1
		else
			>&2 echo "Warning: $SUBDIR is already exist, doing nothing"
			echo "$SAVE_HASH/$SUBDIR"
			return 0
		fi
	fi
}
_save_zite() {
	#local DOMAIN=$(echo "$1" | awk -F/ '{print $1}')
	#if [[ $DOMAIN == *.* ]]; then
	#	MAIN=$(_resolve_zeronet $DOMAIN)
	#	if [[ $MAIN != $DOMAIN && "$MAIN" != "" ]]; then
	#		>&2 echo "Resolved /zeronet/$DOMAIN to /zeronet/$MAIN"
	#	fi
	#else
	#	MAIN=$DOMAIN
	#fi
	local MAIN=$1
	if [[ $MAIN =~ ^[13][a-km-zA-HJ-NP-Z1-9]{25,34}$ ]]; then
		local DT=$(_current_timestamp)
		SUBDIR="$DT-zite"
		_safe ipfs files ls /$SAVE_MFS_ADDR/$SUBDIR >/dev/null
		if [ $? -ne 0 ]; then
			local ZITEDATA="$(_zeronet_data)/$MAIN"
			if [[ -f "$ZITEDATA"/content.json ]]; then
				if _ipfs_add_directory_to_mfs "$ZITEDATA" $SAVE_MFS_ADDR/$SUBDIR >/dev/null; then
					echo "$SAVE_HASH/$SUBDIR"
					return 0
				fi
			fi
			#TODO: try to load zite: "try later" and wget if zeronet node is running, "run ZeroNet node" if not
			>&2 echo "Error: $MAIN is not loaded"
		else
			>&2 echo "Warning: $SUBDIR is already exist, doing nothing"
			echo "$SAVE_HASH/$SUBDIR"
			return 0
		fi
	fi
	return 1
}

_similar() {
	local URL="$(_url_but_fragment "$1")"
	for I in $(_similar_but_scheme "$URL"); do
		for J in $(_similar_but_slash "$I"); do
			for K in $(_similar_but_something "$J"); do
				for L in $(_similar_concrete "$K"); do
					echo "$L"
				done
			done
		done
	done
}
_similar_but_scheme() {
	local URL="$1"
	local host="$(_parse_host "$URL/")"
	if [[ $host == *.* ]]; then
		if [[ $URL == http://* ]]; then
			echo $URL
			echo "https://${URL#http://}"
			echo "ipns://${URL#http://}"
		elif [[ $URL == https://* ]]; then
			echo "http://${URL#https://}"
			echo $URL
			echo "ipns://${URL#https://}"
		elif [[ $URL == ipns://* ]]; then
			echo "http://${URL#ipns://}"
			echo "https://${URL#ipns://}"
			echo $URL
		elif [[ $URL == ftp://* ]]; then
			echo $URL
			echo "ftps://${URL#ftp://}"
		elif [[ $URL == ftps://* ]]; then
			echo "ftp://${URL#ftps://}"
			echo $URL
		else
			echo $URL
		fi
	else
		echo $URL
	fi
}
_similar_but_slash() {
	local URL="$1"
	local URL1="${URL%/}"
	local URL2="$URL1/"
	echo $URL1
	echo $URL2
}
_similar_but_something() {
	local URL="$1"
	local host=$(_parse_host "$URL/")
	echo $URL
	# www
	if [[ $URL == http://www.* ]]; then
		echo "http://${URL#http://www.}"
	elif [[ $URL == http://* ]]; then
		echo "http://www.${URL#http://}"
	elif [[ $URL == https://www.* ]]; then
		echo "https://${URL#https://www.}"
	elif [[ $URL == https://* ]]; then
		echo "https://www.${URL#https://}"
	fi
	# FTP
	if [[ $URL == http://ftp.* ]]; then
		echo "https://ftp.${URL#http://ftp.}"
		echo "ftp://ftp.${URL#http://ftp.}"
	elif [[ $URL == https://ftp.* ]]; then
		echo "http://ftp.${URL#https://ftp.}"
		echo "ftp://ftp.${URL#https://ftp.}"
	elif [[ $URL == ftp://ftp.* ]]; then
		echo "http://ftp.${URL#ftp://ftp.}"
		echo "https://ftp.${URL#ftp://ftp.}"
	fi
	# ZeroNet
	if [[ $URL == http://127.0.0.1:43110/raw/* ]]; then
		echo "http://127.0.0.1:43110/${URL#http://127.0.0.1:43110/raw/}"
	elif [[ $URL == http://127.0.0.1:43110/* ]]; then
		echo "http://127.0.0.1:43110/raw/${URL#http://127.0.0.1:43110/}"
	fi
	# IPFS
	if [[ $URL == ipfs://$host/* ]]; then
		if [[ $URL == ipfs://Qm* ]]; then
			local converted="$(_safe ipfs cid format -v 1 -b base32 $host)"
			if [[ "$converted" != "" ]]; then
				echo "ipfs://$converted/${URL#ipfs://$host/}"
			fi
		elif [[ $URL == ipfs://bafy* ]]; then
			local converted="$(_safe ipfs cid format -v 0 -b base58btc $host)"
			if [[ "$converted" != "" ]]; then
				echo "ipfs://$converted/${URL#ipfs://$host/}"
			fi
		fi
	fi
	#TODO: the same for IPNS
	
}
_similar_concrete() {
	local URL="$1"
	echo $URL
	if [[ $URL == https://* ]]; then
		# Habr
		if [[ $URL == https://habrahabr.ru/* ]]; then
			echo "https://habr.com/ru/${URL#https://habrahabr.ru/}"
			echo "https://habr.com/en/${URL#https://habrahabr.ru/}"
			echo "https://habr.com/${URL#https://habrahabr.ru/}"
		elif [[ $URL == https://habr.com/ru/* ]]; then
			echo "https://habrahabr.ru/${URL#https://habr.com/ru/}"
			echo "https://habr.com/en/${URL#https://habr.com/ru/}"
			echo "https://habr.com/${URL#https://habr.com/ru/}"
		elif [[ $URL == https://habr.com/en/* ]]; then
			echo "https://habrahabr.ru/${URL#https://habr.com/en/}"
			echo "https://habr.com/ru/${URL#https://habr.com/en/}"
			echo "https://habr.com/${URL#https://habr.com/en/}"
		elif [[ $URL == https://habr.com/* ]]; then
			echo "https://habrahabr.ru/${URL#https://habr.com/}"
			echo "https://habr.com/en/${URL#https://habr.com/}"
			echo "https://habr.com/ru/${URL#https://habr.com/}"
		fi
		# VK
		if [[ $URL == https://vk.com/* ]]; then
			echo "https://vkontakte.ru/${URL#https://vk.com/}"
		elif [[ $URL == https://vkontakte.ru/* ]]; then
			echo "https://vk.com/${URL#https://vkontakte.ru/}"
		fi
		# YouTube
		if [[ $URL == https://youtu.be/* ]]; then
			echo "https://www.youtube.com/watch?v=${URL#https://youtu.be/}"
			echo "https://m.youtube.com/watch?v=${URL#https://youtu.be/}"
		elif [[ $URL == https://www.youtube.com/watch?v=* ]]; then
			echo "https://m.youtube.com/watch?v=${URL#https://www.youtube.com/watch?v=}"
			echo "https://youtu.be/${URL#https://www.youtube.com/watch?v=}"
		elif [[ $URL == https://m.youtube.com/watch?v=* ]]; then
			echo "https://www.youtube.com/watch?v=${URL#https://m.youtube.com/watch?v=}"
			echo "https://youtu.be/${URL#https://m.youtube.com/watch?v=}"
		elif [[ $URL == https://www.youtube.com/* ]]; then
			echo "https://m.youtube.com/${URL#https://www.youtube.com/}"
		elif [[ $URL == https://m.youtube.com/* ]]; then
			echo "https://www.youtube.com/${URL#https://m.youtube.com/}"
		fi
	fi
}
#similar() {
#	_similar "$1"
#}

_snapshots_and_save() {
	local SOMETHING="$1"
	snapshots "$SOMETHING"
	save "$SOMETHING"
}

_subcommands() {
  if [[ "${1:-}" == "--raw" ]]
  then
    printf "%s\\n" "${_DEFINED_SUBCOMMANDS[@]}"
  else
    printf "Available commands:\\n"
    printf "  %s\\n" "${_DEFINED_SUBCOMMANDS[@]}"
  fi
}

_temp_directory() {
	mktemp -d 2>/dev/null || mktemp -d -t 'mytmpdir'
}

_temp_file() {
	mktemp 2>/dev/null || mktemp -t 'mytmpfile' 2>/dev/null
}

_temp_file_maybe_in_ram() {
	# https://stackoverflow.com/questions/39230353/creating-a-temporary-file-in-memory-and-using-it-as-input-file-of-a-command
	mktemp -p /dev/shm/ 2>/dev/null || _temp_file
}

_tip_run_ipfs_daemon() {
	>&2 echo "Tip: run 'ipfs daemon' using Kubo v.0.15 or newer"
}

_upgrade() {
	local TESTHASH1=$(_hash "test")
	if [[ "$TESTHASH1" != "a94a8fe5ccb19ba61c4c0873d391e987982fbbd3" ]]; then
		exit 1
	fi
	local VERTXT="/MiceWeb/attributes.txt"
	local VER=$(_safe ipfs files read /$VERTXT | sed -n 2p)
	if [[ $VER == "" ]]; then
		local TESTHASH2="$(echo -n "test" | _safe_with_warnings ipfs add --only-hash --quieter --cid-version=0)"
		#TODO: _IPFS_FEATURES="--to-files" when accessible
		if [[ "$TESTHASH2" != "QmRf22bZar3WKmojipms22PkXH1MZGmvsqzQtuSvQE3uhm" ]]; then
			_exit_1 _print_with_hyperlink "Installed IPFS CLI like " "https://github.com/ipfs/kubo" " is required for MiceWeb"
		fi
	fi
	local APPVER="v.${_VERSION}"
	if [[ $APPVER != $VER ]]; then
		if [[ $VER == "" ]]; then
			if ! _safe ipfs files ls //MiceWeb >/dev/null; then
				_safe ipfs files mkdir //MiceWeb
				local VERTXTCID="$(printf "%s\n%s\n" "Library $(_random_value)" "$APPVER" | _safe_with_warnings ipfs add --quieter --pin=false)"
				if _safe_with_warnings ipfs files cp //ipfs/$VERTXTCID /$VERTXT; then
					return 0
				else
					_exit_1 printf "Can't create MiceWeb library\n"
				fi
			fi
			backup >/dev/null
			_safe ipfs files mkdir //MiceWeb/pages
			local CID="$(_safe_with_warnings ipfs files stat --hash //MiceWeb/pages/)"
			if [[ "$CID" != "" ]]; then
				for I in $(_safe_with_warnings ipfs files ls //MiceWeb/pages/ | grep ^page-Qm); do
					local URL=$(_safe ipfs cat $CID/$I/URL.txt | sed -n 2p)
					if [[ "$URL" != "" ]]; then
						>&2 echo -n "Upgrading $URL..."
						local HASH=$(_hash "$URL")
						>&2 echo -n "."
						if [[ "$HASH" != "" ]]; then
							_safe_with_warnings ipfs files mv //MiceWeb/pages/$I "//MiceWeb/pages/$HASH"
						fi
						>&2 echo "."
					fi
				done
				local VERTXTCID="$(printf "%s\n%s\n" "Library $(_random_value)" "v.0.2" | _safe_with_warnings ipfs add --quieter --pin=false)"
				_safe_with_warnings ipfs files cp //ipfs/$VERTXTCID /$VERTXT
				if [ $? -eq 0 ]; then
					_safe ipfs files flush //MiceWeb >/dev/null
					>&2 echo "Upgraded the MiceWeb library to v.0.2"
					_upgrade
					return $?
				fi
			fi
			_exit_1 printf "Can't upgrade the MiceWeb library\n"
		else
			_vercomp "${_VERSION}" "${VER#v.}"
			if [ $? -eq 1 ]; then
				# updating to v.0.3
				backup >/dev/null
				local VERTXTCID="$(printf "%s\n%s\n" "Library $(_random_value)" "v.0.3" | _safe_with_warnings ipfs add --quieter --pin=false)"
				_safe_with_warnings ipfs files rm /$VERTXT
				_safe_with_warnings ipfs files cp //ipfs/$VERTXTCID /$VERTXT
				if [ $? -eq 0 ]; then
					_safe ipfs files flush //MiceWeb >/dev/null
					>&2 echo "Upgraded the MiceWeb library to v.0.3"
					>&2 echo "It's recommended to run 'miceweb save urls --grep=#'"
					save urls --grep="#"
					>&2 echo ""
					return 0
				fi
				_exit_1 printf "Can't upgrade the MiceWeb library\n"
			else
				_exit_1 printf "MiceWeb $VER+ is required to work with the current MiceWeb Library\nThe current app version is $APPVER\nRun './update.sh' in the MiceWeb repository\n"
			fi
		fi
	fi
	return 0
}

_url_but_fragment() {
	local URL="$1"
	local fragment=$(_parse_fragment "$URL")
	if _has_url_fragment "$URL"; then
		echo "${URL%#$fragment}"
	else
		echo "$URL"
	fi
}

# https://stackoverflow.com/questions/4023830/how-to-compare-two-strings-in-dot-separated-version-format-in-bash
_vercomp () {
    if [[ $1 == $2 ]]
    then
        return 0
    fi
    local IFS=.
    local i ver1=($1) ver2=($2)
    # fill empty fields in ver1 with zeros
    for ((i=${#ver1[@]}; i<${#ver2[@]}; i++))
    do
        ver1[i]=0
    done
    for ((i=0; i<${#ver1[@]}; i++))
    do
        if [[ -z ${ver2[i]} ]]
        then
            # fill empty fields in ver2 with zeros
            ver2[i]=0
        fi
        if ((10#${ver1[i]} > 10#${ver2[i]}))
        then
            return 1
        fi
        if ((10#${ver1[i]} < 10#${ver2[i]}))
        then
            return 2
        fi
    done
    return 0
}

_versions() {
	local URL="$1"
	if [[ "$URL" == "" ]]; then
		return 1
	fi
	local HASH=$(_hash_string "$URL")
	if [[ "$HASH" != "" ]]; then
		for I in $(_safe ipfs files ls //MiceWeb/pages/$HASH | sed 's/^/'"$HASH"'\//')
		do
			if [[ $I != *.* ]]; then
				echo $I
			fi
		done
	fi
}

_warn_about_version() {
	#TODO: compare current and actual version numbers?
	>&2 echo "Disclaimer: it's important to use an actual MiceWeb version for communication"
	>&2 echo ""
}

_wget() {
	local URL="$1"
	local options="$2"
	local comment="$3"
	local MYTMPDIR=$(_temp_directory)
	local MYTMPFILE=$(_temp_file_maybe_in_ram)
	cd $MYTMPDIR
	local RAND="$(_random_value)"
	echo "Log $RAND" > $MYTMPFILE
	echo "$comment" >> $MYTMPFILE
	local USERAGENT="Mozilla/5.0 (Windows NT 10.0; rv:92.0) Gecko/20100101 Firefox/92.0"
	local ACCEPT="text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8"
	local span=""
	if [[ $SUBDIR != *-archive ]]; then
		span="--span-hosts"
	fi
	local robotsoff="--execute=robots=off"
	if [ "$options" != "--torsocks" ]; then
		wget --adjust-extension --no-cache --page-requisites --follow-ftp --no-remove-listing --retr-symlinks --restrict-file-names=windows --convert-links --backup-converted --no-host-directories $span $robotsoff --timeout=30 --tries=1 --header="Accept: $ACCEPT" --user-agent="$USERAGENT" $options --append-output=$MYTMPFILE "$URL"
	else
		torsocks --isolate wget --adjust-extension --no-cache --page-requisites --follow-ftp --no-remove-listing --retr-symlinks --restrict-file-names=windows --convert-links --backup-converted --no-host-directories $span $robotsoff --timeout=30 --tries=1 --header="Accept: $ACCEPT" --user-agent="$USERAGENT" --append-output=$MYTMPFILE "$URL" 2>/dev/null
	fi
	local WGETERR=$?
	local RET=1
	if [[ $WGETERR -eq 0 || $WGETERR -ge 3 ]] && [ $(ls -A "$MYTMPDIR" | wc -l) -ne 0 ]; then
		if [ $WGETERR -ne 0 ]; then
			>&2 echo "Warning: detected issues when downloading '${SUBDIR:18}', wget err. $WGETERR"
		fi
		local CID="$(_ipfs_add_directory_to_mfs $MYTMPDIR $SAVE_MFS_ADDR/$SUBDIR)"
		if [[ "$CID" != "" ]]; then
			echo "$SAVE_HASH/$SUBDIR"
			local logCID="$(_ipfs_add_file_to_mfs $MYTMPFILE $SAVE_MFS_ADDR/$SUBDIR.log)"
			RET=$WGETERR
		fi
	else
		>&2 echo "Error: could not download '${SUBDIR:18}', wget err. $WGETERR"
	fi
	cd ..
	rm -r $MYTMPDIR
	rm $MYTMPFILE
	return $RET
}

_ytdlp() {
	local URL="$1"
	local MYTMPDIR=$(_temp_directory)
	cd $MYTMPDIR
	yt-dlp --no-playlist --format "bv*[ext=mp4]+ba[ext=m4a]/b[ext=mp4] / bv*+ba/b" --format-sort "res~360" --sleep-requests 1 --sleep-interval 5 --max-sleep-interval 10 --embed-chapters --no-write-info-json --no-cookies-from-browser --no-cache-dir --write-description --write-annotations --no-embed-thumbnail --write-all-thumbnails --write-playlist-metafiles --live-from-start --merge-output-format "mp4" --socket-timeout 10 --throttled-rate 50K --output "%(title).144s [%(id)s] - %(channel).48s [%(channel_id)s] - %(upload_date)s.%(ext)s" --output "description:media.%(ext)s" --output "thumbnail:thumbnails/image.%(ext)s" --no-progress "$URL" &>/dev/null
	local YTDLPERR=$?
	local RET=1
	if [[ $YTDLPERR -eq 0 ]]; then
		if _ipfs_add_directory_to_mfs "$MYTMPDIR" $SAVE_MFS_ADDR/$SUBDIR >/dev/null; then
			echo "$SAVE_HASH/$SUBDIR"
			RET=$YTDLPERR
		fi
	else
		>&2 echo "Error: could not download '${SUBDIR:18}', yt-dlp err. $YTDLPERR"
	fi
	cd ..
	rm -r $MYTMPDIR
	return $RET
}

_ytdlp_audio() {
	local URL="$1"
	local MYTMPDIR=$(_temp_directory)
	cd $MYTMPDIR
	yt-dlp --no-playlist --format "(bestaudio[acodec^=opus]/bestaudio)/best" --sleep-requests 1 --sleep-interval 5 --max-sleep-interval 10 --add-metadata --add-chapters --no-write-info-json --no-cookies-from-browser --no-cache-dir --write-description --write-annotations --no-embed-thumbnail --write-all-thumbnails --write-playlist-metafiles --live-from-start --extract-audio --audio-quality 0 --socket-timeout 10 --throttled-rate 50K --output "%(title)s [%(id)s] - %(channel)s [%(channel_id)s] - %(upload_date)s.%(ext)s" --output "description:media.%(ext)s" --output "thumbnail:thumbnails/image.%(ext)s" --no-progress "$URL" &>/dev/null
	local YTDLPERR=$?
	local RET=1
	if [[ $YTDLPERR -eq 0 ]]; then
		if _ipfs_add_directory_to_mfs "$MYTMPDIR" $SAVE_MFS_ADDR/$SUBDIR >/dev/null; then
			echo "$SAVE_HASH/$SUBDIR"
			RET=$YTDLPERR
		fi
	else
		>&2 echo "Error: could not download '${SUBDIR:18}', yt-dlp err. $YTDLPERR"
	fi
	cd ..
	rm -r $MYTMPDIR
	return $RET
}

_zeronet_data() {
	if [ "$ZERONET_PATH" != "" ]; then
		echo "$ZERONET_PATH/data"
	else
		echo "$HOME/Library/Application Support/ZeroNet/data"
	fi
}

_zite_address() {
	local URL="$1"
	local PARSEDPATH=$(_parse_path $URL)
	local ZNPATH=""
	if [[ $URL != http://127.0.0.1:43110/raw/* ]]; then
		ZNPATH="${PARSEDPATH#/}"
	else
		ZNPATH="${PARSEDPATH#/raw/}"
	fi
	local DOMAIN=$(echo "$ZNPATH" | awk -F/ '{print $1}')
	if [[ $DOMAIN == *.* ]]; then
		MAIN=$(_resolve_zeronet $DOMAIN)
		#if [[ $MAIN != $DOMAIN && "$MAIN" != "" ]]; then
		#	>&2 echo "Resolved /zeronet/$DOMAIN to /zeronet/$MAIN"
		#fi
	else
		MAIN=$DOMAIN
	fi
	echo $MAIN
}

###############################################################################
# Subcommands
# ===========..................................................................
#
# Example subcommand group structure:
#
# describe example ""   - Optional. A short description for the subcommand.
# example() { : }   - The subcommand called by the user.
#
#
# describe example <<HEREDOC
#   Usage:
#     $_ME example
#
#   Description:
#     Print "Hello, World!"
#
#     For usage formatting conventions see:
#     - http://docopt.org/
#     - http://pubs.opengroup.org/onlinepubs/9699919799/basedefs/V1_chap12.html
# HEREDOC
# example() {
#   printf "Hello, World!\\n"
# }
#
###############################################################################


# backup ######################################################################

describe "backup" <<HEREDOC
Usage:
  ${_ME} backup

Description:
  Backup CID of the MiceWeb library
HEREDOC
backup() {
	if [[ "$1" != "" ]]; then
		>&2 echo "This command doesn't require parameters"
		return 1
	fi
	mkdir -p "$HOME/.miceweb"
	local DT=$(export TZ=GMT ; date '+%Y-%m-%d GMT %H:%M:%S')
	local CID="$(_safe ipfs files stat --hash //MiceWeb)"
	if [[ "$CID" != "" ]]; then
		printf "%s\t%s\n" "$DT" "$CID" >> "$HOME/.miceweb/backup.txt"
		if [ $? -eq 0 ]; then
			>&2 echo "Added CID of /MiceWeb (MFS) to ~/.miceweb/backup.txt"
			echo $CID
		else
			echo $CID
			_exit_1 printf "Can't backup CID to ~/.miceweb/backup.txt\n"
		fi
	else
		_exit_1 printf "Can't obtain CID of the MiceWeb library\n"
	fi
}

# check #####################################################################

describe "check" <<HEREDOC
Usage:
  ${_ME} check <snapshot>
  ${_ME} check <URL>
  ${_ME} check <SHA-1>
  ${_ME} check urls [--grep=<expr.>] [<local/ipfs/ipns/zeronet file path>]
  ${_ME} check <zite>
  ${_ME} check zites [<local/ipfs/ipns/zeronet file path>]

Description:
  Check saved snapshot
  Check saved snapshots of web page (including similar) by URL
  Check saved snapshots of web page by URL's SHA-1
  Check saved snapshots of web pages
  Check saved snapshots of zite by bitcoin address
  Check saved snapshots of zites
HEREDOC
check() {
	_upgrade
	if [[ "$1" == "urls" ]]; then
		if [[ "$2" != "" ]]; then
			_safe ipfs files mkdir //MiceWeb
			_safe ipfs files mkdir //MiceWeb/presents
			local DT=$(_current_timestamp)
			local MFS_PRESENT_ADDR="/MiceWeb/presents/present-$DT"
			_safe ipfs files mkdir /$MFS_PRESENT_ADDR
			local COUNT=0
			local HASH=""
			for I in $(urls --no-warnings "$2" "$3" "$4" "$5" "$6" "$7")	#$("$0" "$@" 2>/dev/null)
			do
				HASH=$(_hash "$I")
				_safe ipfs files cp //MiceWeb/pages/$HASH /$MFS_PRESENT_ADDR/$HASH
				if [ $? -eq 0 ]; then
					((COUNT++))
				fi
				#TODO: or with similar (maybe support --similar option)
				#for J in $(_similar "$I" 2>/dev/null)
				#do
				#	local HASH=$(_hash "$J")
				#	_safe ipfs files cp //MiceWeb/pages/$HASH /$MFS_PRESENT_ADDR/$HASH
				#	if [ $? -eq 0 ]; then
				#		((COUNT++))
				#	fi
				#done
				if _has_url_fragment "$I"; then
					HASH=$(_hash_string "$I")
					_safe ipfs files cp //MiceWeb/pages/$HASH /$MFS_PRESENT_ADDR/$HASH
					if [ $? -eq 0 ]; then
						((COUNT++))
					fi
				fi
			done
			local CID="$(_safe_with_warnings ipfs files stat --hash /$MFS_PRESENT_ADDR)"
			if [[ "$CID" != "" && $COUNT -ne 0 ]]; then
				if _safe ipfs dag stat QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn --timeout=1s >/dev/null; then
					ipfs dag stat $CID
				else
					>&2 echo "Can't check $CID,"
					>&2 echo " consider to run 'ipfs update'"
					return 1
				fi
				return 0
			fi
			#TODO: fix and implement something like >&2 echo "Run 'miceweb save ${@@Q}'"
			return 1
		fi
	fi
	if [[ "$1" == "zites" ]]; then
		#TODO: support http://127.0.0.1:43110/ipfs/...
		if [[ "$2" != "" ]]; then
			_safe ipfs files mkdir //MiceWeb
			_safe ipfs files mkdir //MiceWeb/presents
			local DT=$(_current_timestamp)
			local MFS_PRESENT_ADDR="/MiceWeb/presents/present-$DT"
			_safe ipfs files mkdir /$MFS_PRESENT_ADDR
			local COUNT=0
			local HASH=""
			for ZITE in $(zites "$2")	#$("$0" "$@" 2>/dev/null)
			do
				if _safe ipfs files cp //MiceWeb/zites/$ZITE /$MFS_PRESENT_ADDR/$ZITE; then
					((COUNT++))
				fi
			done
			local CID="$(_safe_with_warnings ipfs files stat --hash /$MFS_PRESENT_ADDR)"
			if [[ "$CID" != "" && $COUNT -ne 0 ]]; then
				if _safe ipfs dag stat QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn --timeout=1s >/dev/null; then
					ipfs dag stat $CID
				else
					>&2 echo "Can't check $CID,"
					>&2 echo " consider to run 'ipfs update'"
					return 1
				fi
				return 0
			fi
			return 1
		else
			local MFS_PRESENT_ADDR="/MiceWeb/zites/"
			local CID="$(_safe ipfs files stat --hash /$MFS_PRESENT_ADDR)"
			if [[ "$CID" != "" ]]; then
				if _safe ipfs dag stat QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn --timeout=1s >/dev/null; then
					ipfs dag stat $CID
				else
					>&2 echo "Can't check $CID,"
					>&2 echo " consider to run 'ipfs update'"
					return 1
				fi
				return 0
			else
				return 1
			fi
		fi
	fi
	
	local SOMETHING=""
	local _arguments=()
	local _val=
	for __arg in "${@:-}"
	do
	case ${__arg} in
	  -*)
		_exit_1 printf "Unexpected option: %s\\n" "${__arg}"
		;;
	  *)
		if _blank "${SOMETHING}"
		then
		  _val="${__arg}"
		  SOMETHING="$_val"
		else
		  _arguments+=("${__arg}")
		fi
		;;
	esac
	done

	if [[ "$SOMETHING" =~ ^[0-9a-f]{40}/[0-9]{8}GMT[0-9]{6}-. ]]; then
		local SNAP="$SOMETHING"
		if [[ "$SNAP" != *.* ]]; then
			local MFS_SNAP_ADDR="/MiceWeb/pages/$SNAP"
			local CID=""
			local ing=0
			if [[ "$SNAP" == *-import ]]; then
				CID="$(_safe ipfs files stat --hash /$MFS_SNAP_ADDR)"
				if [ "$CID" == "" ]; then
					ing=1
					CID="$(_safe_with_warnings ipfs files stat --hash "/$MFS_SNAP_ADDR"ing)"
				fi
			else
				CID="$(_safe_with_warnings ipfs files stat --hash /$MFS_SNAP_ADDR)"
				if [[ "$SNAP" == *-importing ]]; then
					ing=1
					MFS_SNAP_ADDR="${MFS_SNAP_ADDR%ing}"
				fi
			fi
			if [ "$CID" != "" ]; then
				if _safe ipfs dag stat QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn --timeout=1s >/dev/null; then
					if ipfs dag stat $CID; then
						if [ $ing -eq 1 ]; then
							_safe_with_warnings ipfs files mv "/$MFS_SNAP_ADDR"ing /$MFS_SNAP_ADDR
							return $?
						fi
					fi
				else
					>&2 echo "Can't check $CID,"
					>&2 echo " consider to run 'ipfs update'"
					return 1
				fi
				return 0
			fi
		fi
		return 1
	fi
	
	if [[ "$SOMETHING" =~ ^[13][a-km-zA-HJ-NP-Z1-9]{25,34}/[0-9]{8}GMT[0-9]{6}-zite$ ]]; then
		local SNAP="$SOMETHING"
		local MFS_SNAP_ADDR="/MiceWeb/zites/$SNAP"
		local CID="$(_safe_with_warnings ipfs files stat --hash /$MFS_SNAP_ADDR)"
		if [ "$CID" != "" ]; then			
			if _safe ipfs dag stat QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn --timeout=1s >/dev/null; then
				ipfs dag stat $CID
			else
				>&2 echo "Can't check $CID,"
				>&2 echo " consider to run 'ipfs update'"
				return 1
			fi
			return 0
		fi
		return 1
	fi
	
	local URL="$SOMETHING"
	local HASH=""
	local CID0=""
	local CID=""
	local CNT=0
	
	if [[ "$SOMETHING" =~ ^[0-9a-f]{40}$ ]]; then
		HASH="$SOMETHING"
		URL=$(url "$SOMETHING")
		if [[ "$URL" == "" ]]; then
			return 1
		fi
		local MFS_PAGE_ADDR="/MiceWeb/pages/$HASH"
		CID="$(_safe_with_warnings ipfs files stat --hash /$MFS_PAGE_ADDR)"
		if [ "$CID" != "" ]; then
			if _safe ipfs dag stat QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn --timeout=1s >/dev/null; then
				ipfs dag stat $CID
			else
				>&2 echo "Can't check $CID,"
				>&2 echo " consider to run 'ipfs update'"
				return 1
			fi
			return 0
		else
			return 1
		fi
	elif [[ "$SOMETHING" =~ ^[13][a-km-zA-HJ-NP-Z1-9]{25,34}$ ]]; then
		HASH="$SOMETHING"
		local MFS_PAGE_ADDR="/MiceWeb/zites/$HASH"
		CID="$(_safe_with_warnings ipfs files stat --hash /$MFS_PAGE_ADDR)"
		if [ "$CID" != "" ]; then
			if _safe ipfs dag stat QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn --timeout=1s >/dev/null; then
				ipfs dag stat $CID
			else
				>&2 echo "Can't check $CID,"
				>&2 echo " consider to run 'ipfs update'"
				return 1
			fi
			return 0
		else
			return 1
		fi
	fi
	
	local URL0="$(_url_but_fragment "$URL")"
	
	local SIMURL="$URL0"
	local SIMURLs=()
	
	if [[ "$URL" != "urls" ]]; then
		HASH=$(_hash "$URL" 2>/dev/null)
	fi
	
	if [[ "$HASH" != "" ]]; then
		local MFS_PAGE_ADDR="/MiceWeb/pages/$HASH"
		_safe ipfs files ls /$MFS_PAGE_ADDR/URL.txt >/dev/null
		if [ $? -ne 0 ]; then
			if _check_url "$URL"; then
				_safe ipfs files mkdir //MiceWeb
				_safe ipfs files mkdir //MiceWeb/pages
				_safe ipfs files mkdir /$MFS_PAGE_ADDR
				local URLTXTCID="$(printf "%s\n%s\n" "URL $(_random_value)" "$URL" | _safe_with_warnings ipfs add --quieter --pin=false)"
				_safe_with_warnings ipfs files cp //ipfs/$URLTXTCID /$MFS_PAGE_ADDR/URL.txt
			else
				_echo_supported_url_prefixes
				return 1
			fi
		fi
		_safe ipfs files mkdir //MiceWeb
		_safe ipfs files mkdir //MiceWeb/presents
		local DT=$(_current_timestamp)
		local MFS_PRESENT_ADDR="/MiceWeb/presents/present-$DT"
		_safe ipfs files mkdir /$MFS_PRESENT_ADDR
		for I in $(_similar "$URL" 2>/dev/null)
		do
			local SIMHASH=$(_hash "$I")
			if _safe ipfs files cp //MiceWeb/pages/$SIMHASH /$MFS_PRESENT_ADDR/$SIMHASH; then
				if [[ "$I" != "$URL0" ]]; then
					SIMURL="$I"
					SIMURLs+=("$I")
					((CNT++))
				fi
			fi
		done
		if _has_url_fragment "$URL"; then
			local SIMHASH=$(_hash_string "$URL")
			if _safe ipfs files cp //MiceWeb/pages/$SIMHASH /$MFS_PRESENT_ADDR/$SIMHASH; then
				SIMURLs+=("$URL")
				((CNT++))
			fi
		fi
		CID0="$(_safe_with_warnings ipfs files stat --hash /$MFS_PRESENT_ADDR)"
		if [[ $CID0 == "QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn" ]]; then
			_exit_1 echo "Error: unexpected error, try again"
		fi
		CID="$CID0/$HASH"
	else
		local MFS_PRESENT_ADDR="/MiceWeb/pages/"
		CID0="$(_safe ipfs files stat --hash /$MFS_PRESENT_ADDR)"
		CID="$CID0"
	fi
	
	if [[ "$CID0" != "" ]]; then
		if _safe ipfs dag stat QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn --timeout=1s >/dev/null; then
			ipfs dag stat $CID0
		else
			>&2 echo "Can't check $CID0,"
			>&2 echo " consider to run 'ipfs update'"
			return 1
		fi
	else
		#TODO: fix and implement something like >&2 echo "Run 'miceweb save ${@@Q}'"
		return 1
	fi
}

# cleanup #####################################################################

describe "cleanup" <<HEREDOC
Usage:
  ${_ME} cleanup

Description:
  Cleanup service data
HEREDOC
cleanup() {
	if [[ "$1" != "" ]]; then
		>&2 echo "This command doesn't require parameters"
		return 1
	fi
	local MFS_PRESENTS_ADDR="/MiceWeb/presents"
	local CID="$(_safe_with_warnings ipfs files stat --hash /$MFS_PRESENTS_ADDR)"
	if [[ "$CID" == "" ]]; then
		>&2 echo "Nothing to cleanup"
		return 0
	fi
	if _safe_with_warnings ipfs files rm -r /$MFS_PRESENTS_ADDR; then
		>&2 echo "Removed the history of presents"
		>&2 echo ""
		>&2 echo "You can try to undo that right now by running"
		>&2 echo " 'ipfs files cp /ipfs/$CID $MFS_PRESENTS_ADDR'"
		return 0
	else
		>&2 echo "Failed to cleanup"
		return 1
	fi
}

# commands ####################################################################

describe "commands" <<HEREDOC
Usage:
  ${_ME} commands

Description:
  Display the list of available commands
HEREDOC
commands() {
	echo "miceweb			Introduce MiceWeb"
	#_subcommands --raw $1 | awk -v PREFIX="miceweb " '{print PREFIX $0}'
	echo "miceweb backup		Backup CID of the MiceWeb library
miceweb check		Check saved snapshots data
miceweb check urls
miceweb check zites
miceweb cleanup		Cleanup service data
miceweb commands	Display the list of available commands
miceweb find		Find saved web pages on the local machine
miceweb hash		Calculate SHA-1 hash for URL (but fragment)
miceweb help		Display help information
miceweb history		List URLs which were attempted to be saved or imported
miceweb import		Import web page snapshot from file or directory
miceweb log		Print log created when saved snapshot
miceweb present		Present saved snapshots
miceweb present urls
miceweb present zites
miceweb remove		Remove saved snapshot
miceweb request		Request web page snapshots from remote sources
miceweb resolve		Resolve dynamic path (e.g., IPNS) to direct path
miceweb save		Save web page snapshots
miceweb save urls
miceweb save zites
miceweb snapshots	List saved snapshots
miceweb talks		Welcome to MiceWeb Talks in ZeroNet
miceweb url		Return URL by SHA-1 hash
miceweb urls		List URLs from file, or from the MiceWeb library
miceweb version		Display the current program version
miceweb zites		List zites from the MiceWeb library"
}

# find ########################################################################

describe "find" <<HEREDOC
Usage:
  ${_ME} find <URL>
  ${_ME} find <SHA-1>

Description:
  Find saved web pages in ~/Downloads (use SingleFile or SingleFileZ browser extension)
HEREDOC
find() {
	_upgrade
	>&2 _print_with_hyperlink "Install " "https://github.com/gildas-lormeau/SingleFile"
	>&2 _print_with_hyperlink " or " "https://github.com/gildas-lormeau/SingleFileZ" " browser extension,"
	>&2 echo " then set filename template to some value contains {url-href-digest-sha-1}"
	>&2 echo "Downloads folder should be inside ~/Downloads (or just create a symlink)"
	>&2 echo ""
	local URL="$(_url_but_fragment "$1")"
	if [[ "$URL" == "" ]]; then
		>&2 echo "This command requires URL or SHA-1 as a parameter"
		return 1
	fi
	if [[ "$1" =~ ^[0-9a-f]{40}$ ]]; then
		local HASH="$1"
		URL=$(url "$1")
		if [[ "$URL" == "" ]]; then
			command find -L ~/Downloads -name "*$HASH*" -not -path '*/.*' | awk -v PREFIX="miceweb import $HASH \"" -v SUFFIX="\"" '{print PREFIX $0 SUFFIX}'
			return 0
		fi
		if [[ "$URL" == http*://* ]]; then
			command find -L ~/Downloads -name "*$HASH*" -not -path '*/.*' | awk -v PREFIX="miceweb import \"$URL\" \"" -v SUFFIX="\"" '{print PREFIX $0 SUFFIX}'
		fi
	else
		if ! _check_url "$URL"; then
			_echo_supported_url_prefixes
			return 1
		fi
		for J in $(_similar "$URL" 2>/dev/null); do
			if [[ "$J" == http*://* ]]; then
				local HASH=$(_hash "$J")
				if [[ "$HASH" != "" ]]; then
					command find -L ~/Downloads -name "*$HASH*" -not -path '*/.*' | awk -v PREFIX="miceweb import \"$J\" \"" -v SUFFIX="\"" '{print PREFIX $0 SUFFIX}'
				fi
			fi
		done
	fi
	local filename=$(basename "$URL")
	command find -L ~/Downloads -name "$filename" -not -path '*/.*' | awk -v PREFIX="miceweb import \"$URL\" \"" -v SUFFIX="\"" '{print PREFIX $0 SUFFIX}'
	command find -L ~/Downloads -name "$filename.*" -not -path '*/.*' | awk -v PREFIX="miceweb import \"$URL\" \"" -v SUFFIX="\"" '{print PREFIX $0 SUFFIX}'
}

# hash ########################################################################

describe "hash" <<HEREDOC
Usage:
  ${_ME} hash <URL>

Description:
  Calculate SHA-1 hash for URL (but fragment)
HEREDOC
hash() {
	local URL="$1"
	if [[ "$URL" == "" ]]; then
		>&2 echo "This command requires URL as a parameter"
		return 1
	fi
	if ! _check_url "$URL"; then
		_echo_supported_url_prefixes
		return 1
	fi
	local HASH=$(_hash "$URL")
	if [[ "$HASH" != "" ]]; then
		echo $HASH
		local MFS_ADDR="/MiceWeb/pages/$HASH"
		_safe ipfs files ls /$MFS_ADDR/URL.txt >/dev/null
		if [ $? -ne 0 ]; then
			_safe ipfs files mkdir //MiceWeb
			_safe ipfs files mkdir //MiceWeb/pages
			_safe ipfs files mkdir /$MFS_ADDR
			local URL0=$(_url_but_fragment "$URL")
			local URLTXTCID="$(printf "%s\n%s\n" "URL $(_random_value)" "$URL0" | _safe_with_warnings ipfs add --quieter --pin=false)"
			_safe_with_warnings ipfs files cp //ipfs/$URLTXTCID /$MFS_ADDR/URL.txt
		fi
		return 0
	else
		return 1
	fi
}

# help ########################################################################

describe "help" <<HEREDOC
Usage:
  ${_ME} help
  ${_ME} help <command>

Description:
  Display help information for ${_ME} or a specified command
HEREDOC
help() {
  if [[ "${1:-}" ]]
  then
    describe --get "${1}"
  else
    cat <<HEREDOC
  __  __   _                 __        __        _     
 |  \/  | (_)   ___    ___   \ \      / /  ___  | |__  
 | |\/| | | |  / __|  / _ \   \ \ /\ / /  / _ \ | '_ \ 
 | |  | | | | | (__  |  __/    \ V  V /  |  __/ | |_) |
 |_|  |_| |_|  \___|  \___|     \_/\_/    \___| |_.__/ 

Version: ${_SUB_VERSION}

Usage:
  ${_ME} <URL|SHA-1|zite|snapshot>
  ${_ME} <command> [--<command-options>] [<arguments>]

Help:
  ${_ME} help [<command>]

$(_subcommands --)

$(_news)
HEREDOC
  fi
}

# history #####################################################################

describe "history" <<HEREDOC
Usage:
  ${_ME} history

Description:
  List URLs which were attempted to be saved or imported
HEREDOC
history() {
	FN="$HOME/.miceweb/history.txt"
	COUNT=$(cat $FN 2>/dev/null | wc -l)
	if [ $COUNT -ne 0 ]; then
		>&2 echo "There is a list of URLs which was attempted to be saved or imported:"
		cat $FN
		>&2 echo ""
		>&2 echo "NumEntries: $COUNT"
	else
		>&2 echo "There are no URLs which was attempted to be saved or imported"
	fi
}

# import ######################################################################

describe "import" <<HEREDOC
Usage:
  ${_ME} import <URL> <local/ipfs/ipns/zeronet path> [<comment>]
  ${_ME} import <SHA-1> <local/ipfs/ipns/zeronet path> [<comment>]

Description:
  Import web page snapshot from file or directory
HEREDOC
import() {
	_upgrade
	_reproviding_warning
	local URL="$1"
	local IMPPATH="$2"
	local COMMENT="$3"
	if [[ "$URL" =~ ^[0-9a-f]{40}$ ]]; then
		URL=$(url "$1")
		if [[ "$URL" == "" ]]; then
			#TODO: handle it
			return 1
		fi
	fi
	local SNAPTYPE="import"
	#if [[ "$IMPPATH" == "" ]]; then
	#	if [[ "$URL" == ipfs://* ]]; then
	#		IMPPATH="/ipfs/$(echo "${URL#ipfs://}" | awk -F/ '{print $1}')"
	#		>&2 echo "Set path to $IMPPATH"
	#	elif [[ "$URL" == ipns://* ]]; then
	#		IMPPATH="/ipns/$(echo "${URL#ipns://}" | awk -F/ '{print $1}')"
	#		>&2 echo "Set path to $IMPPATH"
	#	elif [[ "$URL" == http://127.0.0.1:43110/raw/* ]]; then
	#		IMPPATH="/zeronet/$(echo "${URL#http://127.0.0.1:43110/raw/}" | awk -F/ '{print $1}')"
	#		SNAPTYPE="zite"
	#		>&2 echo "Set path to $IMPPATH"
	#	elif [[ "$URL" == http://127.0.0.1:43110/* ]]; then
	#		IMPPATH="/zeronet/$(echo "${URL#http://127.0.0.1:43110/}" | awk -F/ '{print $1}')"
	#		SNAPTYPE="zite"
	#		>&2 echo "Set path to $IMPPATH"
		#elif [[ "$URL" == http://* || "$URL" == https://* ]]; then
			#if [[ ! "$URL" =~ ^[0-9a-f]{40}$ ]]; then
				#if _safe ipfs name resolve --recursive=false --timeout=5s $DOMAIN >/dev/null; then
					
				#fi
			#fi
	#	fi
	#fi
	if [[ "$URL" == "" || "$IMPPATH" == "" ]]; then
		>&2 echo "This command requires URL or SHA-1 as a first parameter"
		>&2 echo " and local/ipfs/ipns/zeronet path as a second parameter,"
		>&2 echo " some comment can be specified as a third parameter"
		return 1
	fi
	if ! _check_url "$URL"; then
		_echo_supported_url_prefixes
		return 1
	fi
	_addToHistory "$URL"
	local HASH=$(hash "$URL")
	if [[ "$HASH" != "" ]]; then
		local MFS_ADDR="/MiceWeb/pages/$HASH"
		local DT=$(_current_timestamp)
		SUBDIR="$DT-$SNAPTYPE"
		local SUBDIR0="$SUBDIR"ing
		SAVE_HASH=$HASH
		SAVE_MFS_ADDR=$MFS_ADDR
		_safe ipfs files ls /$SAVE_MFS_ADDR/$SUBDIR >/dev/null
		if [ $? -ne 0 ]; then
			local CID=""
			if [[ "$IMPPATH" == /ipfs/* || "$IMPPATH" == /ipns/* ]]; then
				local ADDR=""
				local RESOLVED=""
				if [[ "$IMPPATH" == /ipns/* ]]; then
					ADDR="/ipfs/$(_resolve_ipns "${IMPPATH#/ipns/}")"
					>&2 echo "Resolved to $ADDR"
					RESOLVED=", which resolved to $ADDR"
				else
					ADDR="$IMPPATH"
				fi
				if [[ "$ADDR" != "" ]]; then
					local ADDR2=$(_safe_with_warnings ipfs resolve --timeout=60s "${ADDR#/ipfs/}")
					if [[ "$ADDR2" != "" ]]; then
						if _safe_with_warnings ipfs files cp /$ADDR2 /$MFS_ADDR/$SUBDIR0; then
							if [[ "${ADDR%/}" != "$ADDR2" ]]; then
								>&2 echo "Resolved to $ADDR2"
								if [[ "$RESOLVED" == "" ]]; then
									RESOLVED=", which resolved to $ADDR2"
								else
									RESOLVED="$RESOLVED, then to $ADDR2"
								fi
							fi
							CID="${ADDR2#/ipfs/}"
							echo "$SAVE_HASH/$SUBDIR"
							printf "%s\n%s\n%s\n" "Log $(_random_value)" "Imported from $IMPPATH$RESOLVED" "$COMMENT" | _ipfs_add_pipe_to_mfs $SAVE_MFS_ADDR/$SUBDIR.log
							if _safe ipfs dag stat QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn --timeout=1s >/dev/null; then
								>&2 echo "Getting content from IPFS Network..."
								if ipfs dag stat $CID; then
									if _safe_with_warnings ipfs files mv /$MFS_ADDR/$SUBDIR0 /$MFS_ADDR/$SUBDIR; then
										>&2 echo "Done"
									else
										>&2 echo "Done, but could not confirm it"
									fi
									return 0
								else
									>&2 echo "Incompleted"
								fi
							fi
							if [[ "$(_safe_with_warnings ipfs files stat --format="<type>" /$MFS_ADDR/$SUBDIR0)" == "file" ]]; then
								>&2 echo "Run 'ipfs get $CID --output=/dev/null' to ensure availability"
							else
								>&2 echo "Run 'ipfs get $CID' to ensure availability"
							fi
							return 0
						fi
					fi
				fi
			elif [[ "$IMPPATH" == /zeronet/* ]]; then
				ADDR=$(_resolve_zeronet "${IMPPATH#/zeronet/}")
				if [[ $ADDR != "" ]]; then
					local datadir="$(_zeronet_data)"
					if [ -d "$datadir" ]; then
						local path="$datadir/$ADDR"
						if [ -e "$path" ]; then
							if [ -d "$path" ]; then
								CID="$(_ipfs_add_directory_to_mfs "$path" $SAVE_MFS_ADDR/$SUBDIR)"
							else
								CID="$(_ipfs_add_file_to_mfs "$path" $SAVE_MFS_ADDR/$SUBDIR)"
							fi
							if [[ "$CID" != "" ]]; then
								echo "$SAVE_HASH/$SUBDIR"
								printf "%s\n%s\n%s\n" "Log $(_random_value)" "Imported from $IMPPATH" "$COMMENT" | _ipfs_add_pipe_to_mfs $SAVE_MFS_ADDR/$SUBDIR.log
								return 0
							fi
						else
							>&2 echo "Error: path not found, visit http://127.0.0.1:43110/$ADDR in a browser and try again"
							return 1
						fi
					else
						>&2 echo "Error: '$datadir' not found,"
						>&2 echo " check ZERONET_PATH environment variable"
						return 1
					fi
				else
					return 1
				fi
			elif [ -e "$IMPPATH" ]; then
				if [ -d "$IMPPATH" ]; then
					CID="$(_ipfs_add_directory_to_mfs "$IMPPATH" $SAVE_MFS_ADDR/$SUBDIR)"
				else
					CID="$(_ipfs_add_file_to_mfs "$IMPPATH" $SAVE_MFS_ADDR/$SUBDIR)"
				fi
				if [[ "$CID" != "" ]]; then
					echo "$SAVE_HASH/$SUBDIR"
					local IMPPATH0=${IMPPATH%/}
					local IMPBASE=${IMPPATH0%/*}
					local IMPBASEDIR=${IMPBASE##*/}
					local IMPNAME=${IMPPATH0##*/}
					printf "%s\n%s\n%s\n" "Log $(_random_value)" "Imported from $IMPBASEDIR/$IMPNAME" "$COMMENT" | _ipfs_add_pipe_to_mfs $SAVE_MFS_ADDR/$SUBDIR.log
					#>&2 echo "Run 'miceweb present \"$URL\"' to view saved snapshots"
					#>&2 echo "Run 'miceweb $HASH/$SUBDIR' to present"
					return 0
				fi
			else
				>&2 echo "Error: $IMPPATH not found"
			fi
		else
			>&2 echo "Error: $SAVE_HASH/$SUBDIR is already exist"
			return 1
		fi
	fi
	return 1
}

# log #########################################################################

describe "log" <<HEREDOC
Usage:
  ${_ME} log <snapshot>

Description:
  Print log created when saved snapshot
HEREDOC
log() {
	_upgrade
	local SNAP="$1"
	if [[ "$SNAP" =~ ^[0-9a-f]{40}/[0-9]{8}GMT[0-9]{6}-. ]]; then
		if [[ "$SNAP" != *.* ]]; then
			_safe_with_warnings ipfs files read //MiceWeb/pages/$SNAP.log
			return $?
		fi
	elif [[ "$SNAP" =~ ^[13][a-km-zA-HJ-NP-Z1-9]{25,34}/[0-9]{8}GMT[0-9]{6}-zite$ ]]; then
		_safe_with_warnings ipfs files read //MiceWeb/zites/$SNAP.log
		return $?
	fi
	>&2 echo "This command requires snapshot as a parameter"
	return 1
}

# present #####################################################################

describe "present" <<HEREDOC
Usage:
  ${_ME} present <snapshot>
  ${_ME} present <URL>
  ${_ME} present <SHA-1>
  ${_ME} present urls [--grep=<expr.>] [<local/ipfs/ipns/zeronet file path>]
  ${_ME} present <zite>
  ${_ME} present zites [<local/ipfs/ipns/zeronet file path>]

Description:
  Present saved snapshot
  Present saved snapshots of web page (including similar) by URL
  Present saved snapshots of web page by URL's SHA-1
  Present saved snapshots of web pages
  Present saved snapshots of zite by bitcoin address
  Present saved snapshots of zites
HEREDOC
present() {
	if [[ "$1" != "--no-warnings" ]]; then
		_upgrade
	fi
	local REPROVIDING=$(_reprovider_strategy)
	local GATEWAY=$(_ipfs_gateway)
	if [[ "$1" == "urls" ]]; then
		if [[ "$2" != "" ]]; then
			_safe ipfs files mkdir //MiceWeb
			_safe ipfs files mkdir //MiceWeb/presents
			local DT=$(_current_timestamp)
			local MFS_PRESENT_ADDR="/MiceWeb/presents/present-$DT"
			_safe ipfs files mkdir /$MFS_PRESENT_ADDR
			local COUNT=0
			local HASH=""
			for I in $(urls --no-warnings "$2" "$3" "$4" "$5" "$6" "$7")	#$("$0" "$@" 2>/dev/null)
			do
				HASH=$(_hash "$I")
				_safe ipfs files cp //MiceWeb/pages/$HASH /$MFS_PRESENT_ADDR/$HASH
				if [ $? -eq 0 ]; then
					((COUNT++))
				fi
				#TODO: or with similar (maybe support --similar option)
				#for J in $(_similar "$I" 2>/dev/null)
				#do
				#	local HASH=$(_hash "$J")
				#	_safe ipfs files cp //MiceWeb/pages/$HASH /$MFS_PRESENT_ADDR/$HASH
				#	if [ $? -eq 0 ]; then
				#		((COUNT++))
				#	fi
				#done
				if _has_url_fragment "$I"; then
					HASH=$(_hash_string "$I")
					_safe ipfs files cp //MiceWeb/pages/$HASH /$MFS_PRESENT_ADDR/$HASH
					if [ $? -eq 0 ]; then
						((COUNT++))
					fi
				fi
			done
			local CID="$(_safe_with_warnings ipfs files stat --hash /$MFS_PRESENT_ADDR)"
			if [[ "$CID" != "" && $COUNT -ne 0 ]]; then
				echo "/ipfs/$CID"
				>&2 echo ""
				if [ "$GATEWAY" != "" ]; then
					>&2 _print_with_hyperlink "Open " "$GATEWAY/ipfs/$CID" ""
					>&2 echo " in a browser on the local machine"
					if [[ "$REPROVIDING" == "all" || "$REPROVIDING" == "" ]]; then
						local converted="$(_safe ipfs cid format -v 1 -b base32 $CID)"
						if [[ "$converted" != "" ]]; then
							>&2 _print_with_hyperlink " or " "ipfs://$converted" ""
							>&2 echo " in an IPFS friendly browser - out of box (Brave, Opera) or with IPFS Companion"
						fi
					else
						>&2 echo ""
						>&2 echo "If you need to publish or view from an other machine,"
						>&2 echo " run 'ipfs pin add $CID'"
						#if [[ "$REPROVIDING" == "roots" ]]; then
						#	>&2 echo " and 'ipfs config Reprovider.Strategy pinned'"
						#fi
					fi
				else
					_tip_run_ipfs_daemon
				fi
				local STAT="NumURLs: $COUNT"
				>&2 echo ""
				>&2 echo "$STAT"
				return 0
			fi
			#TODO: fix and implement something like >&2 echo "Run 'miceweb save ${@@Q}'"
			return 1
		fi
	fi
	if [[ "$1" == "zites" ]]; then
		#TODO: support http://127.0.0.1:43110/ipfs/...
		if [[ "$2" != "" ]]; then
			_safe ipfs files mkdir //MiceWeb
			_safe ipfs files mkdir //MiceWeb/presents
			local DT=$(_current_timestamp)
			local MFS_PRESENT_ADDR="/MiceWeb/presents/present-$DT"
			_safe ipfs files mkdir /$MFS_PRESENT_ADDR
			local COUNT=0
			local HASH=""
			for ZITE in $(zites "$2")	#$("$0" "$@" 2>/dev/null)
			do
				if _safe ipfs files cp //MiceWeb/zites/$ZITE /$MFS_PRESENT_ADDR/$ZITE; then
					((COUNT++))
				fi
			done
			local CID="$(_safe_with_warnings ipfs files stat --hash /$MFS_PRESENT_ADDR)"
			if [[ "$CID" != "" && $COUNT -ne 0 ]]; then
				echo "/ipfs/$CID"
				>&2 echo ""
				if [ "$GATEWAY" != "" ]; then
					>&2 _print_with_hyperlink "Open " "$GATEWAY/ipfs/$CID" ""
					>&2 echo " in a browser on the local machine"
					if [[ "$REPROVIDING" == "all" || "$REPROVIDING" == "" ]]; then
						local converted="$(_safe ipfs cid format -v 1 -b base32 $CID)"
						if [[ "$converted" != "" ]]; then
							>&2 _print_with_hyperlink " or " "ipfs://$converted" ""
							>&2 echo " in an IPFS friendly browser - out of box (Brave, Opera) or with IPFS Companion"
						fi
					else
						>&2 echo ""
						>&2 echo "If you need to publish or view from an other machine,"
						>&2 echo " run 'ipfs pin add $CID'"
						#if [[ "$REPROVIDING" == "roots" ]]; then
						#	>&2 echo " and 'ipfs config Reprovider.Strategy pinned'"
						#fi
					fi
				else
					_tip_run_ipfs_daemon
				fi
				local STAT="NumZites: $COUNT"
				>&2 echo ""
				>&2 echo "$STAT"
				return 0
			fi
			return 1
		else
			local MFS_PRESENT_ADDR="/MiceWeb/zites/"
			local CID="$(_safe ipfs files stat --hash /$MFS_PRESENT_ADDR)"
			if [[ "$CID" != "" ]]; then
				echo "/ipfs/$CID"
				local COUNT=$(_safe_with_warnings ipfs files ls //MiceWeb/zites | wc -l)
				local STAT="NumZites: $COUNT"
				>&2 echo ""
				>&2 echo "There is a content identifier of current zites of all the MiceWeb library"
				>&2 echo "It's not recommended to share it because security and other reasons,"
				>&2 echo " however, if you need it, pin $CID"
				#if [[ "$REPROVIDING" == "roots" ]]; then
				#	>&2 echo " and run 'ipfs config Reprovider.Strategy pinned'"
				#fi
				>&2 echo ""
				if [ "$GATEWAY" != "" ]; then
					>&2 _print_with_hyperlink "Open " "$GATEWAY/ipfs/$CID" ""
					>&2 echo " in a browser on the local machine to view snapshots"
				else
					_tip_run_ipfs_daemon
				fi
				>&2 echo ""
				>&2 echo "$STAT"
				return 0
			else
				return 1
			fi
		fi
	fi
	
	local SOMETHING=""
	local _arguments=()
	local _warnings=1
	local _val=
	for __arg in "${@:-}"
	do
	case ${__arg} in
	  --no-warnings)
		_warnings=0
		;;
	  -*)
		_exit_1 printf "Unexpected option: %s\\n" "${__arg}"
		;;
	  *)
		if _blank "${SOMETHING}"
		then
		  _val="${__arg}"
		  SOMETHING="$_val"
		else
		  _arguments+=("${__arg}")
		fi
		;;
	esac
	done

	if [[ "$SOMETHING" =~ ^[0-9a-f]{40}/[0-9]{8}GMT[0-9]{6}-. ]]; then
		local SNAP="$SOMETHING"
		if [[ "$SNAP" != *.* ]]; then
			local MFS_SNAP_ADDR="/MiceWeb/pages/$SNAP"
			
			local CID=""
			local ing=0
			if [[ "$SNAP" == *-import ]]; then
				CID="$(_safe ipfs files stat --hash /$MFS_SNAP_ADDR)"
				if [ "$CID" == "" ]; then
					ing=1
					CID="$(_safe_with_warnings ipfs files stat --hash "/$MFS_SNAP_ADDR"ing)"
				fi
			else
				CID="$(_safe_with_warnings ipfs files stat --hash /$MFS_SNAP_ADDR)"
			fi
			
			if [ "$CID" != "" ]; then
				echo -n "/ipfs/$CID/"
				local suffix=""
				local HASH=$(echo "$SNAP" | awk -F/ '{print $1}')
				if [[ "$HASH" != "" ]]; then
					local URL=$(url "$HASH")
					if [[ "$URL" != "" ]]; then
						suffix="$URL"
						local part=
						part=$(echo $suffix | awk -F/ '{print $1}'); suffix="${suffix#$part/}"
						part=$(echo $suffix | awk -F/ '{print $1}'); suffix="${suffix#$part/}"
						part=$(echo $suffix | awk -F/ '{print $1}'); suffix="${suffix#$part/}"
						local suff="$suffix"
						#TODO: don't check if suffix is empty
						if ! _safe ipfs resolve --timeout=1s "$CID/$suffix" >/dev/null; then
							suffix="${suffix%/}.html"
							if ! _safe ipfs resolve --timeout=1s "$CID/$suffix" >/dev/null; then
								part=$(echo $suff | awk -F/ '{print $1}'); suffix="${suff#$part/}"
								if ! _safe ipfs resolve --timeout=1s "$CID/$suffix" >/dev/null; then
									#TODO: try without last component
									suffix=""
								fi
							fi
						fi
					fi
				fi
				echo "$suffix" #echo "/ipfs/$CID$/suffix"
				if [ $_warnings -eq 1 ]; then
					>&2 echo ""
					if [ "$GATEWAY" != "" ]; then
						>&2 _print_with_hyperlink "Open " "$GATEWAY/ipfs/$CID/$suffix" ""
						>&2 echo " in a browser on the local machine"
						if [[ "$REPROVIDING" == "all" || "$REPROVIDING" == "" ]]; then
							local converted="$(_safe ipfs cid format -v 1 -b base32 $CID)"
							if [[ "$converted" != "" ]]; then
								>&2 _print_with_hyperlink " or " "ipfs://$converted/$suffix" ""
								>&2 echo " in an IPFS friendly browser - out of box (Brave, Opera) or with IPFS Companion"
							fi
						else
							>&2 echo ""
							>&2 echo "If you need to publish or view from an other machine,"
							>&2 echo " run 'ipfs pin add $CID'"
							#if [[ "$REPROVIDING" == "roots" ]]; then
							#	>&2 echo " and 'ipfs config Reprovider.Strategy pinned'"
							#fi
						fi
					else
						_tip_run_ipfs_daemon
					fi
				fi
				return 0
			fi
		fi
		return 1
	fi
	
	if [[ "$SOMETHING" =~ ^[13][a-km-zA-HJ-NP-Z1-9]{25,34}/[0-9]{8}GMT[0-9]{6}-zite$ ]]; then
		local SNAP="$SOMETHING"
		local MFS_SNAP_ADDR="/MiceWeb/zites/$SNAP"
		local CID="$(_safe_with_warnings ipfs files stat --hash /$MFS_SNAP_ADDR)"
		if [ "$CID" != "" ]; then
			local suffix=""
			echo "/ipfs/$CID$suffix"
			if [ $_warnings -eq 1 ]; then
				>&2 echo ""
				if [ "$GATEWAY" != "" ]; then
					>&2 _print_with_hyperlink "Open " "$GATEWAY/ipfs/$CID$suffix" ""
					>&2 echo " in a browser on the local machine"
					if [[ "$REPROVIDING" == "all" || "$REPROVIDING" == "" ]]; then
						local converted="$(_safe ipfs cid format -v 1 -b base32 $CID)"
						if [[ "$converted" != "" ]]; then
							>&2 _print_with_hyperlink " or " "ipfs://$converted$suffix" ""
							>&2 echo " in an IPFS friendly browser - out of box (Brave, Opera) or with IPFS Companion"
						fi
					else
						>&2 echo ""
						>&2 echo "If you need to publish or view from an other machine,"
						>&2 echo " run 'ipfs pin add $CID'"
						#if [[ "$REPROVIDING" == "roots" ]]; then
						#	>&2 echo " and 'ipfs config Reprovider.Strategy pinned'"
						#fi
					fi
				else
					_tip_run_ipfs_daemon
				fi
			fi
			return 0
		fi
		return 1
	fi
	
	local URL="$SOMETHING"
	local HASH=""
	local CID0=""
	local CID=""
	local CNT=0
	
	if [[ "$SOMETHING" =~ ^[0-9a-f]{40}$ ]]; then
		HASH="$SOMETHING"
		URL=$(url "$SOMETHING")
		if [[ "$URL" == "" ]]; then
			return 1
		fi
		local MFS_PAGE_ADDR="/MiceWeb/pages/$HASH"
		CID="$(_safe_with_warnings ipfs files stat --hash /$MFS_PAGE_ADDR)"
		if [ "$CID" != "" ]; then
			echo "/ipfs/$CID"
			local COUNT=0
			for I in $(_safe_with_warnings ipfs files ls /$MFS_PAGE_ADDR); do
				if [[ $I != *.* ]]; then
					((COUNT++))
				fi
			done
			local STAT="NumVersions: $COUNT"
			>&2 echo ""
			if [ "$GATEWAY" != "" ]; then
				>&2 _print_with_hyperlink "Open " "$GATEWAY/ipfs/$CID" ""
				>&2 echo " in a browser on the local machine"
			else
				_tip_run_ipfs_daemon
			fi
			if [[ "$REPROVIDING" == "all" || "$REPROVIDING" == "" ]]; then
				local converted="$(_safe ipfs cid format -v 1 -b base32 $CID)"
				if [[ "$converted" != "" ]]; then
					>&2 _print_with_hyperlink " or " "ipfs://$converted" ""
					>&2 echo " in an IPFS friendly browser - out of box (Brave, Opera) or with IPFS Companion"
				fi
			else
				>&2 echo ""
				>&2 echo "If you need to publish or view from an other machine,"
				>&2 echo " run 'ipfs pin add $CID'"
				#if [[ "$REPROVIDING" == "roots" ]]; then
				#	>&2 echo " and 'ipfs config Reprovider.Strategy pinned'"
				#fi
			fi
			>&2 echo ""
			>&2 echo "$STAT"
			return 0
		else
			return 1
		fi
	elif [[ "$SOMETHING" =~ ^[13][a-km-zA-HJ-NP-Z1-9]{25,34}$ ]]; then
		HASH="$SOMETHING"
		local MFS_PAGE_ADDR="/MiceWeb/zites/$HASH"
		CID="$(_safe_with_warnings ipfs files stat --hash /$MFS_PAGE_ADDR)"
		if [ "$CID" != "" ]; then
			echo "/ipfs/$CID"
			local COUNT=0
			for I in $(_safe_with_warnings ipfs files ls /$MFS_PAGE_ADDR); do
				if [[ $I != *.* ]]; then
					((COUNT++))
				fi
			done
			local STAT="NumVersions: $COUNT"
			>&2 echo ""
			if [ "$GATEWAY" != "" ]; then
				>&2 _print_with_hyperlink "Open " "$GATEWAY/ipfs/$CID" ""
				>&2 echo " in a browser on the local machine"
				if [[ "$REPROVIDING" == "all" || "$REPROVIDING" == "" ]]; then
					local converted="$(_safe ipfs cid format -v 1 -b base32 $CID)"
					if [[ "$converted" != "" ]]; then
						>&2 _print_with_hyperlink " or " "ipfs://$converted" ""
						>&2 echo " in an IPFS friendly browser - out of box (Brave, Opera) or with IPFS Companion"
					fi
				else
					>&2 echo ""
					>&2 echo "If you need to publish or view from an other machine,"
					>&2 echo " run 'ipfs pin add $CID'"
					#if [[ "$REPROVIDING" == "roots" ]]; then
					#	>&2 echo " and 'ipfs config Reprovider.Strategy pinned'"
					#fi
				fi
			else
				_tip_run_ipfs_daemon
			fi
			>&2 echo ""
			>&2 echo "$STAT"
			return 0
		else
			return 1
		fi
	fi
	
	local URL0="$(_url_but_fragment "$URL")"
	
	local SIMURL="$URL0"
	local SIMURLs=()
	
	if [[ "$URL" != "urls" ]]; then
		HASH=$(_hash "$URL" 2>/dev/null)
	fi
	
	if [[ "$HASH" != "" ]]; then
		local MFS_PAGE_ADDR="/MiceWeb/pages/$HASH"
		_safe ipfs files ls /$MFS_PAGE_ADDR/URL.txt >/dev/null
		if [ $? -ne 0 ]; then
			if _check_url "$URL"; then
				_safe ipfs files mkdir //MiceWeb
				_safe ipfs files mkdir //MiceWeb/pages
				_safe ipfs files mkdir /$MFS_PAGE_ADDR
				local URLTXTCID="$(printf "%s\n%s\n" "URL $(_random_value)" "$URL" | _safe_with_warnings ipfs add --quieter --pin=false)"
				_safe_with_warnings ipfs files cp //ipfs/$URLTXTCID /$MFS_PAGE_ADDR/URL.txt
			else
				_echo_supported_url_prefixes
				return 1
			fi
		fi
		_safe ipfs files mkdir //MiceWeb
		_safe ipfs files mkdir //MiceWeb/presents
		local DT=$(_current_timestamp)
		local MFS_PRESENT_ADDR="/MiceWeb/presents/present-$DT"
		_safe ipfs files mkdir /$MFS_PRESENT_ADDR
		for I in $(_similar "$URL" 2>/dev/null)
		do
			local SIMHASH=$(_hash "$I")
			if _safe ipfs files cp //MiceWeb/pages/$SIMHASH /$MFS_PRESENT_ADDR/$SIMHASH; then
				if [[ "$I" != "$URL0" ]]; then
					SIMURL="$I"
					SIMURLs+=("$I")
					((CNT++))
				fi
				
			fi
		done
		if _has_url_fragment "$URL"; then
			local SIMHASH=$(_hash_string "$URL")
			if _safe ipfs files cp //MiceWeb/pages/$SIMHASH /$MFS_PRESENT_ADDR/$SIMHASH; then
				SIMURLs+=("$URL")
				((CNT++))
			fi
		fi
		CID0="$(_safe_with_warnings ipfs files stat --hash /$MFS_PRESENT_ADDR)"
		if [[ $CID0 == "QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn" ]]; then
			_exit_1 echo "Error: unexpected error, try again"
		fi
		CID="$CID0/$HASH"
	else
		local MFS_PRESENT_ADDR="/MiceWeb/pages/"
		CID0="$(_safe ipfs files stat --hash /$MFS_PRESENT_ADDR)"
		CID="$CID0"
	fi
	
	if [[ "$CID" != "" ]]; then
		echo "/ipfs/$CID"
		local STAT=""
		local COUNT=0
		if [ "$HASH" != "" ]; then
			for I in $(_safe_with_warnings ipfs files ls //MiceWeb/pages/$HASH); do
				if [[ $I != *.* ]]; then
					((COUNT++))
				fi
			done
			STAT="NumVersions: $COUNT"
			if [[ $CNT -eq 0 && $COUNT -eq 0 ]]; then
				>&2 echo ""
				>&2 echo "There are no snapshots to view"
				return 0
			fi
			>&2 echo ""
			if [ "$GATEWAY" != "" ]; then
				>&2 _print_with_hyperlink "Open " "$GATEWAY/ipfs/$CID" " in a browser on the local machine"
				if [[ "$REPROVIDING" == "all" || "$REPROVIDING" == "" ]]; then
					local converted="$(_safe ipfs cid format -v 1 -b base32 $CID0)"
					if [[ "$converted" != "" ]]; then
						>&2 _print_with_hyperlink " or " "ipfs://$converted/$HASH" " in an IPFS friendly browser"
					fi
					>&2 _print_with_hyperlink " to view " "$URL0" " snapshots"
				else
					>&2 _print_with_hyperlink " to view " "$URL0" " snapshots"
					>&2 echo ""
					>&2 echo "If you need to publish or view from an other machine,"
					>&2 echo " run 'ipfs pin add $CID0'"
					#if [[ "$REPROVIDING" == "roots" ]]; then
					#	>&2 echo " and 'ipfs config Reprovider.Strategy pinned'"
					#fi
				fi
			else
				_tip_run_ipfs_daemon
			fi
		else
			>&2 echo ""
			>&2 echo "There is a content identifier of current pages of all the MiceWeb library"
			>&2 echo "It's not recommended to share it because security and other reasons,"
			>&2 echo " however, if you need it, pin $CID0"
			#if [[ "$REPROVIDING" == "roots" ]]; then
			#	>&2 echo " and run 'ipfs config Reprovider.Strategy pinned'"
			#fi
			>&2 echo ""
			if [ "$GATEWAY" != "" ]; then
				>&2 _print_with_hyperlink "Open " "$GATEWAY/ipfs/$CID" ""
				>&2 echo " in a browser on the local machine to view snapshots"
			else
				_tip_run_ipfs_daemon
			fi
			COUNT=$(_safe_with_warnings ipfs files ls //MiceWeb/pages | grep ^[0-9a-f] | wc -l)
			STAT="NumURLs: $COUNT"
		fi
		>&2 echo ""
		>&2 echo "$STAT"
		if [ "$HASH" != "" ]; then
			local PAYATT=""
			if [ $CNT -ge 2 ]; then
				PAYATT="There are similar URLs found in the MiceWeb library:"
			elif [ $CNT -eq 1 ]; then
				PAYATT="There is a similar URL found in the MiceWeb library:"
			fi
			if [ "$PAYATT" != "" ]; then
				>&2 echo ""
				>&2 echo $PAYATT
				for I in "${SIMURLs[@]}"; do
					>&2 echo "$I"
				done
			fi
		fi
	else
		#TODO: fix and implement something like >&2 echo "Run 'miceweb save ${@@Q}'"
		return 1
	fi
}

# remove ######################################################################

describe "remove" <<HEREDOC
Usage:
  ${_ME} remove <snapshot>

Description:
  Remove saved snapshot
HEREDOC
remove() {
	_upgrade
	local SNAP="$1"
	if [[ "$SNAP" =~ ^[0-9a-f]{40}/[0-9]{8}GMT[0-9]{6}-. ]]; then
		if [[ "$SNAP" != *.* ]]; then
			local MFS_SNAP_ADDR="/MiceWeb/pages/$SNAP"
			if ! _remove_file $MFS_SNAP_ADDR; then
				_remove_dir $MFS_SNAP_ADDR
			fi
			if [[ "$SNAP" == *-import ]]; then
				if ! _remove_file "$MFS_SNAP_ADDR"ing; then
					_remove_dir "$MFS_SNAP_ADDR"ing
				fi
			fi
			_remove_file "$MFS_SNAP_ADDR.log"
			return 0
		fi
	elif [[ "$SNAP" =~ ^[13][a-km-zA-HJ-NP-Z1-9]{25,34}/[0-9]{8}GMT[0-9]{6}-zite$ ]]; then
		local MFS_SNAP_ADDR="/MiceWeb/zites/$SNAP"
		if ! _remove_file $MFS_SNAP_ADDR; then
			_remove_dir $MFS_SNAP_ADDR
		fi
		_remove_file "$MFS_SNAP_ADDR.log"
		return 0
	fi
	>&2 echo "This command requires snapshot as a parameter"
	return 1
}

# request #####################################################################

describe "request" <<HEREDOC
Usage:
  ${_ME} request <URL>
  ${_ME} request <SHA-1>

Description:
  Request web page snapshots from remote sources
HEREDOC
request() {
	_upgrade
	local URL="$(_url_but_fragment "$1")"
	if [[ "$URL" == "" ]]; then
		>&2 echo "This command requires URL or SHA-1 as a parameter"
		return 1
	fi
	if [[ "$1" =~ ^[0-9a-f]{40}$ ]]; then
		URL=$(url "$1")
		if [[ "$URL" == "" ]]; then
			return 1
		fi
	fi
	if ! _check_url "$URL"; then
		_echo_supported_url_prefixes
		return 1
	fi
	>&2 echo "Run following commands 'miceweb <parameters>' to obtain snapshots"
	if _command_exists wayback_machine_downloader; then
		if _command_exists jq; then
			if [[ $URL == http://* || $URL == https://* || $URL == ipns://* ]]; then
				>&2 echo ""
				>&2 echo "Requesting snapshots from the Wayback Machine..."
				if [[ "$1" =~ ^[0-9a-f]{40}$ ]]; then
					if [[ $URL == http*://* ]]; then
						local HASH=$1
						for I in $(wayback_machine_downloader -s -e -l "$URL" 2>/dev/null | jq --raw-output '.. | .timestamp? | strings'); do
							echo "miceweb save $HASH/${I:0:8}GMT${I:8:6}-archive"
						done
					fi
				else
					local URL_arc=$URL
					if [[ $URL == http://* ]]; then
						URL_arc="https://${URL#http://}"
					elif [[ $URL == ipns://* ]]; then
						URL_arc="https://${URL#ipns://}"
					fi
					for URL_concrete in $(_similar_concrete $URL_arc)
					do
						if [[ "$URL_concrete" == "$URL_arc" ]]; then
							if [[ $URL == http://* ]]; then
								URL_concrete=$URL
							fi
						fi
						local HASH=$(hash "$URL_concrete")
						for I in $(wayback_machine_downloader -s -e -l "$URL_concrete" 2>/dev/null | jq --raw-output '.. | .timestamp? | strings'); do
							echo "miceweb save $HASH/${I:0:8}GMT${I:8:6}-archive"
						done
					done
				fi
				>&2 echo "Done"
			fi
		else
			>&2 _print_with_hyperlink "Error: jq is not installed (seeing " "https://stedolan.github.io/jq/download/" ")"
		fi
	else
		>&2 echo "Error: wayback_machine_downloader is not installed"
	fi
}

# resolve #####################################################################

describe "resolve" <<HEREDOC
Usage:
  ${_ME} resolve /ipns/<cid-of-libp2p-key>
  ${_ME} resolve /ipns/<domain>
  ${_ME} resolve /zeronet/<domain>
  
Description:
  Resolve dynamic path to direct path
HEREDOC
resolve() {
	_upgrade
	if [[ $1 == /ipns/* ]]; then
		_resolve_ipns "${1#/ipns/}" | awk -v PREFIX="/ipfs/" '{print PREFIX $0}'
		return 0
		#TODO: show history in stderr?
		#local DOMAIN=$(echo "$1" | awk -F/ '{print $1}')
		#for I in $(_safe_with_warnings ipfs files ls //MiceWeb/resolves/ipns/$DOMAIN)
		#do
		#	echo ${I%.txt} $(_safe_with_warnings ipfs files read //MiceWeb/resolves/ipns/$DOMAIN/$I | sed -n 2p)
		#done
	elif [[ $1 == /zeronet/* ]]; then
		_resolve_zeronet "${1#/zeronet/}" | awk -v PREFIX="/zeronet/" '{print PREFIX $0}'
		return 0
	else
		help resolve 1>&2
	fi
	return 1
}

# save ########################################################################

describe "save" <<HEREDOC
Usage:
  ${_ME} save <URL>
  ${_ME} save <SHA-1>
  ${_ME} save <SHA-1>/<timestamp>-archive
  ${_ME} save urls [--grep=<expression>] [<local/ipfs/ipns/zeronet file path>]
  ${_ME} save <zite>
  ${_ME} save zites [<local/ipfs/ipns/zeronet file path>]

Description:
  Save web page snapshot(s)
  Save zite snapshot(s)
HEREDOC
save() {
	if [[ "$1" != "--no-warnings" ]]; then
		_upgrade
	fi
	#TODO: --archives={default|none|last|set}
	if [[ "$1" == "urls" ]]; then
		#TODO: add "urls ..." to history.txt?
		_reproviding_warning
		if ! _command_exists torsocks; then
			>&2 echo "Error: torsocks is not installed, some web pages might be inaccessible"
		fi
		#TODO: hash all valid urls, sort the list, then download?
		local URLs=$(urls --no-warnings "$2" "$3" "$4" "$5" "$6" "$7") #$("$0" "$@" 2>/dev/null)
		local count=0	#echo ${#URLs[@]}
		for I in $URLs; do
			((count++))
		done
		local index=0
		for I in $URLs; do
			((index++))
			if _check_url "$I"; then
				#TODO: at first, save pages which have no snapshots
				#local VERSIONS_COUNT=$(_versions "$(_url_but_fragment $I)" | grep -e "^.*-wget$" -e "^.*-wget-tor$" -e "^.*-wget-ip.s$" | wc -l)
				#if [ "$VERSIONS_COUNT" -eq 0 ]; then
				if ! _check_free_space_for_temp
				then
					>&2 echo "Free disk space for temporary files and run the command again"
					return 1
				fi
				local PAGE_HASH=$(hash "$I")
				if [[ "$PAGE_HASH" != "" ]]; then
					>&2 echo -n "Saving $I ($index of $count)"
					local rnumber=$((RANDOM%11+5))
					#TODO: wait just 3 seconds, plus something dependent from time spent on previous saving
					for (( i = 1; i <= $rnumber; i++ )) ; do
						sleep 1
						>&2 echo -n "."
					done
					>&2 echo ""
					save --no-warnings $PAGE_HASH
				fi
			fi
		done
		#TODO: fix and implement something like >&2 echo "Run 'miceweb present $@' to view saved snapshots"
		return 0
	elif [[ "$1" == "zites" ]]; then
		local datadir="$(_zeronet_data)"
		if [[ -d "$datadir" ]]; then
			_reproviding_warning
			if [[ "$2" == "" ]]; then
				for ZITE in $(zites); do
					save --no-warnings $ZITE
				done
			else
				for ZITE in $(zites "$2")	#$("$0" "$@" 2>/dev/null)
				do
					save --no-warnings $ZITE
				done
			fi
			return 0
		else
			>&2 echo "Error: '$datadir' not found,"
			>&2 echo " check ZERONET_PATH environment variable"
			return 1
		fi
	fi
	local SOMETHING=""
	local _arguments=()
	local _warnings=1
	local _val=
	for __arg in "${@:-}"
	do
	case ${__arg} in
	  --no-warnings)
		_warnings=0
		;;
	  -*)
		_exit_1 printf "Unexpected option: %s\\n" "${__arg}"
		;;
	  *)
		if _blank "${SOMETHING}"
		then
		  _val="${__arg}"
		  SOMETHING="$_val"
		else
		  _arguments+=("${__arg}")
		fi
		;;
	esac
	done
	if [[ "$SOMETHING" == "" ]]; then
		help save 1>&2
		return 1
	fi
	local URL="$SOMETHING"
	if [[ "$SOMETHING" =~ ^[0-9a-f]{40}/[0-9]{8}GMT[0-9]{6}-. ]]; then
		if [[ "$SOMETHING" =~ ^[0-9a-f]{40}/[0-9]{8}GMT[0-9]{6}-archive$ ]]; then
			local SNAP="$SOMETHING"
			local HASH=${SNAP:0:40}
			URL=$(url "$HASH")
			if [[ "$URL" == "" ]]; then
				return 1
			fi
			if [ $_warnings -eq 1 ]; then
				_reproviding_warning
			fi
			if _initiate_saving_url $URL; then
				_save_archived_snapshot $URL ${SNAP:41}
			fi
			return $?
		else
			>&2 echo "Only 'archive' snapshot can be specifically saved"
			return 1
		fi
	elif [[ "$SOMETHING" =~ ^[0-9a-f]{40}$ ]]; then
		URL=$(url "$SOMETHING")
		if [[ "$URL" == "" ]]; then
			return 1
		fi
	elif [[ "$SOMETHING" =~ ^[13][a-km-zA-HJ-NP-Z1-9]{25,34}$ ]]; then
		local datadir="$(_zeronet_data)"
		if [[ -d "$datadir" ]]; then
			if [ $_warnings -eq 1 ]; then
				_reproviding_warning
			fi
			#TODO: warn when ZeroNet node works?
			SAVE_HASH=$SOMETHING
			_safe ipfs files mkdir //MiceWeb
			_safe ipfs files mkdir //MiceWeb/zites
			SAVE_MFS_ADDR="/MiceWeb/zites/$SAVE_HASH"
			_safe ipfs files mkdir /$SAVE_MFS_ADDR
			_save_zite $SAVE_HASH
			return $?
		else
			if [ $_warnings -eq 1 ]; then
				>&2 echo "Error: '$datadir' not found,"
				>&2 echo " check ZERONET_PATH environment variable"
			fi
			return 1
		fi
	fi
	if ! _check_url "$URL"; then
		_echo_supported_url_prefixes
		return 1
	fi
	_addToHistory "$URL"
	type -P wget &>/dev/null && ISINST=1 || ISINST=0
	if [ $ISINST -eq 0 ]
	then
		>&2 echo "Error: wget is not installed"
		return 127
	fi
	if [ $_warnings -eq 1 ]; then
		_reproviding_warning
	fi
	local URL0=$(_url_but_fragment "$URL")
	if _initiate_saving_url $URL; then
		if _check_free_space_for_temp
		then
			PARSEDPATH=$(_parse_path $URL)
			if [[ $URL == ipns://* ]]; then
				if ! _save_wget_ipns "${URL#ipns://}"; then
					if [[ ! "$SOMETHING" =~ ^[0-9a-f]{40}$ ]]; then
						local SIMILAR_HASH=$(hash "https://${URL#ipns://}")
						if [[ "$SIMILAR_HASH" != "" ]]; then
							"$0" save --no-warnings $SIMILAR_HASH #2> >(grep --line-buffered .) # | awk '!a[$0]++; fflush()'
						fi
					fi
				fi
			elif [[ $URL == ipfs://* ]]; then
				_save_wget_ipfs "${URL#ipfs://}"
			elif [[ $URL == gemini://* ]]; then
				if _command_exists gemget; then
					_save_gemget $URL
				else
					>&2 _print_with_hyperlink "Error: " "https://github.com/makeworld-the-better-one/gemget" " is not installed"
				fi
			elif [[ $URL == gopher://* ]]; then
				if ! _save_curl $URL; then
					if _command_exists torsocks; then
						_save_curl_tor $URL
					fi
				fi
			elif [[ $URL == git://* ]]; then
				_save_git $URL
			else
				if [[ $URL == https://* ]]; then
					_save_media $URL
					_save_playlist $URL
				fi
				_save_wget $URL
				local WGETERR=$?
				local ININET= ; [[ $URL != http://127.0.0.1:* && $URL != http://localhost:* ]] ; ININET=$?
				if [ $WGETERR -ne 1 ]; then
					if [[ $URL == http* ]]; then
						_save_git $URL
					fi
				fi
				if [ $WGETERR -ne 0 ]; then
					if [ $WGETERR -le 4 ]; then
						if [ $ININET -eq 0 ]; then
							if _command_exists torsocks; then
								_save_wget_tor $URL
								local WGETERR_TOR=$?
								if [ $WGETERR_TOR -eq 0 ]; then
									WGETERR=9
								elif [ $WGETERR_TOR -ge 4 ]; then
									WGETERR=$WGETERR_TOR
								fi
							else
								if [ $_warnings -eq 1 ]; then
									>&2 echo "Error: torsocks is not installed"
								fi
							fi
						fi
					fi
					if [ $WGETERR -lt 4 ]; then
						if [ $ININET -eq 0 ]; then
							if ! _save_curl $URL; then
								if _command_exists torsocks; then
									_save_curl_tor $URL
								fi
							fi
						fi
						if [ $WGETERR -lt 3 ]; then
							if [[ $URL == http*://* ]]; then
								if [[ ! "$SOMETHING" =~ ^[0-9a-f]{40}$ ]]; then
									local wos=""
									local SIMILAR_HASH=""
									if [[ $URL == https://* ]]; then
										wos=${URL#https://}
										#SIMILAR_HASH=$(hash "http://$wos")
										#if [[ "$SIMILAR_HASH" != "" ]]; then
										#	"$0" save --no-warnings $SIMILAR_HASH #2> >(grep --line-buffered .) | awk '!a[$0]++; fflush()'
										#fi
									elif [[ $URL == http://* ]]; then
										wos=${URL#http://}
									fi
									local DOMAIN=$(echo "$wos" | awk -F/ '{print $1}')
									if _safe ipfs name resolve --recursive=false --timeout=5s $DOMAIN >/dev/null; then	#TODO: use fast version of _resolve_ipns (timeout=5s, recursive=false)
										SIMILAR_HASH=$(hash "ipns://$wos")
										if [[ "$SIMILAR_HASH" != "" ]]; then
											"$0" save --no-warnings $SIMILAR_HASH #2> >(grep .)
										fi
									fi
									if [ $ININET -eq 0 ]; then
										_save_archived $URL
									fi
								else
									if [ $ININET -eq 0 ]; then
										_save_archived $URL
									fi
								fi
							fi
						fi
					fi
					if [[ ! "$SOMETHING" =~ ^[0-9a-f]{40}$ ]]; then
						local wos=""
						local SIMILAR_HASH=""
						#TODO: replace it with saving similar links ipfs:// and ipns://, created snapshots should be available from here
						if [[ $URL == http*://*.*/ipfs/* ]]; then
							wos="${PARSEDPATH#/ipfs/}"
							_save_wget_ipfs $wos
						elif [[ $URL == http*://*.*/ipns/* ]]; then
							wos="${PARSEDPATH#/ipns/}"
							_save_wget_ipns $wos
						fi
					fi
				fi
				if [[ $URL == http://127.0.0.1:43110/* ]]; then
					if [[ ! "$SOMETHING" =~ ^[0-9a-f]{40}$ ]]; then
						local ext=$(_parse_extension "$URL")
						local wos=""
						local SIMILAR_HASH=""
						if [[ $ext == htm || $ext == html || $URL == */ ]]; then
							if [[ $URL != http://127.0.0.1:43110/raw/* ]]; then
								wos=${URL#http://127.0.0.1:43110/}
								SIMILAR_HASH=$(hash "http://127.0.0.1:43110/raw/$wos")
								if [[ "$SIMILAR_HASH" != "" ]]; then
									"$0" save --no-warnings $SIMILAR_HASH
								fi
							fi
						elif [[ $ext == bit || $ext == yo || $ext == zn || $ext == inf || $ext == yu || $ext == of || $ext == list || "$ext" == "" ]]; then
							if [[ $URL != http://127.0.0.1:43110/raw/* ]]; then
								wos=${URL#http://127.0.0.1:43110/}
								SIMILAR_HASH=$(hash "http://127.0.0.1:43110/raw/$wos/")
								if [[ "$SIMILAR_HASH" != "" ]]; then
									"$0" save --no-warnings $SIMILAR_HASH
								fi
							else
								SIMILAR_HASH=$(hash "$URL/")
								if [[ "$SIMILAR_HASH" != "" ]]; then
									"$0" save --no-warnings $SIMILAR_HASH
								fi
							fi
						fi
						#TODO: since implemented saving zites as a separate mechanism, created snapshots should be available from there
						#TODO: look into http://127.0.0.1:43110/1LtvsjbtQ2tY7SCtCZzC4KhErqEK3bXD4n/ (working with .db)
						local ZITE=$(_zite_address $URL)
						if [[ "$ZITE" =~ ^[13][a-km-zA-HJ-NP-Z1-9]{25,34}$ ]]; then
							>&2 echo "Tip: run 'miceweb save $ZITE'"
						fi
					fi
				fi
			fi
		else
			>&2 echo "Error: insufficient disk space for temporary files"
			return 1
		fi
	else
		return 1
	fi
}

# snapshots ###################################################################

describe "snapshots" <<HEREDOC
Usage:
  ${_ME} snapshots <URL>
  ${_ME} snapshots <SHA-1>
  ${_ME} snapshots <zite>

Description:
  List saved versions of web pages (including similar) by URL
  List saved versions of web page by SHA-1
  List saved versions of zite by bitcoin address
HEREDOC
snapshots() {
	if [[ "$1" == "" ]]; then
		>&2 echo "This command requires URL or SHA-1 or zite as a parameter"
		return 1
	fi
	if [[ "$1" =~ ^[13][a-km-zA-HJ-NP-Z1-9]{25,34}$ ]]; then
		local ZITE=$1
		_safe ipfs files ls //MiceWeb/zites/$ZITE | sed 's/^/'"$ZITE"'\//'
		return $?
	fi
	local URL="$1"
	if [[ "$1" =~ ^[0-9a-f]{40}$ ]]; then
		URL=$(url "$1")
		if [[ "$URL" == "" ]]; then
			return 1
		fi
		_versions "$URL"
		return 0
	fi
	if _check_url "$URL"; then
		for I in $(_similar "$URL" 2>/dev/null)
		do
			_versions "$I"
		done
		if _has_url_fragment "$URL"; then
			_versions "$URL"
		fi
	else
		_echo_supported_url_prefixes
		return 1
	fi
}

# talks #######################################################################

describe "talks" <<HEREDOC
Usage:
  ${_ME} talks

Description:
  Welcome to MiceWeb Talks in ZeroNet
HEREDOC
talks() {
	if ! wget "http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/uimedia/all.css?rev=1270494604" --timeout=1 --tries=1 --output-document=- &>/dev/null; then
		>&2 echo "Run a local ZeroNet node,"
		>&2 _print_with_hyperlink " seeing " "https://github.com/ZeroNetX/ZeroNet#user-content-how-to-join"
		>&2 _print_with_hyperlink " or " "https://github.com/zeronet-conservancy/zeronet-conservancy#how-to-join"
		>&2 echo ""
	fi
	_print_with_hyperlink "" "http://127.0.0.1:43110/$_SITE_ADDRESS/?Main"
}

# url #########################################################################

describe "url" <<HEREDOC
Usage:
  ${_ME} url <SHA-1>

Description:
  Return URL by SHA-1 hash
HEREDOC
url() {
	_upgrade
	if [[ ! "$1" =~ ^[0-9a-f]{40}$ ]]; then
		>&2 echo "This command requires SHA-1 hash as a parameter"
		return 1
	fi
	local CACHE_FILE="$HOME/.miceweb/cache/urls/$1"
	local URL=$(grep "" "$CACHE_FILE" 2>/dev/null)
	if [[ "$URL" != "" ]]; then
		local HASH=$(_hash "$URL")
		if [[ "$1" == "$HASH" ]]; then
			echo "$URL"
			return 0
		fi
	fi
	URL=$(_safe_with_warnings ipfs files read //MiceWeb/pages/$1/URL.txt | sed -n 2p)
	if [[ "$URL" != "" ]]; then
		local HASH=$(_hash "$URL")
		if [[ "$1" == "$HASH" ]]; then
			echo "$URL" > "$CACHE_FILE"
			echo "$URL"
			return 0
		fi
	fi
	return 1
}

# urls ########################################################################

describe "urls" <<HEREDOC
Usage:
  ${_ME} urls [--grep=<expression>] [<local/ipfs/ipns/zeronet file path>]
  ${_ME} urls --format={txt|json|xml|html} <local/ipfs/ipns/zeronet file path>

Description:
  List URLs from file (text or json or xml or html) or from the MiceWeb library
HEREDOC
urls() {
	_upgrade
	local FIL=""
	local PARAM=""
	local GREP=""
	local BASE=""
	local FORMAT=""
	local _warnings=1
	for I in "$@"; do
		if [[ $I == "--grep" ]]; then
			PARAM="grep"
		elif [[ $I == "--base" ]]; then
			PARAM="base"
		elif [[ $I == "--format" ]]; then
			PARAM="format"
		elif [[ $I == "--no-warnings" ]]; then
			_warnings=0
			PARAM=""
		elif [[ $I != "" ]]; then
			if [[ $PARAM == "grep" ]]; then
				GREP=$I
			elif [[ $PARAM == "base" ]]; then
				BASE=$I
			elif [[ $PARAM == "format" ]]; then
				FORMAT=$I
			else
				FIL=$I
			fi
			PARAM=""
		fi
	done
	if [[ "$FIL" == "" ]]; then
		if [ $_warnings -eq 1 ]; then
			>&2 echo "This command takes file path as a parameter:"
			>&2 echo " txt - contain URLs in separate lines"
			>&2 echo " json - contain URLs in text fields"
			>&2 echo " xml - contain URLs in text fields"
			>&2 echo " htm, html - contain URLs in the 'href' attribute"
			>&2 echo ""
		fi
		local CID="$(_safe ipfs files stat --hash //MiceWeb/pages/)"
		if [[ "$CID" != "" ]]; then
			local CACHE_DIR="$HOME/.miceweb/cache/urls/"
			mkdir -p "$CACHE_DIR"
			if declare -A URLs 2>/dev/null; then
				if [ $_warnings -eq 1 ]; then
					>&2 echo "There are URLs already in the MiceWeb library (see also 'miceweb history'):"
				fi
				local HT="$HOME/.miceweb/cache/urls.hashtable"
				if [ -e "$HT" ]; then
					while read line
					do
						local LINE_ARR=($line)
						local LINE_HASH=${LINE_ARR[0]}
						local LINE_URL=${LINE_ARR[1]}
						if [[ $LINE_HASH != "" && $LINE_URL != "" ]]; then
							URLs["$LINE_HASH"]="$LINE_URL"
						fi
					done < "$HT"
				else
					>&2 echo "Warning: it could be slowly, at first"
				fi
				for I in $(_safe_with_warnings ipfs files ls //MiceWeb/pages/ | grep ^[0-9a-f]); do
					local URL="${URLs[$I]}"
					if [[ "$URL" != "" ]]; then
						echo "$URL"
					else
						URL=$(grep "" "$CACHE_DIR$I" 2>/dev/null)
						if [[ "$URL" == "" ]]; then
							URL=$(_safe ipfs cat $CID/$I/URL.txt | sed -n 2p)
						fi
						if [[ "$URL" != "" ]]; then
							echo "$URL"
							printf "%s\t%s\n" "$I" "$URL" >> "$HT"
						fi
					fi
				done | grep "$GREP"
			else
				>&2 echo "Warning: installed Bash v.$BASH_VERSION is too old,"
				>&2 _print_with_hyperlink " seeing " "https://stackoverflow.com/questions/6047648" ","
				>&2 echo " consider to install newer Bash (v.4.0+) to significantly increase performance"
				if [ $_warnings -eq 1 ]; then
					>&2 echo ""
					>&2 echo "There are URLs already in the MiceWeb library (see also 'miceweb history'):"
				fi
				for I in $(_safe_with_warnings ipfs files ls //MiceWeb/pages/ | grep ^[0-9a-f]); do
					local CACHE_FILE="$CACHE_DIR$I"
					local URL=$(grep "" "$CACHE_FILE" 2>/dev/null)
					if [[ "$URL" != "" ]]; then
						echo "$URL"
					else
						URL=$(_safe ipfs cat $CID/$I/URL.txt | sed -n 2p)
						if [[ "$URL" != "" ]]; then
							echo "$URL" > "$CACHE_FILE"
							echo "$URL"
						fi
					fi
				done | grep "$GREP"
			fi
		else
			if [ $_warnings -eq 1 ]; then
				>&2 echo "The MiceWeb library has no pages"
			fi
		fi
		return
	fi
	if [[ "$FORMAT" == "" ]]; then
		FORMAT=$(_path_extension "$FIL")
	fi
	if [[ $FORMAT == htm || $FORMAT == html ]]; then
		type -P htmlq &>/dev/null && ISINST=1 || ISINST=0
		if [ $ISINST -eq 0 ]
		then
			>&2 _print_with_hyperlink "Error: htmlq is not installed (seeing " "https://github.com/mgdm/htmlq/" ")"
			exit 127
		fi
		if [[ "$BASE" != "" ]]; then
			_cat_file "$FIL" | htmlq --base="$BASE" --attribute href a | grep "$GREP" | awk '!a[$0]++; fflush()'
		else
			>&2 echo "Tip: use '--base' attribute to handle relative links"
			_cat_file "$FIL" | htmlq --detect-base --attribute href a | grep "$GREP" | awk '!a[$0]++; fflush()'
		fi
	elif [[ $FORMAT == json ]]; then
		if [[ "$BASE" != "" ]]; then
			>&2 echo "Attribute --base is only supported for html files"
			exit 1
		fi
		for I in $(_cat_json_file "$FIL" | sed -e 's/\.\ /\ /g' | sed -e 's/\,\ /\ /g' | sed -e 's/\;\ /\ /g'); do
			IFS=' ' read -ra IARR <<< "$I"
			for J in "${IARR[@]}"; do
				if _check_url "$J"; then
					echo "${J%.}"
				fi
			done
		done | grep "$GREP" | awk '!a[$0]++; fflush()'
	elif [[ $FORMAT == xml ]]; then
		if [[ "$BASE" != "" ]]; then
			>&2 echo "Attribute --base is only supported for html files"
			exit 1
		fi
		for I in $(_cat_xml_file "$FIL" | sed -e 's/\.\ /\ /g' | sed -e 's/\,\ /\ /g' | sed -e 's/\;\ /\ /g'); do
			IFS=' ' read -ra IARR <<< "$I"
			for J in "${IARR[@]}"; do
				if _check_url "$J"; then
					echo "${J%.}"
				fi
			done
		done | grep "$GREP" | awk '!a[$0]++; fflush()'
	else
		if [[ "$BASE" != "" ]]; then
			>&2 echo "Attribute --base is only supported for html files"
			exit 1
		fi
		_cat_file "$FIL" "$GREP" | awk '!a[$0]++; fflush()'
	fi
}

# version #####################################################################

describe "version" <<HEREDOC
Usage:
  ${_ME} version

Description:
  Display the current program version

  To save you the trouble, the current version is ${_SUB_VERSION}
HEREDOC
version() {
  printf "%s\\n" "${_SUB_VERSION}"
}

# zites #######################################################################

describe "zites" <<HEREDOC
Usage:
  ${_ME} zites
  ${_ME} zites <local/ipfs/ipns/zeronet file path>

Description:
  List zites from text file or from the MiceWeb library
HEREDOC
zites() {
	if [[ "$1" == "" ]]; then
		_safe ipfs files ls //MiceWeb/zites
		return $?
	fi
	for I in $(_cat_file "$1" "^1"); do
		local J="${I%/}"
		local K="${J%/}"
		if [[ "$K" =~ ^[13][a-km-zA-HJ-NP-Z1-9]{25,34}$ ]]; then
			echo $K
		fi
	done | awk '!a[$0]++; fflush()'
}


###############################################################################
# Run Program
###############################################################################

# Call the `_main` function after everything has been defined.
_main
