#!/usr/bin/env bash
###############################################################################
#
#                                                
# 88b           d88  88                           
# 888b         d888  ""                           
# 88`8b       d8'88                               
# 88 `8b     d8' 88  88   ,adPPYba,   ,adPPYba,   
# 88  `8b   d8'  88  88  a8"     ""  a8P_____88   
# 88   `8b d8'   88  88  8b          8PP"""""""   
# 88    `888'    88  88  "8a,   ,aa  "8b,   ,aa   
# 88     `8'     88  88   `"Ybbd8"'   `"Ybbd8"'   
#                                                
#                                                
#                                                
# I8,        8        ,8I            88           
# `8b       d8b       d8'            88           
#  "8,     ,8"8,     ,8"             88           
#   Y8     8P Y8     8P   ,adPPYba,  88,dPPYba,   
#   `8b   d8' `8b   d8'  a8P_____88  88P'    "8a  
#    `8a a8'   `8a a8'   8PP"""""""  88       d8  
#     `8a8'     `8a8'    "8b,   ,aa  88b,   ,a8"  
#      `8'       `8'      `"Ybbd8"'  8Y"Ybbd8"'   
#                                                
#
# Depends on:
#  https://docs.ipfs.io/install/command-line/
#  https://www.gnu.org/software/wget/
#  https://curl.se/
#  https://stedolan.github.io/jq/download/
#  https://github.com/mgdm/htmlq/
#  https://github.com/makeworld-the-better-one/gemget
#  https://github.com/yt-dlp/yt-dlp/
#. https://www.ffmpeg.org
#  https://gitlab.torproject.org/tpo/core/torsocks
#  https://github.com/ImportTaste/wayback-machine-downloader
#  https://git-scm.com/downloads
#  https://www.gnu.org/software/bash/
#
# MiceWeb: https://github.com/Robotizing/MiceWeb
#
# Copyright (c) 2022 Robotizing Networks • robotizing.net
###############################################################################

# Return value of a pipeline is the value of the last (rightmost) command to
# exit with a non-zero status, or zero if all commands in the pipeline exit
# successfully.
set -o pipefail

# Set $IFS to only newline and tab.
#
# http://www.dwheeler.com/essays/filenames-in-shell.html
IFS=$'\n\t'

###############################################################################
# Globals
###############################################################################

# $_ME
#
# This program's basename.
_ME="$(basename "${0}")"

# $_VERSION
#
# Manually set this to to current version of the program. Adhere to the
# semantic versioning specification: http://semver.org
_VERSION="0.3"

# The MiceWeb Threads
_SITE_ADDRESS="1MiceWebdn35s6pUd3EM54uNveUJNSHsMr"

# $DEFAULT_SUBCOMMAND
#
# The subcommand to be run by default, when no subcommand name is specified.
# If the environment has an existing $DEFAULT_SUBCOMMAND set, then that value
# is used.
DEFAULT_SUBCOMMAND="${DEFAULT_SUBCOMMAND:-help}"

_IPFS_FEATURES=""

SAVE_MFS_ADDR=""
SUBDIR=""

###############################################################################
# Debug
###############################################################################

# _debug()
#
# Usage:
#   _debug <command> <options>...
#
# Description:
#   Execute a command and print to standard error. The command is expected to
#   print a message and should typically be either `echo`, `printf`, or `cat`.
#
# Example:
#   _debug printf "Debug info. Variable: %s\\n" "$0"
__DEBUG_COUNTER=0
_debug() {
  if ((${_USE_DEBUG:-0}))
  then
    __DEBUG_COUNTER=$((__DEBUG_COUNTER+1))
    {
      # Prefix debug message with "bug (U+1F41B)"
      printf "🐛  %s " "${__DEBUG_COUNTER}"
      "${@}"
      printf "―――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――\\n"
    } 1>&2
  fi
}

###############################################################################
# Error Messages
###############################################################################

# _exit_1()
#
# Usage:
#   _exit_1 <command>
#
# Description:
#   Exit with status 1 after executing the specified command with output
#   redirected to standard error. The command is expected to print a message
#   and should typically be either `echo`, `printf`, or `cat`.
_exit_1() {
  {
    printf "%s " "$(tput setaf 1)!$(tput sgr0)"
    "${@}"
  } 1>&2
  exit 1
}

# _warn()
#
# Usage:
#   _warn <command>
#
# Description:
#   Print the specified command with output redirected to standard error.
#   The command is expected to print a message and should typically be either
#   `echo`, `printf`, or `cat`.
_warn() {
  {
    printf "%s " "$(tput setaf 1)!$(tput sgr0)"
    "${@}"
  } 1>&2
}

###############################################################################
# Utility Functions
###############################################################################

# _command_exists()
#
# Usage:
#   _command_exists <name>
#
# Exit / Error Status:
#   0 (success, true) If a command with <name> is defined in the current
#                     environment.
#   1 (error,  false) If not.
#
# Information on why `hash` is used here:
# http://stackoverflow.com/a/677212
_command_exists() {
  command hash "${1}" 2>/dev/null
}

# _contains()
#
# Usage:
#   _contains <query> <list-item>...
#
# Exit / Error Status:
#   0 (success, true)  If the item is included in the list.
#   1 (error,  false)  If not.
#
# Examples:
#   _contains "${_query}" "${_list[@]}"
_contains() {
  local _query="${1:-}"
  shift

  if [[ -z "${_query}"  ]] ||
     [[ -z "${*:-}"     ]]
  then
    return 1
  fi

  for __element in "${@}"
  do
    [[ "${__element}" == "${_query}" ]] && return 0
  done

  return 1
}

# _join()
#
# Usage:
#   _join <delimiter> <list-item>...
#
# Description:
#   Print a string containing all <list-item> arguments separated by
#   <delimeter>.
#
# Example:
#   _join "${_delimeter}" "${_list[@]}"
#
# More information:
#   https://stackoverflow.com/a/17841619
_join() {
  local _delimiter="${1}"
  shift
  printf "%s" "${1}"
  shift
  printf "%s" "${@/#/${_delimiter}}" | tr -d '[:space:]'
}

# _blank()
#
# Usage:
#   _blank <argument>
#
# Exit / Error Status:
#   0 (success, true)  If <argument> is not present or null.
#   1 (error,  false)  If <argument> is present and not null.
_blank() {
  [[ -z "${1:-}" ]]
}

# _interactive_input()
#
# Usage:
#   _interactive_input
#
# Exit / Error Status:
#   0 (success, true)  If the current input is interactive (eg, a shell).
#   1 (error,  false)  If the current input is stdin / piped input.
_interactive_input() {
  [[ -t 0 ]]
}

# _piped_input()
#
# Usage:
#   _piped_input
#
# Exit / Error Status:
#   0 (success, true)  If the current input is stdin / piped input.
#   1 (error,  false)  If the current input is interactive (eg, a shell).
_piped_input() {
  ! _interactive_input
}

###############################################################################
# describe
###############################################################################

# describe()
#
# Usage:
#   describe <name> <description>
#   describe --get <name>
#
# Options:
#   --get  Print the description for <name> if one has been set.
#
# Examples:
# ```
#   describe "list" <<HEREDOC
# Usage:
#   ${_ME} list
#
# Description:
#   List items.
# HEREDOC
#
# describe --get "list"
# ```
#
# Set or print a description for a specified subcommand or function <name>. The
# <description> text can be passed as the second argument or as standard input.
#
# To make the <description> text available to other functions, `describe()`
# assigns the text to a variable with the format `$___describe_<name>`.
#
# When the `--get` option is used, the description for <name> is printed, if
# one has been set.
#
# NOTE:
#
# The `read` form of assignment is used for a balance of ease of
# implementation and simplicity. There is an alternative assignment form
# that could be used here:
#
# var="$(cat <<'HEREDOC'
# some message
# HEREDOC
# )
#
# However, this form appears to require trailing space after backslases to
# preserve newlines, which is unexpected. Using `read` simply requires
# escaping backslashes, which is more common.
describe() {
  _debug printf "describe() \${*}: %s\\n" "$@"
  [[ -z "${1:-}" ]] && _exit_1 printf "describe(): <name> required.\\n"

  if [[ "${1}" == "--get" ]]
  then # get ------------------------------------------------------------------
    [[ -z "${2:-}" ]] &&
      _exit_1 printf "describe(): <description> required.\\n"

    local _name="${2:-}"
    local _describe_var="___describe_${_name}"

    if [[ -n "${!_describe_var:-}" ]]
    then
      printf "%s\\n" "${!_describe_var}"
    else
      printf "No additional information for \`%s\`\\n" "${_name}"
    fi
  else # set ------------------------------------------------------------------
    if [[ -n "${2:-}" ]]
    then # argument is present
      read -r -d '' "___describe_${1}" <<HEREDOC
${2}
HEREDOC
    else # no argument is present, so assume piped input
      # `read` exits with non-zero status when a delimeter is not found, so
      # avoid errors by ending statement with `|| true`.
      read -r -d '' "___describe_${1}" || true
    fi
  fi
}

###############################################################################
# Program Option Parsing
#
# NOTE: The `getops` builtin command only parses short options and BSD `getopt`
# does not support long arguments (GNU `getopt` does), so use custom option
# normalization and parsing.
#
# For a pure bash `getopt` function, try pure-getopt:
#   https://github.com/agriffis/pure-getopt
#
# More info:
#   http://wiki.bash-hackers.org/scripting/posparams
#   http://www.gnu.org/software/libc/manual/html_node/Argument-Syntax.html
#   http://stackoverflow.com/a/14203146
#   http://stackoverflow.com/a/7948533
#   https://stackoverflow.com/a/12026302
#   https://stackoverflow.com/a/402410
###############################################################################

# Normalize Options ###########################################################

# Source:
#   https://github.com/e36freak/templates/blob/master/options

# Iterate over options, breaking -ab into -a -b and --foo=bar into --foo bar
# also turns -- into --endopts to avoid issues with things like '-o-', the '-'
# should not indicate the end of options, but be an invalid option (or the
# argument to the option, such as wget -qO-)
unset options
# while the number of arguments is greater than 0
while ((${#}))
do
  case "${1}" in
    # if option is of type -ab
    -[!-]?*)
      # loop over each character starting with the second
      for ((i=1; i<${#1}; i++))
      do
        # extract 1 character from position 'i'
        c="${1:i:1}"
        # add current char to options
        options+=("-${c}")
      done
      ;;
    # if option is of type --foo=bar, split on first '='
    --?*=*)
      options+=("${1%%=*}" "${1#*=}")
      ;;
    # end of options, stop breaking them up
    --)
      options+=(--endopts)
      shift
      options+=("${@}")
      break
      ;;
    # otherwise, nothing special
    *)
      options+=("${1}")
      ;;
  esac

  shift
done
# set new positional parameters to altered options. Set default to blank.
set -- "${options[@]:-}"
unset options

# Parse Options ###############################################################

_SUBCOMMAND=""
_SUBCOMMAND_ARGUMENTS=()
_USE_DEBUG=0

while ((${#}))
do
  __opt="${1}"

  shift

  case "${__opt}" in
    -h|--help)
      _SUBCOMMAND="help"
      ;;
    --debug)
      _USE_DEBUG=1
      ;;
    *)
      # The first non-option argument is assumed to be the subcommand name.
      # All subsequent arguments are added to $_SUBCOMMAND_ARGUMENTS.
      if [[ -n "${_SUBCOMMAND}" ]]
      then
        _SUBCOMMAND_ARGUMENTS+=("${__opt}")
      else
        _SUBCOMMAND="${__opt}"
      fi
      ;;
  esac
done

###############################################################################
# Main
###############################################################################

# Declare the $_DEFINED_SUBCOMMANDS array.
_DEFINED_SUBCOMMANDS=()

# _main()
#
# Usage:
#   _main
#
# Description:
#   The primary function for starting the program.
#
#   NOTE: must be called at end of program after all subcommands are defined.
_main() {
  # If $_SUBCOMMAND is blank, then set to `$DEFAULT_SUBCOMMAND`
  if [[ -z "${_SUBCOMMAND}" ]]
  then
    _SUBCOMMAND="${DEFAULT_SUBCOMMAND}"
  fi

  for __name in $(declare -F)
  do
    # Each element has the format `declare -f function_name`, so set the name
    # to only the 'function_name' part of the string.
    local _function_name
    _function_name=$(printf "%s" "${__name}" | awk '{ print $3 }')

    if ! { [[ -z "${_function_name:-}"                      ]] ||
           [[ "${_function_name}" =~ ^_(.*)                 ]] ||
           [[ "${_function_name}" == "bats_readlinkf"       ]] ||
           [[ "${_function_name}" == "describe"             ]] ||
           [[ "${_function_name}" == "shell_session_update" ]]
    }
    then
      _DEFINED_SUBCOMMANDS+=("${_function_name}")
    fi
  done

  # If the subcommand is defined, run it, otherwise return an error.
  if _contains "${_SUBCOMMAND}" "${_DEFINED_SUBCOMMANDS[@]:-}"
  then
    # Pass all comment arguments to the program except for the first ($0).
    ${_SUBCOMMAND} "${_SUBCOMMAND_ARGUMENTS[@]:-}"
  else
	local SOMETHING="${_SUBCOMMAND}"
	local URL=""
	if [[ "$SOMETHING" =~ ^[0-9a-f]{40}$ ]]; then
		URL=$(url "$SOMETHING")
		if [ "$URL" == "" ]; then
			>&2 printf "\n"
			return 1
		fi
		_reprovidingWarning
		local SNAPS=$(save --no-warnings $SOMETHING | tee -a >(cat>&2))
		>&2 printf "\n"
		local SNAP=$(echo "$SNAPS" | sed -n '1p')
		if [[ "$SNAP" != "" ]]; then
			present "$SNAP"
			>&2 printf "\n"
			>&2 echo "Run 'miceweb present $SOMETHING' to view all saved snapshots"
		else
			>&2 echo "Try to run 'miceweb present $SOMETHING' to view snapshots, saved before"
		fi
		>&2 printf "\n"
		return 0
	elif [[ "$SOMETHING" =~ ^[0-9a-f]{40}/[0-9]{8}GMT[0-9]{6}-. ]]; then
		local SNAP="$SOMETHING"
		if [[ "$SNAP" =~ ^[0-9a-f]{40}/[0-9]{8}GMT[0-9]{6}-archive ]]; then
			local HASH=${SNAP:0:40}
			URL=$(url "$HASH")
			if [[ "$URL" != "" ]]; then
				if _initiate_saving_url $URL; then
					_save_archived_snapshot $URL ${SNAP:41} 1>/dev/null
				fi
			fi
		fi
		present "$SNAP"
		>&2 printf "\n"
		return 1
	fi
	URL="$SOMETHING"
	if _check_url "$URL"; then
		_save_and_present "$URL"
	else
		_exit_1 printf "Unknown command: %s\\n" "${_SUBCOMMAND}"
	fi
  fi
  if [[ "${_SUBCOMMAND_ARGUMENTS[0]}" != "--no-warnings" ]]; then
  	>&2 printf "\n"
  fi
}

# --------------------------------------------------------------------- functions

_addToHistory() {
	mkdir -p "$HOME/.miceweb"
	local DT=$(export TZ=GMT ; date '+%Y-%m-%d GMT %H:%M:%S')
	printf "%s\t%s\n" "$DT" "$1" >> "$HOME/.miceweb/history.txt"
}

_cat_file() {
	local FIL="$1"
	local GREP="$2"
	local ADDR=""
	if [[ "$FIL" == /ipns/* ]]; then
		ADDR=$(_resolve_ipns "${FIL#/ipns/}")
		ipfs cat "$ADDR" | grep -a "$GREP"
	elif [[ "$FIL" == /ipfs/* ]]; then
		ADDR="${FIL#/ipfs/}"
		ipfs cat "$ADDR" | grep -a "$GREP"
	elif [[ "$FIL" == /zeronet/* ]]; then
		ADDR=$(_resolve_zeronet "${FIL#/zeronet/}")
		if [[ $ADDR != "" ]]; then
			local datadir="$(_zeronet_data)"
			if [ -d "$datadir" ]; then
				local filename="$datadir/$ADDR"
				if [ -e "$filename" ]; then
					grep -a "$GREP" "$filename"
				else
					>&2 echo "Error: file not found, visit http://127.0.0.1:43110/$ADDR in a browser and try again"
					return 1
				fi
			else
				>&2 echo "Error: '$datadir' not found,"
				>&2 echo " check ZERONET_PATH environment variable"
				return 1
			fi
		else
			return 1
		fi
	else
		grep -a "$GREP" "$FIL"
	fi
	return $?
}

_cat_json_file() {
	if _command_exists jq; then
		_cat_file "$1" | jq --raw-output '.. | strings'
	else
		>&2 _print_with_hyperlink "Error: jq is not installed (seeing " "https://stedolan.github.io/jq/download/" ")"
		return 1
	fi
}

_check_free_space_for_temp() {
	if [ $(_free_space $(dirname $(mktemp -u 2>/dev/null || mktemp -u -t 'mytmpdir'))) -gt 102400 ]; then
		return 0
	else
		return 1
	fi
}

_check_url() {
	local URL="$1"
	if [[ "$URL" != http://* && "$URL" != https://* && "$URL" != gopher://* && "$URL" != gemini://* && "$URL" != ipns://* && "$URL" != ipfs://* && "$URL" != ftp://* && "$URL" != ftps://* ]]; then
		return 1
	else
		return 0
	fi
}

_echo_supported_url_prefixes() {
	#>&2 echo "Supported URL prefixes: http://, https://, ftp://, ftps://, ipns://, ipfs://"
	>&2 echo "Supported URL prefixes:"
	>&2 echo " http://, https://,"
	>&2 echo " gopher://,"
	>&2 echo " gemini://,"
	>&2 echo " ftp://, ftps://,"
	>&2 echo " ipns://, ipfs://"
}

_free_space() {
	echo $(df -Pk $1 | sed 1d | grep -v used | awk '{ print $4 "\t" }')
}

_has_url_fragment() {
	local URL="$1"
	if [[ "$URL" =~ ['#'] ]]; then
		return 0;
	else
		return 1;
	fi
}

_hash() {
	_hash_string "$(_url_but_fragment "$1")"
}

_hash_string() {
	local HASH=$(printf '%s' "$1" | sha1sum 2>/dev/null | cut -d' ' -f1)
	if [[ "$HASH" != "" ]]; then
		echo "$HASH"
	else
		HASH=$(printf '%s' "$1" | openssl sha1 -r 2>/dev/null | cut -d' ' -f1)
		if [[ "$HASH" != "" ]]; then
			echo "$HASH"
		else
			HASH=$(printf '%s' "$1" | shasum -a 1 2>/dev/null | cut -d' ' -f1)
			if [[ "$HASH" != "" ]]; then
				echo "$HASH"
			else
				_exit_1 printf "Installed sha1sum, shasum or openssl is required for MiceWeb\n"
			fi
		fi
	fi
}

_initiate_saving_url() {
	local URL="$1"
	SAVE_HASH=$(hash "$URL")
	if [[ "$SAVE_HASH" != "" ]]; then
		SAVE_MFS_ADDR="/MiceWeb/pages/$SAVE_HASH"
		return 0
	else
		return 1
	fi
}

_news() {
	if cat "$(_zeronet_data)/$_SITE_ADDRESS/news.txt" 2>/dev/null; then
		echo ""
		echo ""
	fi
	echo "Invintation:"
	echo "  Run 'miceweb discuss' to find answers together"
}

# https://www.rfc-editor.org/rfc/rfc3986#appendix-B
#
readonly URI_REGEX='^(([^:/?#]+):)?(//((([^:/?#]+)@)?([^:/?#]+)(:([0-9]+))?))?(/([^?#]*))(\?([^#]*))?(#(.*))?'
#                    ↑↑            ↑  ↑↑↑            ↑         ↑ ↑            ↑ ↑        ↑  ↑        ↑ ↑
#                    |2 scheme     |  ||6 userinfo   7 host    | 9 port       | 11 rpath |  13 query | 15 fragment
#                    1 scheme:     |  |5 userinfo@             8 :…           10 path    12 ?…       14 #…
#                                  |  4 authority
#                                  3 //…
_parse_scheme () {
    [[ "$@" =~ $URI_REGEX ]] && echo "${BASH_REMATCH[2]}"
}
_parse_authority () {
    [[ "$@" =~ $URI_REGEX ]] && echo "${BASH_REMATCH[4]}"
}
_parse_user () {
    [[ "$@" =~ $URI_REGEX ]] && echo "${BASH_REMATCH[6]}"
}
_parse_host () {
    [[ "$@" =~ $URI_REGEX ]] && echo "${BASH_REMATCH[7]}"
}
_parse_port () {
    [[ "$@" =~ $URI_REGEX ]] && echo "${BASH_REMATCH[9]}"
}
_parse_path () {
    [[ "$@" =~ $URI_REGEX ]] && echo "${BASH_REMATCH[10]}"
}
_parse_rpath () {
    [[ "$@" =~ $URI_REGEX ]] && echo "${BASH_REMATCH[11]}"
}
_parse_query () {
    [[ "$@" =~ $URI_REGEX ]] && echo "${BASH_REMATCH[13]}"
}
_parse_fragment () {
    [[ "$@" =~ $URI_REGEX ]] && echo "${BASH_REMATCH[15]}"
}

_parse_extension() {
	local rpath=$(_parse_rpath "$@")
	local LPC="${rpath##*/}"
	if [[ "$LPC" != "" ]]; then
		local extension="${LPC##*.}"
		if [[ "$LPC" != "$extension" ]]; then
			if [[ "$extension" != "" ]]; then
				echo "$extension"
			fi
		fi
	fi
}

_path_extension() {
	local filename="$@"
	extension="${filename##*.}"
	echo "$extension"
}

_print_hyperlink() {
	local URL="$1"
	local URLTEXT="$2"
	if [[ "$URLTEXT" == "" ]]; then
		URLTEXT="$URL"
	fi
	printf '\e]8;;%s\e\\%s\e]8;;\e\\' "$URL" "$URLTEXT"
}
_print_with_hyperlink() {
	local PREFIX="$1"
	local URL="$2"
	local SUFFIX="$3"
	printf '%s' "$PREFIX"
	_print_hyperlink "$URL"
	printf '%s\n' "$SUFFIX"
}

_random_value() {
	local chars=abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789
	for i in {1..32} ; do
		echo -n "${chars:RANDOM%${#chars}:1}"
	done
	echo
}

_remove_dir() {
	local DIRPATH="$1"
	local CID="$(ipfs files stat --hash /$DIRPATH)"
	if [[ "$CID" != "" ]]; then
		if ipfs files rm -r /$DIRPATH &>/dev/null; then
			echo "Removed $DIRPATH, you can try to undo that right now by running 'ipfs files cp /ipfs/$CID $DIRPATH'"
			return 0
		fi
	fi
	return 1
}
_remove_file() {
	local FILEPATH="$1"
	local CID="$(ipfs files stat --hash /$FILEPATH)"
	if [[ "$CID" != "" ]]; then
		if ipfs files rm /$FILEPATH &>/dev/null; then
			echo "Removed $FILEPATH, you can try to undo that right now by running 'ipfs files cp /ipfs/$CID $FILEPATH'"
			return 0
		fi
	fi
	return 1
}

_reprovidingWarning() {
	local REPROVIDING=$(ipfs config Reprovider.Strategy)
	if [[ "$REPROVIDING" == "all" ]]; then
		>&2 echo "Warning: the reprovider announces all IPFS data including the MiceWeb Library,"
		>&2 echo " consider to run 'ipfs config Reprovider.Strategy pinned', seeing"
		>&2 echo " https://github.com/ipfs/kubo/blob/master/docs/config.md#reproviderstrategy"
	fi
}

_resolve_ipns() {
	local DOMAIN=$(echo "$1" | awk -F/ '{print $1}')
	local ADDR=$(ipfs name resolve --recursive=true --timeout=60s $DOMAIN 2>/dev/null)
	local CID="${ADDR#/ipfs/}"
	if [[ $CID != "" ]]; then
		echo "$CID${1#$DOMAIN}"
		local DT=$(export TZ=GMT ; date '+%Y%m%dGMT%H%M%S')
		local LOGTXTADDR=""
		for I in $(ipfs files ls //MiceWeb/resolves/ipns/$DOMAIN 2>/dev/null | sort --reverse); do
			local PREVCID=$(ipfs files read //MiceWeb/resolves/ipns/$DOMAIN/$I | sed -n 2p)
			if [[ $PREVCID == $CID ]]; then
				LOGTXTADDR="/MiceWeb/resolves/ipns/$DOMAIN/$I"
				break
			fi
		done
		if [[ $LOGTXTADDR == "" ]]; then
			LOGTXTADDR="/ipfs/$(printf "%s\n%s\n" "CID $(_random_value)" "$CID" | ipfs add --quieter --pin=false)"
		fi
		if [[ $LOGTXTADDR != "" ]]; then
			ipfs files mkdir //MiceWeb/resolves 2>/dev/null
			ipfs files mkdir //MiceWeb/resolves/ipns 2>/dev/null
			ipfs files mkdir //MiceWeb/resolves/ipns/$DOMAIN 2>/dev/null
			ipfs files cp /$LOGTXTADDR //MiceWeb/resolves/ipns/$DOMAIN/$DT.txt
		fi
		return 0
	else
		for I in $(ipfs files ls //MiceWeb/resolves/ipns/$DOMAIN 2>/dev/null | sort --reverse); do
			CID=$(ipfs files read //MiceWeb/resolves/ipns/$DOMAIN/$I | sed -n 2p)
			if [[ $CID != "" ]]; then
				>&2 echo "Warning: could not resolve /ipns/$DOMAIN actually"
				echo "$CID${1#$DOMAIN}"
				return 0
			fi
		done
	fi
	>&2 echo "Error: could not resolve /ipns/$DOMAIN"
	return 1
}

_resolve_zeronet() {
	local MAIN=$(echo "$1" | awk -F/ '{print $1}')
	if [[ $MAIN == *.* ]]; then
		if ! _command_exists jq; then
			>&2 _print_with_hyperlink "Error: jq is not installed (seeing " "https://stedolan.github.io/jq/download/" ")"
			return 1
		fi
		local DOMAIN=$MAIN
		MAIN=$(wget http://127.0.0.1:43110/raw/$MAIN/content.json --timeout=1 --output-document=- 2>/dev/null | jq --raw-output '.address' 2>/dev/null)
		if [[ $MAIN == 1* ]]; then
			echo $MAIN"${1#$DOMAIN}"
			return 0
		elif [[ $MAIN == "" ]]; then
			>&2 echo "Error: running ZeroNet node is required to resolve such domains"
			return 1
		else
			>&2 echo "Error: not supported address /zeronet/$MAIN"
			return 1
		fi
	elif [[ $MAIN == 1* ]]; then
		echo $1
		return 0
	fi
	return 1
}

_save_and_present() {
	local URL="$1"
	_reprovidingWarning
	local URL0=$(_url_but_fragment "$URL")
	local SNAPS=$(save --no-warnings "$URL" | tee -a >(cat>&2))
	>&2 printf "\n"
	local SNAP=$(echo "$SNAPS" | sed -n '1p')
	if [[ "$SNAP" != "" ]]; then
		present "$SNAP"
		>&2 printf "\n"
		>&2 echo "Run 'miceweb present \"$URL0\"' to view all saved snapshots"
	else
		>&2 echo "Try to run 'miceweb present \"$URL0\"' to view snapshots, saved before"
	fi
}

_save_archived() {
	type -P wayback_machine_downloader &>/dev/null && ISINST=1 || ISINST=0
	if [ $ISINST -eq 0 ]
	then
		>&2 echo "Error: wayback_machine_downloader is not installed"
		return 127
	fi
	type -P jq &>/dev/null && ISINST=1 || ISINST=0
	if [ $ISINST -eq 0 ]
	then
		>&2 _print_with_hyperlink "Error: jq is not installed (seeing " "https://stedolan.github.io/jq/download/" ")"
		return 127
	fi
	local ADDR=""
	if [[ $1 == http://* ]]; then
		ADDR="${1#http://}"
	elif [[ $1 == https://* ]]; then
		ADDR="${1#https://}"
	else
		return 1
	fi
	local RET=1
	for I in $(wayback_machine_downloader -s -e -l "$1" 2>/dev/null | jq --raw-output '.. | .timestamp? | strings' | tail -n1); do
		SUBDIR="${I:0:8}GMT${I:8:6}-archive"
		ipfs files ls /$SAVE_MFS_ADDR/$SUBDIR &>/dev/null
		if [ $? -ne 0 ]; then
			_wget "https://web.archive.org/web/$I/$ADDR" --cut-dirs=3
			RET=$?
		else
			>&2 echo "Warning: $SUBDIR is already downloaded, doing nothing"
			echo "$SAVE_HASH/$SUBDIR"
			RET=0
		fi
	done
	return $RET
}
_save_archived_snapshot() {
	local URL="$1"
	local ADDR=""
	if [[ $URL == http://* ]]; then
		ADDR="${URL#http://}"
	elif [[ $URL == https://* ]]; then
		ADDR="${URL#https://}"
	else
		return 1
	fi
	local RET=1
	SUBDIR="$2"
	ipfs files ls /$SAVE_MFS_ADDR/$SUBDIR &>/dev/null
	if [ $? -ne 0 ]; then
		_wget "https://web.archive.org/web/${SUBDIR:0:8}${SUBDIR:11:6}/$ADDR" --cut-dirs=3
		RET=$?
	else
		>&2 echo "Warning: $SUBDIR is already downloaded, doing nothing"
		echo "$SAVE_HASH/$SUBDIR"
		RET=0
	fi
	return $RET
}
_save_curl() {
	local DT=$(export TZ=GMT ; date '+%Y%m%dGMT%H%M%S')
	SUBDIR="$DT-curl"
	ipfs files ls /$SAVE_MFS_ADDR/$SUBDIR &>/dev/null
	if [ $? -ne 0 ]; then
		local EMPTY="QmbFMke1KXqnYyBBWxB74N4c5SBnJMVAiMNRcGu6x1AwQH"
		local CID=$(curl --connect-timeout 60 -f "$1" 2>/dev/null | ipfs add --cid-version=0 --quieter --pin=false)
		if [[ "$CID" != "" && "$CID" != "$EMPTY" ]]; then
			ipfs files cp //ipfs/$CID /$SAVE_MFS_ADDR/$SUBDIR
			if [ $? -eq 0 ]; then
				echo "$SAVE_HASH/$SUBDIR"
				#TODO: make it better
				local sz=$(ipfs files stat --size /$SAVE_MFS_ADDR/$SUBDIR)
				if [ $sz -le 1024 ]; then
					local content=$(ipfs files read /$SAVE_MFS_ADDR/$SUBDIR)
					if [[ "$content" == "<meta http-equiv=\"refresh\" content=\"0; url="*"\">" ]]; then
						content="${content#<meta http-equiv=\"refresh\" content=\"0; url=}"
						content="${content%\">}"
						>&2 echo "Found redirect to $content, saving it"
						#TODO: avoid possible infinite recursions, and use 'save' function (but remember about global variables 'SAVE_MFS_ADDR' and 'SUBDIR')
						"$0" save --no-warnings "$content" #2> >(grep .)
					fi
				fi
				return 0
			fi
		else
			>&2 echo "Error: could not download '${SUBDIR:18}'"
		fi
		return 1
	else
		>&2 echo "$SUBDIR exists"
		return 0
	fi
}
_save_curl_tor() {
	local DT=$(export TZ=GMT ; date '+%Y%m%dGMT%H%M%S')
	SUBDIR="$DT-curl-tor"
	ipfs files ls /$SAVE_MFS_ADDR/$SUBDIR &>/dev/null
	if [ $? -ne 0 ]; then
		local EMPTY="QmbFMke1KXqnYyBBWxB74N4c5SBnJMVAiMNRcGu6x1AwQH"
		local CID=$(torsocks --isolate curl --connect-timeout 60 -f "$1" 2>/dev/null | ipfs add --cid-version=0 --quieter --pin=false)
		if [[ "$CID" != "" && "$CID" != "$EMPTY" ]]; then
			ipfs files cp //ipfs/$CID /$SAVE_MFS_ADDR/$SUBDIR
			if [ $? -eq 0 ]; then
				echo "$SAVE_HASH/$SUBDIR"
				#TODO: handle redirections like in _save_curl
				return 0
			fi
		else
			>&2 echo "Error: could not download '${SUBDIR:18}'"
		fi
		return 1
	else
		>&2 echo "$SUBDIR exists"
		return 0
	fi
}
_save_gemget() {
	local DT=$(export TZ=GMT ; date '+%Y%m%dGMT%H%M%S')
	SUBDIR="$DT-gemget"
	ipfs files ls /$SAVE_MFS_ADDR/$SUBDIR &>/dev/null
	if [ $? -ne 0 ]; then
		local EMPTY="QmbFMke1KXqnYyBBWxB74N4c5SBnJMVAiMNRcGu6x1AwQH"
		local CID=$(gemget --output=- "$1" 2>/dev/null | ipfs add --cid-version=0 --quieter --pin=false)
		if [[ "$CID" != "" && "$CID" != "$EMPTY" ]]; then
			ipfs files cp //ipfs/$CID /$SAVE_MFS_ADDR/$SUBDIR
			if [ $? -eq 0 ]; then
				echo "$SAVE_HASH/$SUBDIR"
				return 0
			fi
		else
			>&2 echo "Error: could not download '${SUBDIR:18}'"
		fi
		return 1
	else
		>&2 echo "$SUBDIR exists"
		return 0
	fi
}
_save_wget_ipfs() {
	local MAIN=$(echo "$1" | awk -F/ '{print $1}')
	local ADDR=$(ipfs resolve --timeout=60s $MAIN)
	if [[ "$ADDR" != "" ]]; then
		local DT=$(export TZ=GMT ; date '+%Y%m%dGMT%H%M%S')
		SUBDIR="$DT-wget-ipfs"
		ipfs files ls /$SAVE_MFS_ADDR/$SUBDIR &>/dev/null
		if [ $? -ne 0 ]; then
			local GATEWAY=$(ipfs config Addresses.Gateway)
			if [ "$GATEWAY" != "" ]; then
				_wget "http://127.0.0.1:${GATEWAY##*/}/ipfs/$1" --cut-dirs=2
				return $?
			else
				>&2 echo "Error: local IPFS gateway is not set"
			fi
		else
			>&2 echo "$SUBDIR exists"
			return 0
		fi
	fi
	return 1
}
_save_wget_ipns() {
	local ADDR=$(_resolve_ipns "$1")
	if [[ "$ADDR" != "" ]]; then
		local DT=$(export TZ=GMT ; date '+%Y%m%dGMT%H%M%S')
		SUBDIR="$DT-wget-ipns"
		ipfs files ls /$SAVE_MFS_ADDR/$SUBDIR &>/dev/null
		if [ $? -ne 0 ]; then
			local GATEWAY=$(ipfs config Addresses.Gateway)
			if [ "$GATEWAY" != "" ]; then
				_wget "http://127.0.0.1:${GATEWAY##*/}/ipfs/$ADDR" --cut-dirs=2 "Resolved /ipns/$1 to /ipfs/$ADDR"
				return $?
			else
				>&2 echo "Error: local IPFS gateway is not set"
			fi
		else
			>&2 echo "$SUBDIR exists"
			return 0
		fi
	fi
	return 1
}
_save_wget() {
	local DT=$(export TZ=GMT ; date '+%Y%m%dGMT%H%M%S')
	SUBDIR="$DT-wget"
	ipfs files ls /$SAVE_MFS_ADDR/$SUBDIR &>/dev/null
	if [ $? -ne 0 ]; then
		_wget $1
		return $?
	else
		>&2 echo "$SUBDIR exists"
		return 0
	fi
}
_save_wget_tor() {
	local DT=$(export TZ=GMT ; date '+%Y%m%dGMT%H%M%S')
	SUBDIR="$DT-wget-tor"
	ipfs files ls /$SAVE_MFS_ADDR/$SUBDIR &>/dev/null
	if [ $? -ne 0 ]; then
		_wget $1 --torsocks
		return $?
	else
		>&2 echo "$SUBDIR exists"
		return 0
	fi
}
_save_media() {
	if [[ $1 == https://www.youtube.com/watch?v=* || $1 == https://youtu.be/* ]]; then
		local DT=$(export TZ=GMT ; date '+%Y%m%dGMT%H%M%S')
		SUBDIR="$DT-media"
		ipfs files ls /$SAVE_MFS_ADDR/$SUBDIR &>/dev/null
		if [ $? -ne 0 ]; then
			if _command_exists yt-dlp; then
				if _command_exists ffmpeg; then
					_ytdlp $1
					return $?
				else
					>&2 echo "Error: ffmpeg is required to save media"
				fi
			else
				>&2 echo "Error: yt-dlp is required to save media"
			fi
		else
			>&2 echo "$SUBDIR exists"
			return 0
		fi
	fi
	return 1
}
_save_zite() {
	local DOMAIN=$(echo "$1" | awk -F/ '{print $1}')
	if [[ $DOMAIN == *.* ]]; then
		MAIN=$(_resolve_zeronet $DOMAIN)
		if [[ $MAIN != $DOMAIN && "$MAIN" != "" ]]; then
			>&2 echo "Resolved /zeronet/$DOMAIN to /zeronet/$MAIN"
		fi
	else
		MAIN=$DOMAIN
	fi
	if [[ $MAIN == 1* ]]; then
		local DT=$(export TZ=GMT ; date '+%Y%m%dGMT%H%M%S')
		SUBDIR="$DT-zite"
		ipfs files ls /$SAVE_MFS_ADDR/$SUBDIR &>/dev/null
		if [ $? -ne 0 ]; then
			local ZITEDATA="$(_zeronet_data)/$MAIN"
			if [[ -d "$ZITEDATA" ]]; then
				local CID=$(ipfs add -r "$ZITEDATA" --quieter --pin=false --cid-version=0)
				if [[ "$CID" != "" && "$CID" != "QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn" ]]; then
					if ipfs files mkdir /$SAVE_MFS_ADDR/$SUBDIR; then
						ipfs files cp //ipfs/$CID /$SAVE_MFS_ADDR/$SUBDIR/$DOMAIN
						if [ $? -eq 0 ]; then
							echo "$SAVE_HASH/$SUBDIR"
							return 0
						fi
					fi
				fi
			fi
		else
			>&2 echo "$SUBDIR exists"
			return 0
		fi
	fi
	return 1
}

_similar() {
	local URL="$(_url_but_fragment "$1")"
	for I in $(_similar_but_scheme "$URL"); do
		for J in $(_similar_but_slash "$I"); do
			for K in $(_similar_but_something "$J"); do
				for L in $(_similar_concrete "$K"); do
					echo "$L"
				done
			done
		done
	done
}
_similar_but_scheme() {
	local URL="$1"
	local host="$(_parse_host "$URL/")"
	if [[ $host == *.* ]]; then
		if [[ $URL == http://* ]]; then
			echo $URL
			echo "https://${URL#http://}"
			echo "ipns://${URL#http://}"
		elif [[ $URL == https://* ]]; then
			echo "http://${URL#https://}"
			echo $URL
			echo "ipns://${URL#https://}"
		elif [[ $URL == ipns://* ]]; then
			echo "http://${URL#ipns://}"
			echo "https://${URL#ipns://}"
			echo $URL
		elif [[ $URL == ftp://* ]]; then
			echo $URL
			echo "ftps://${URL#ftp://}"
		elif [[ $URL == ftps://* ]]; then
			echo "ftp://${URL#ftps://}"
			echo $URL
		else
			echo $URL
		fi
	else
		echo $URL
	fi
}
_similar_but_slash() {
	local URL="$1"
	local URL1="${URL%/}"
	local URL2="$URL1/"
	echo $URL1
	echo $URL2
}
_similar_but_something() {
	local URL="$1"
	local host=$(_parse_host "$URL/")
	echo $URL
	# www
	if [[ $URL == http://www.* ]]; then
		echo "http://${URL#http://www.}"
	elif [[ $URL == http://* ]]; then
		echo "http://www.${URL#http://}"
	elif [[ $URL == https://www.* ]]; then
		echo "https://${URL#https://www.}"
	elif [[ $URL == https://* ]]; then
		echo "https://www.${URL#https://}"
	fi
	# FTP
	if [[ $URL == http://ftp.* ]]; then
		echo "https://ftp.${URL#http://ftp.}"
		echo "ftp://ftp.${URL#http://ftp.}"
	elif [[ $URL == https://ftp.* ]]; then
		echo "http://ftp.${URL#https://ftp.}"
		echo "ftp://ftp.${URL#https://ftp.}"
	elif [[ $URL == ftp://ftp.* ]]; then
		echo "http://ftp.${URL#ftp://ftp.}"
		echo "https://ftp.${URL#ftp://ftp.}"
	fi
	# ZeroNet
	if [[ $URL == http://127.0.0.1:43110/raw/* ]]; then
		echo "http://127.0.0.1:43110/${URL#http://127.0.0.1:43110/raw/}"
	elif [[ $URL == http://127.0.0.1:43110/* ]]; then
		echo "http://127.0.0.1:43110/raw/${URL#http://127.0.0.1:43110/}"
	fi
	# IPFS
	if [[ $URL == ipfs://$host/* ]]; then
		if [[ $URL == ipfs://Qm* ]]; then
			local converted="$(ipfs cid format -v 1 -b base32 $host 2>/dev/null)"
			if [[ "$converted" != "" ]]; then
				echo "ipfs://$converted/${URL#ipfs://$host/}"
			fi
		elif [[ $URL == ipfs://bafy* ]]; then
			local converted="$(ipfs cid format -v 0 -b base58btc $host 2>/dev/null)"
			if [[ "$converted" != "" ]]; then
				echo "ipfs://$converted/${URL#ipfs://$host/}"
			fi
		fi
	fi
	#TODO: the same for IPNS
	
}
_similar_concrete() {
	local URL="$1"
	echo $URL
	if [[ $URL == https://* ]]; then
		# Habr
		if [[ $URL == https://habrahabr.ru/* ]]; then
			echo "https://habr.com/ru/${URL#https://habrahabr.ru/}"
			echo "https://habr.com/en/${URL#https://habrahabr.ru/}"
			echo "https://habr.com/${URL#https://habrahabr.ru/}"
		elif [[ $URL == https://habr.com/ru/* ]]; then
			echo "https://habrahabr.ru/${URL#https://habr.com/ru/}"
			echo "https://habr.com/en/${URL#https://habr.com/ru/}"
			echo "https://habr.com/${URL#https://habr.com/ru/}"
		elif [[ $URL == https://habr.com/en/* ]]; then
			echo "https://habrahabr.ru/${URL#https://habr.com/en/}"
			echo "https://habr.com/ru/${URL#https://habr.com/en/}"
			echo "https://habr.com/${URL#https://habr.com/en/}"
		elif [[ $URL == https://habr.com/* ]]; then
			echo "https://habrahabr.ru/${URL#https://habr.com/}"
			echo "https://habr.com/en/${URL#https://habr.com/}"
			echo "https://habr.com/ru/${URL#https://habr.com/}"
		fi
		# VK
		if [[ $URL == https://vk.com/* ]]; then
			echo "https://vkontakte.ru/${URL#https://vk.com/}"
		elif [[ $URL == https://vkontakte.ru/* ]]; then
			echo "https://vk.com/${URL#https://vkontakte.ru/}"
		fi
		# YouTube
		if [[ $URL == https://youtu.be/* ]]; then
			echo "https://www.youtube.com/watch?v=${URL#https://youtu.be/}"
		elif [[ $URL == https://www.youtube.com/watch?v=* ]]; then
			echo "https://youtu.be/${URL#https://www.youtube.com/watch?v=}"
		fi
	fi
}
#similar() {
#	_similar "$1"
#}

_subcommands() {
  if [[ "${1:-}" == "--raw" ]]
  then
    printf "%s\\n" "${_DEFINED_SUBCOMMANDS[@]}"
  else
    printf "Available commands:\\n"
    printf "  %s\\n" "${_DEFINED_SUBCOMMANDS[@]}"
  fi
}

_upgrade() {
	local TESTHASH1=$(_hash "test")
	if [[ "$TESTHASH1" != "a94a8fe5ccb19ba61c4c0873d391e987982fbbd3" ]]; then
		exit 1
	fi
	local VERTXT="/MiceWeb/attributes.txt"
	local VER=$(ipfs files read /$VERTXT 2>/dev/null | sed -n 2p)
	if [[ $VER == "" ]]; then
		local TESTHASH2="$(echo -n "test" | ipfs add --only-hash --quieter --cid-version=0)"
		#TODO: _IPFS_FEATURES="--to-files" when accessible
		if [[ "$TESTHASH2" != "QmRf22bZar3WKmojipms22PkXH1MZGmvsqzQtuSvQE3uhm" ]]; then
			_exit_1 _print_with_hyperlink "Installed IPFS CLI like " "https://github.com/ipfs/kubo" " is required for MiceWeb"
		fi
	fi
	local APPVER="v.${_VERSION}"
	if [[ $APPVER != $VER ]]; then
		if [[ $VER == "" ]]; then
			if ! ipfs files ls //MiceWeb &>/dev/null; then
				ipfs files mkdir //MiceWeb 2>/dev/null
				local VERTXTCID="$(printf "%s\n%s\n" "Library $(_random_value)" "$APPVER" | ipfs add --quieter --pin=false)"
				if ipfs files cp //ipfs/$VERTXTCID /$VERTXT; then
					return 0
				else
					_exit_1 printf "Can't create the MiceWeb Library\n"
				fi
			fi
			backup >/dev/null
			ipfs files mkdir //MiceWeb/pages 2>/dev/null
			local CID="$(ipfs files stat --hash //MiceWeb/pages/)"
			if [[ "$CID" != "" ]]; then
				for I in $(ipfs files ls //MiceWeb/pages/ | grep ^page-Qm); do
					local URL=$(ipfs cat $CID/$I/URL.txt 2>/dev/null | sed -n 2p)
					if [[ "$URL" != "" ]]; then
						>&2 echo -n "Upgrading $URL..."
						local HASH=$(_hash "$URL")
						>&2 echo -n "."
						if [[ "$HASH" != "" ]]; then
							ipfs files mv //MiceWeb/pages/$I "//MiceWeb/pages/$HASH"
						fi
						>&2 echo "."
					fi
				done
				local VERTXTCID="$(printf "%s\n%s\n" "Library $(_random_value)" "v.0.2" | ipfs add --quieter --pin=false)"
				ipfs files cp //ipfs/$VERTXTCID /$VERTXT
				if [ $? -eq 0 ]; then
					ipfs files flush //MiceWeb &>/dev/null
					>&2 echo "Upgraded the MiceWeb Library to v.0.2"
					_upgrade
					return $?
				fi
			fi
			_exit_1 printf "Can't upgrade the MiceWeb Library\n"
		else
			_vercomp "${_VERSION}" "${VER#v.}"
			if [ $? -eq 1 ]; then
				# updating to v.0.3
				backup >/dev/null
				local VERTXTCID="$(printf "%s\n%s\n" "Library $(_random_value)" "v.0.3" | ipfs add --quieter --pin=false)"
				ipfs files rm /$VERTXT
				ipfs files cp //ipfs/$VERTXTCID /$VERTXT
				if [ $? -eq 0 ]; then
					ipfs files flush //MiceWeb &>/dev/null
					>&2 echo "Upgraded the MiceWeb Library to v.0.3"
					>&2 echo "It's recommended to run 'miceweb save urls --grep=#'"
					save urls --grep="#"
					>&2 echo ""
					return 0
				fi
				_exit_1 printf "Can't upgrade the MiceWeb Library\n"
			else
				_exit_1 printf "MiceWeb $VER+ is required to work with the current MiceWeb Library\nThe current app version is $APPVER\nRun './update.sh' in the MiceWeb repository\n"
			fi
		fi
	fi
	return 0
}

_url_but_fragment() {
	local URL="$1"
	local fragment=$(_parse_fragment "$URL")
	if _has_url_fragment "$URL"; then
		echo "${URL%#$fragment}"
	else
		echo "$URL"
	fi
}

# https://stackoverflow.com/questions/4023830/how-to-compare-two-strings-in-dot-separated-version-format-in-bash
_vercomp () {
    if [[ $1 == $2 ]]
    then
        return 0
    fi
    local IFS=.
    local i ver1=($1) ver2=($2)
    # fill empty fields in ver1 with zeros
    for ((i=${#ver1[@]}; i<${#ver2[@]}; i++))
    do
        ver1[i]=0
    done
    for ((i=0; i<${#ver1[@]}; i++))
    do
        if [[ -z ${ver2[i]} ]]
        then
            # fill empty fields in ver2 with zeros
            ver2[i]=0
        fi
        if ((10#${ver1[i]} > 10#${ver2[i]}))
        then
            return 1
        fi
        if ((10#${ver1[i]} < 10#${ver2[i]}))
        then
            return 2
        fi
    done
    return 0
}

_versions() {
	local URL="$1"
	if [[ "$URL" == "" ]]; then
		#>&2 echo "This sub command requires URL as a parameter"
		return 1
	fi
	local HASH=$(_hash_string "$URL")
	if [[ "$HASH" != "" ]]; then
		for I in $(ipfs files ls //MiceWeb/pages/$HASH 2>/dev/null | sed 's/^/'"$HASH"'\//')
		do
			if [[ $I != *.* ]]; then
				echo "${I%ing}"
			fi
		done
	fi
}

_wget() {
	local URL="$1"
	local options="$2"
	local comment="$3"
	local MYTMPDIR=$(mktemp -d 2>/dev/null || mktemp -d -t 'mytmpdir')
	local MYTMPFILE=$(mktemp 2>/dev/null || mktemp -t 'mytmpfile')
	cd $MYTMPDIR
	local RAND="$(_random_value)"
	echo "Log $RAND" > $MYTMPFILE
	echo "$comment" >> $MYTMPFILE
	local USERAGENT="Mozilla/5.0 (Windows NT 10.0; rv:91.0) Gecko/20100101 Firefox/91.0"
	local span=""
	if [[ $SUBDIR != *-archive ]]; then
		span="--span-hosts"
	fi
	local robotsoff="--execute=robots=off"
	if [ "$options" != "--torsocks" ]; then
		wget --adjust-extension --no-cache --page-requisites --follow-ftp --no-remove-listing --retr-symlinks --restrict-file-names=windows --convert-links --backup-converted --no-host-directories $span $robotsoff --timeout=30 --tries=1 --user-agent="$USERAGENT" $options --append-output=$MYTMPFILE "$URL"
	else
		torsocks --isolate wget --adjust-extension --no-cache --page-requisites --follow-ftp --no-remove-listing --retr-symlinks --restrict-file-names=windows --convert-links --backup-converted --no-host-directories $span $robotsoff --timeout=30 --tries=1 --user-agent="$USERAGENT" --append-output=$MYTMPFILE "$URL" 2>/dev/null
	fi
	local WGETERR=$?
	local RET=1
	if [[ $WGETERR -eq 0 || $WGETERR -ge 3 ]] && [ $(ls -A "$MYTMPDIR" | wc -l) -ne 0 ]; then
		if [ $WGETERR -ne 0 ]; then
			>&2 echo "Warning: detected issues when downloading '${SUBDIR:18}', wget err. $WGETERR"
		fi
		local CID="$(ipfs add --quieter --pin=false -r $MYTMPDIR)"
		ipfs files cp //ipfs/$CID /$SAVE_MFS_ADDR/$SUBDIR
		if [ $? -eq 0 ]; then
			local LOGCID="$(ipfs add --quieter --pin=false $MYTMPFILE)"
			ipfs files cp //ipfs/$LOGCID /$SAVE_MFS_ADDR/$SUBDIR.log
			echo "$SAVE_HASH/$SUBDIR"
			RET=$WGETERR
		fi
	else
		>&2 echo "Error: could not download '${SUBDIR:18}', wget err. $WGETERR"
	fi
	cd ..
	rm -r $MYTMPDIR
	rm $MYTMPFILE
	return $RET
}

_ytdlp() {
	local URL="$1"
	local MYTMPDIR=$(mktemp -d 2>/dev/null || mktemp -d -t 'mytmpdir')
	cd $MYTMPDIR
	yt-dlp --no-playlist --format "bv*[ext=mp4]+ba[ext=m4a]/b[ext=mp4] / bv*+ba/b" --format-sort "res~360" --sleep-requests 1 --sleep-interval 5 --max-sleep-interval 15 --add-metadata --no-write-info-json --no-cookies-from-browser --no-cache-dir --write-description --write-annotations --no-embed-thumbnail --write-all-thumbnails --write-playlist-metafiles --match-filter "!is_live & !live" --merge-output-format "mp4" --socket-timeout 10 --throttled-rate 50K --output "%(title)s [%(id)s] - %(channel)s [%(channel_id)s] - %(upload_date)s.%(ext)s" --output "thumbnail:thumbnails/image.%(ext)s" --no-progress "$URL" &>/dev/null
	local YTDLPERR=$?
	local RET=1
	if [[ $YTDLPERR -eq 0 ]]; then
		local CID="$(ipfs add --quieter --pin=false -r $MYTMPDIR)"
		ipfs files cp //ipfs/$CID /$SAVE_MFS_ADDR/$SUBDIR
		if [ $? -eq 0 ]; then
			echo "$SAVE_HASH/$SUBDIR"
			RET=$YTDLPERR
		fi
	else
		>&2 echo "Error: could not download '${SUBDIR:18}', yt-dlp err. $YTDLPERR"
	fi
	cd ..
	rm -r $MYTMPDIR
	return $RET
}

_zeronet_data() {
	if [ "$ZERONET_PATH" != "" ]; then
		echo "$ZERONET_PATH/data"
	else
		echo "$HOME/Library/Application Support/ZeroNet/data"
	fi
}

###############################################################################
# Subcommands
# ===========..................................................................
#
# Example subcommand group structure:
#
# describe example ""   - Optional. A short description for the subcommand.
# example() { : }   - The subcommand called by the user.
#
#
# describe example <<HEREDOC
#   Usage:
#     $_ME example
#
#   Description:
#     Print "Hello, World!"
#
#     For usage formatting conventions see:
#     - http://docopt.org/
#     - http://pubs.opengroup.org/onlinepubs/9699919799/basedefs/V1_chap12.html
# HEREDOC
# example() {
#   printf "Hello, World!\\n"
# }
#
###############################################################################


# backup ######################################################################

describe "backup" <<HEREDOC
Usage:
  ${_ME} backup

Description:
  Backup CID of the MiceWeb Library
HEREDOC
backup() {
	if [[ "$1" != "" ]]; then
		>&2 echo "This command doesn't require parameters"
		return 1
	fi
	mkdir -p "$HOME/.miceweb"
	local DT=$(export TZ=GMT ; date '+%Y-%m-%d GMT %H:%M:%S')
	local CID="$(ipfs files stat --hash //MiceWeb 2>/dev/null)"
	if [[ "$CID" != "" ]]; then
		printf "%s\t%s\n" "$DT" "$CID" >> "$HOME/.miceweb/backup.txt"
		if [ $? -eq 0 ]; then
			>&2 echo "Added CID of /MiceWeb (MFS) to ~/.miceweb/backup.txt"
			echo $CID
		else
			echo $CID
			_exit_1 printf "Can't backup CID to ~/.miceweb/backup.txt\n"
		fi
	else
		_exit_1 printf "Can't obtain CID of the MiceWeb Library\n"
	fi
}

# cleanup #####################################################################

describe "cleanup" <<HEREDOC
Usage:
  ${_ME} cleanup

Description:
  Cleanup service data
HEREDOC
cleanup() {
	if [[ "$1" != "" ]]; then
		>&2 echo "This command doesn't require parameters"
		return 1
	fi
	local MFS_PRESENTS_ADDR="/MiceWeb/presents"
	local CID="$(ipfs files stat --hash /$MFS_PRESENTS_ADDR)"
	if [[ "$CID" == "" ]]; then
		>&2 echo "Nothing to cleanup"
		return 0
	fi
	if ipfs files rm -r /$MFS_PRESENTS_ADDR; then
		>&2 echo "Removed the history of presents"
		>&2 echo ""
		>&2 echo "You can try to undo that right now by running"
		>&2 echo " 'ipfs files cp /ipfs/$CID $MFS_PRESENTS_ADDR'"
		return 0
	else
		>&2 echo "Failed to cleanup"
		return 1
	fi
}

# commands ####################################################################

describe "commands" <<HEREDOC
Usage:
  ${_ME} commands

Description:
  Display the list of available commands
HEREDOC
commands() {
	echo "miceweb			Introduce MiceWeb"
	#_subcommands --raw $1 | awk -v PREFIX="miceweb " '{print PREFIX $0}'
	echo "miceweb backup		Backup CID of the MiceWeb Library
miceweb cleanup		Cleanup service data
miceweb commands	Display the list of available commands
miceweb discuss		Welcome to the MiceWeb Threads in ZeroNet
miceweb find		Find saved web pages on the local machine
miceweb hash		Calculate SHA-1 hash for URL (but fragment)
miceweb help		Display help information
miceweb history		List URLs which were attempted to be saved or imported
miceweb import		Import web page snapshot from file or directory
miceweb log		Print log created when saved snapshot
miceweb present		Present saved snapshots
miceweb present urls
miceweb remove		Remove saved snapshot
miceweb request		Request web page snapshots from remote sources
miceweb resolve		Resolve dynamic path (e.g., IPNS) to direct path
miceweb save		Save web page snapshots
miceweb save urls
miceweb snapshots	List saved snapshots
miceweb url		Return URL by SHA-1 hash
miceweb urls		List URLs from file, or from the MiceWeb Library
miceweb version		Display the current program version"
}

# discuss #####################################################################

describe "discuss" <<HEREDOC
Usage:
  ${_ME} discuss

Description:
  Welcome to the MiceWeb Threads in ZeroNet
HEREDOC
discuss() {
	if ! wget "http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/uimedia/all.css?rev=1270494604" --timeout=1 --output-document=- &>/dev/null; then
		>&2 echo "Run a local ZeroNet node,"
		>&2 _print_with_hyperlink " seeing " "https://github.com/ZeroNetX/ZeroNet#user-content-how-to-join"
		>&2 _print_with_hyperlink " or " "https://github.com/zeronet-conservancy/zeronet-conservancy#how-to-join"
		>&2 echo ""
	fi
	_print_with_hyperlink "" "http://127.0.0.1:43110/$_SITE_ADDRESS/?Main"
}

# find ########################################################################

describe "find" <<HEREDOC
Usage:
  ${_ME} find <URL>
  ${_ME} find <SHA-1>

Description:
  Find saved web pages in ~/Downloads (use SingleFile or SingleFileZ browser extension)
HEREDOC
find() {
	_upgrade
	>&2 _print_with_hyperlink "Install " "https://github.com/gildas-lormeau/SingleFile"
	>&2 _print_with_hyperlink " or " "https://github.com/gildas-lormeau/SingleFileZ" " browser extension,"
	>&2 echo " then set filename template to some value contains {url-href-digest-sha-1}"
	>&2 echo "Downloads folder should be inside ~/Downloads (or just create a symlink)"
	>&2 echo ""
	local URL="$(_url_but_fragment "$1")"
	if [[ "$URL" == "" ]]; then
		>&2 echo "This command requires URL or SHA-1 as a parameter"
		return 1
	fi
	if [[ "$1" =~ ^[0-9a-f]{40}$ ]]; then
		local HASH="$1"
		URL=$(url "$1")
		if [[ "$URL" == "" ]]; then
			command find -L ~/Downloads -name "*$HASH*" -not -path '*/.*' | awk -v PREFIX="miceweb import $HASH \"" -v SUFFIX="\"" '{print PREFIX $0 SUFFIX}'
			return 0
		fi
		if [[ "$URL" == http*://* ]]; then
			command find -L ~/Downloads -name "*$HASH*" -not -path '*/.*' | awk -v PREFIX="miceweb import \"$URL\" \"" -v SUFFIX="\"" '{print PREFIX $0 SUFFIX}'
		fi
	else
		if ! _check_url "$URL"; then
			_echo_supported_url_prefixes
			return 1
		fi
		for J in $(_similar "$URL" 2>/dev/null); do
			if [[ "$J" == http*://* ]]; then
				local HASH=$(_hash "$J")
				if [[ "$HASH" != "" ]]; then
					command find -L ~/Downloads -name "*$HASH*" -not -path '*/.*' | awk -v PREFIX="miceweb import \"$J\" \"" -v SUFFIX="\"" '{print PREFIX $0 SUFFIX}'
				fi
			fi
		done
	fi
	local filename=$(basename "$URL")
	command find -L ~/Downloads -name "$filename" -not -path '*/.*' | awk -v PREFIX="miceweb import \"$URL\" \"" -v SUFFIX="\"" '{print PREFIX $0 SUFFIX}'
	command find -L ~/Downloads -name "$filename.*" -not -path '*/.*' | awk -v PREFIX="miceweb import \"$URL\" \"" -v SUFFIX="\"" '{print PREFIX $0 SUFFIX}'
}

# hash ########################################################################

describe "hash" <<HEREDOC
Usage:
  ${_ME} hash <URL>

Description:
  Calculate SHA-1 hash for URL (but fragment)
HEREDOC
hash() {
	local URL="$1"
	if [[ "$URL" == "" ]]; then
		>&2 echo "This command requires URL as a parameter"
		return 1
	fi
	if ! _check_url "$URL"; then
		_echo_supported_url_prefixes
		return 1
	fi
	local HASH=$(_hash "$URL")
	if [[ "$HASH" != "" ]]; then
		echo $HASH
		local MFS_ADDR="/MiceWeb/pages/$HASH"
		ipfs files ls /$MFS_ADDR/URL.txt >/dev/null 2>/dev/null
		if [ $? -ne 0 ]; then
			ipfs files mkdir //MiceWeb 2>/dev/null
			ipfs files mkdir //MiceWeb/pages 2>/dev/null
			ipfs files mkdir /$MFS_ADDR 2>/dev/null
			local URL0=$(_url_but_fragment "$URL")
			local URLTXTCID="$(printf "%s\n%s\n" "URL $(_random_value)" "$URL0" | ipfs add --quieter --pin=false)"
			ipfs files cp //ipfs/$URLTXTCID /$MFS_ADDR/URL.txt
		fi
		return 0
	else
		return 1
	fi
}

# help ########################################################################

describe "help" <<HEREDOC
Usage:
  ${_ME} help
  ${_ME} help <command>

Description:
  Display help information for ${_ME} or a specified command
HEREDOC
help() {
  if [[ "${1:-}" ]]
  then
    describe --get "${1}"
  else
    cat <<HEREDOC
  __  __   _                 __        __        _     
 |  \/  | (_)   ___    ___   \ \      / /  ___  | |__  
 | |\/| | | |  / __|  / _ \   \ \ /\ / /  / _ \ | '_ \ 
 | |  | | | | | (__  |  __/    \ V  V /  |  __/ | |_) |
 |_|  |_| |_|  \___|  \___|     \_/\_/    \___| |_.__/ 

Version: ${_VERSION}

Usage:
  ${_ME} <URL>
  ${_ME} <SHA-1>
  ${_ME} <command> [--command-options] [<arguments>]

Help:
  ${_ME} help [<command>]

$(_subcommands --)

$(_news)
HEREDOC
  fi
}

# history #####################################################################

describe "history" <<HEREDOC
Usage:
  ${_ME} history

Description:
  List URLs which were attempted to be saved or imported
HEREDOC
history() {
	FN="$HOME/.miceweb/history.txt"
	COUNT=$(cat $FN 2>/dev/null | wc -l)
	if [ $COUNT -ne 0 ]; then
		>&2 echo "There is a list of URLs which was attempted to be saved or imported:"
		cat $FN
		>&2 echo ""
		>&2 echo "NumEntries: $COUNT"
	else
		>&2 echo "There are no URLs which was attempted to be saved or imported"
	fi
}

# import ######################################################################

describe "import" <<HEREDOC
Usage:
  ${_ME} import <URL> <local/ipfs/ipns path> [<comment>]
  ${_ME} import <SHA-1> <local/ipfs/ipns path> [<comment>]

Description:
  Import web page snapshot from file or directory
HEREDOC
import() {
	_upgrade
	local URL="$1"
	local IMPPATH="$2"
	local COMMENT="$3"
	if [[ "$IMPPATH" == "" ]]; then
		if [[ "$URL" == ipfs://* ]]; then
			IMPPATH="/ipfs/$(echo "${URL#ipfs://}" | awk -F/ '{print $1}')"
		elif [[ "$URL" == ipns://* ]]; then
			IMPPATH="/ipns/$(echo "${URL#ipns://}" | awk -F/ '{print $1}')"
		fi
	fi
	if [[ "$URL" == "" || "$IMPPATH" == "" ]]; then
		>&2 echo "This command requires URL or SHA-1 as a first parameter"
		>&2 echo " and local/ipfs/ipns path as a second parameter,"
		>&2 echo " some comment can be specified as a third parameter"
		return 1
	fi
	if [[ "$URL" =~ ^[0-9a-f]{40}$ ]]; then
		URL=$(url "$1")
		if [[ "$URL" == "" ]]; then
			#TODO: handle it
			return 1
		fi
	fi
	if ! _check_url "$URL"; then
		_echo_supported_url_prefixes
		return 1
	fi
	_addToHistory "$URL"
	_reprovidingWarning
	local HASH=$(hash "$URL")
	if [[ "$HASH" != "" ]]; then
		local MFS_ADDR="/MiceWeb/pages/$HASH"
		local DT=$(export TZ=GMT ; date '+%Y%m%dGMT%H%M%S')
		SUBDIR="$DT-import"
		local SUBDIR0="$SUBDIR"ing
		local CID=""
		local LOGTXTCID=""
		if [[ "$IMPPATH" == /ipfs/* || "$IMPPATH" == /ipns/* ]]; then
			local ADDR=""
			local RESOLVED=""
			if [[ "$IMPPATH" == /ipns/* ]]; then
				ADDR="/ipfs/$(_resolve_ipns "${IMPPATH#/ipns/}")"
				>&2 echo "Resolved to $ADDR"
				RESOLVED=", which resolved to $ADDR"
			else
				ADDR="$IMPPATH"
			fi
			if [[ "$ADDR" != "" ]]; then
				local ADDR2=$(ipfs resolve --timeout=60s "${ADDR#/ipfs/}")
				if [[ "$ADDR2" != "" ]]; then
					if ipfs files cp /$ADDR2 /$MFS_ADDR/$SUBDIR0; then
						if [[ "${ADDR%/}" != "$ADDR2" ]]; then
							>&2 echo "Resolved to $ADDR2"
							if [[ "$RESOLVED" == "" ]]; then
								RESOLVED=", which resolved to $ADDR2"
							else
								RESOLVED="$RESOLVED, then to $ADDR2"
							fi
						fi
						LOGTXTCID="$(printf "%s\n%s\n%s\n" "Log $(_random_value)" "Imported from $IMPPATH$RESOLVED" "$COMMENT" | ipfs add --quieter --pin=false)"
						ipfs files cp //ipfs/$LOGTXTCID /$MFS_ADDR/$SUBDIR.log
						echo "$HASH/$SUBDIR"
						if ipfs dag stat QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn --timeout=1s &>/dev/null; then
							>&2 echo "Getting content from IPFS Network..."
							if ipfs dag stat "${ADDR2#/ipfs/}"; then
								if ipfs files mv /$MFS_ADDR/$SUBDIR0 /$MFS_ADDR/$SUBDIR; then
									>&2 echo "Done"
								else
									>&2 echo "Done, but could not confirm it"
								fi
								return 0
							else
								>&2 echo "Incompleted"
							fi
						fi
						if [[ "$(ipfs files stat --format="<type>" /$MFS_ADDR/$SUBDIR0)" == "file" ]]; then
							>&2 echo "Run 'ipfs get ${ADDR2#/ipfs/} --output=/dev/null' to ensure availability"
						else
							>&2 echo "Run 'ipfs get ${ADDR2#/ipfs/}' to ensure availability"
						fi
						return 0
					fi
				fi
			fi
		elif [ -e "$IMPPATH" ]; then
			if [ -d "$IMPPATH" ]; then
				CID="$(ipfs add --quieter --pin=false -r "$IMPPATH")"
			else
				CID="$(ipfs add --quieter --pin=false "$IMPPATH")"
			fi
			ipfs files cp //ipfs/$CID /$MFS_ADDR/$SUBDIR
			if [ $? -eq 0 ]; then
				local IMPPATH0=${IMPPATH%/}
				local IMPBASE=${IMPPATH0%/*}
				local IMPBASEDIR=${IMPBASE##*/}
				local IMPNAME=${IMPPATH0##*/}
				LOGTXTCID="$(printf "%s\n%s\n%s\n" "Log $(_random_value)" "Imported from $IMPBASEDIR/$IMPNAME" "$COMMENT" | ipfs add --quieter --pin=false)"
				ipfs files cp //ipfs/$LOGTXTCID /$MFS_ADDR/$SUBDIR.log
				echo "$HASH/$SUBDIR"
				#>&2 echo "Run 'miceweb present \"$URL\"' to view saved snapshots"
				#>&2 echo "Run 'miceweb $HASH/$SUBDIR' to present"
				return 0
			fi
		else
			>&2 echo "Error: $IMPPATH not found"
		fi
	fi
	return 1
}

# log #########################################################################

describe "log" <<HEREDOC
Usage:
  ${_ME} log <snapshot>

Description:
  Print log created when saved snapshot
HEREDOC
log() {
	_upgrade
	local SNAP="$1"
	if [[ "$SNAP" =~ ^[0-9a-f]{40}/[0-9]{8}GMT[0-9]{6}-. ]]; then
		if [[ "$SNAP" != *.* ]]; then
			ipfs files read //MiceWeb/pages/$SNAP.log
			return $?
		fi
	fi
	>&2 echo "This command requires snapshot as a parameter"
	return 1
}

# present #####################################################################

describe "present" <<HEREDOC
Usage:
  ${_ME} present <URL>
  ${_ME} present <SHA-1>
  ${_ME} present <snapshot>
  ${_ME} present urls [--grep=<expression>] [<local/ipfs/ipns file path>]
  ${_ME} present

Description:
  Present saved snapshot
  Present saved snapshots of web page (including similar) by URL
  Present saved snapshots of web page (including similar) by URL's SHA-1
  Present saved snapshots of web pages by URLs from file
  Present saved snapshots of web pages in the MiceWeb Library
HEREDOC
present() {
	_upgrade
	local REPROVIDING=$(ipfs config Reprovider.Strategy)
	local GATEWAY=$(ipfs config Addresses.Gateway)
	if [[ "$1" == "urls" ]]; then
		if [[ "$2" != "" ]]; then
			ipfs files mkdir //MiceWeb 2>/dev/null
			ipfs files mkdir //MiceWeb/presents 2>/dev/null
			local DT=$(export TZ=GMT ; date '+%Y%m%dGMT%H%M%S')
			local MFS_PRESENT_ADDR="/MiceWeb/presents/present-$DT"
			ipfs files mkdir /$MFS_PRESENT_ADDR 2>/dev/null
			local COUNT=0
			local HASH=""
			for I in $("$0" "$@" 2>/dev/null)
			do
				HASH=$(_hash "$I")
				ipfs files cp //MiceWeb/pages/$HASH /$MFS_PRESENT_ADDR/$HASH 2>/dev/null
				if [ $? -eq 0 ]; then
					((COUNT++))
				fi
				#TODO: or with similar (maybe support --similar option)
				#for J in $(_similar "$I" 2>/dev/null)
				#do
				#	local HASH=$(_hash "$J")
				#	ipfs files cp //MiceWeb/pages/$HASH /$MFS_PRESENT_ADDR/$HASH 2>/dev/null
				#	if [ $? -eq 0 ]; then
				#		((COUNT++))
				#	fi
				#done
				if _has_url_fragment "$I"; then
					HASH=$(_hash_string "$I")
					ipfs files cp //MiceWeb/pages/$HASH /$MFS_PRESENT_ADDR/$HASH 2>/dev/null
					if [ $? -eq 0 ]; then
						((COUNT++))
					fi
				fi
			done
			local CID="$(ipfs files stat --hash /$MFS_PRESENT_ADDR)"
			if [[ "$CID" != "" && $COUNT -ne 0 ]]; then
				echo "/ipfs/$CID"
				if [ "$GATEWAY" != "" ]; then
					>&2 echo ""
					>&2 _print_with_hyperlink "Open " "http://127.0.0.1:${GATEWAY##*/}/ipfs/$CID" ""
					>&2 echo " in a browser on the local machine"
				fi
				if [[ "$REPROVIDING" == "all" ]]; then
					local converted="$(ipfs cid format -v 1 -b base32 $CID 2>/dev/null)"
					if [[ "$converted" != "" ]]; then
						>&2 _print_with_hyperlink " or " "ipfs://$converted" ""
						>&2 echo " in an IPFS friendly browser - out of box (Brave, Opera) or with IPFS Companion"
					fi
				else
					>&2 echo ""
					>&2 echo "If you need to publish or view from an other machine,"
					>&2 echo " run 'ipfs pin add $CID'"
					if [[ "$REPROVIDING" == "roots" ]]; then
						>&2 echo " and 'ipfs config Reprovider.Strategy pinned'"
					fi
				fi
				local STAT="NumURLs: $COUNT"
				>&2 echo ""
				if ipfs dag stat QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn --timeout=1s &>/dev/null; then
					ipfs dag stat $CID | awk -v SUFFIX=", $STAT" '{print $0 SUFFIX}' 1>&2
				else
					>&2 echo "$STAT"
				fi
				return 0
			fi
		else
			present
			return $?
		fi
		#TODO: fix and implement something like >&2 echo "Run 'miceweb save ${@@Q}'"
		return 1
	fi
	
	if [[ "$1" =~ ^[0-9a-f]{40}/[0-9]{8}GMT[0-9]{6}-. ]]; then
		local SNAP="$1"
		if [[ "$SNAP" != *.* ]]; then
			local MFS_SNAP_ADDR="/MiceWeb/pages/$SNAP"
			local CID="$(ipfs files stat --hash /$MFS_SNAP_ADDR)"
			local ing=0
			if [ "$CID" == "" ]; then
				if [[ "$SNAP" == *-import ]]; then
					ing=1
					CID="$(ipfs files stat --hash "/$MFS_SNAP_ADDR"ing)"
				fi
			fi
			if [ "$CID" != "" ]; then
				echo -n "/ipfs/$CID"
				local suffix=""
				local HASH=$(echo "$1" | awk -F/ '{print $1}')
				if [[ "$HASH" != "" ]]; then
					local URL=$(url "$HASH")
					if [[ "$URL" != "" ]]; then
						suffix="$URL"
						local part=
						part=$(echo $suffix | awk -F/ '{print $1}'); suffix="${suffix#$part/}"
						part=$(echo $suffix | awk -F/ '{print $1}'); suffix="${suffix#$part/}"
						part=$(echo $suffix | awk -F/ '{print $1}'); suffix="${suffix#$part/}"
						local suff="$suffix"
						suffix="/$suffix"
						if ! ipfs resolve --timeout=1s $CID$suffix &>/dev/null; then
							suffix="${suffix%/}.html"
							if ! ipfs resolve --timeout=1s $CID$suffix &>/dev/null; then
								part=$(echo $suff | awk -F/ '{print $1}'); suffix="/${suff#$part/}"
								if ! ipfs resolve --timeout=1s $CID$suffix &>/dev/null; then
									suffix=""
								fi
							fi
						fi
					fi
				fi
				echo $suffix
				if [ "$GATEWAY" != "" ]; then
					>&2 echo ""
					>&2 _print_with_hyperlink "Open " "http://127.0.0.1:${GATEWAY##*/}/ipfs/$CID$suffix" ""
					>&2 echo " in a browser on the local machine"
				fi
				if [[ "$REPROVIDING" == "all" ]]; then
					local converted="$(ipfs cid format -v 1 -b base32 $CID 2>/dev/null)"
					if [[ "$converted" != "" ]]; then
						>&2 _print_with_hyperlink " or " "ipfs://$converted$suffix" ""
						>&2 echo " in an IPFS friendly browser - out of box (Brave, Opera) or with IPFS Companion"
					fi
				else
					>&2 echo ""
					>&2 echo "If you need to publish or view from an other machine,"
					>&2 echo " run 'ipfs pin add $CID'"
					if [[ "$REPROVIDING" == "roots" ]]; then
						>&2 echo " and 'ipfs config Reprovider.Strategy pinned'"
					fi
				fi
				if ipfs dag stat QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn --timeout=1s &>/dev/null; then
					>&2 echo ""
					if ipfs dag stat $CID; then
						if [ $ing -eq 1 ]; then
							ipfs files mv "/$MFS_SNAP_ADDR"ing /$MFS_SNAP_ADDR
						fi
					fi
				fi
				return 0
			fi
		fi
		return 1
	fi
	
	local URL="$1"
	local HASH=""
	local CID0=""
	local CID=""
	local CNT=0
	
	if [[ "$URL" =~ ^[0-9a-f]{40}$ ]]; then
		HASH="$1"
		URL=$(url "$1")
		if [[ "$URL" == "" ]]; then
			return 1
		fi
		local MFS_PAGE_ADDR="/MiceWeb/pages/$HASH"
		local CID="$(ipfs files stat --hash /$MFS_PAGE_ADDR)"
		if [ "$CID" != "" ]; then
			echo "/ipfs/$CID"
			local COUNT=0
			for I in $(ipfs files ls /$MFS_PAGE_ADDR); do
				if [[ $I != *.* ]]; then
					((COUNT++))
				fi
			done
			local STAT="NumVersions: $COUNT"
			if [ "$GATEWAY" != "" ]; then
				>&2 echo ""
				>&2 _print_with_hyperlink "Open " "http://127.0.0.1:${GATEWAY##*/}/ipfs/$CID" ""
				>&2 echo " in a browser on the local machine"
			fi
			if [[ "$REPROVIDING" == "all" ]]; then
				local converted="$(ipfs cid format -v 1 -b base32 $CID 2>/dev/null)"
				if [[ "$converted" != "" ]]; then
					>&2 _print_with_hyperlink " or " "ipfs://$converted" ""
					>&2 echo " in an IPFS friendly browser - out of box (Brave, Opera) or with IPFS Companion"
				fi
			else
				>&2 echo ""
				>&2 echo "If you need to publish or view from an other machine,"
				>&2 echo " run 'ipfs pin add $CID'"
				if [[ "$REPROVIDING" == "roots" ]]; then
					>&2 echo " and 'ipfs config Reprovider.Strategy pinned'"
				fi
			fi
			>&2 echo ""
			if ipfs dag stat QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn --timeout=1s &>/dev/null; then
				ipfs dag stat $CID | awk -v SUFFIX=", $STAT" '{print $0 SUFFIX}' 1>&2
			else
				>&2 echo "$STAT"
			fi
			return 0
		else
			return 1
		fi
	fi
	
	local URL0="$(_url_but_fragment "$URL")"
	
	local SIMURL="$URL0"
	local SIMURLs=()
	
	if [[ "$URL" != "" ]]; then
		HASH=$(_hash "$URL" 2>/dev/null)
	fi
	
	if [[ "$HASH" != "" ]]; then
		local MFS_PAGE_ADDR="/MiceWeb/pages/$HASH"
		ipfs files ls /$MFS_PAGE_ADDR/URL.txt >/dev/null 2>/dev/null
		if [ $? -ne 0 ]; then
			if _check_url "$URL"; then
				ipfs files mkdir //MiceWeb 2>/dev/null
				ipfs files mkdir //MiceWeb/pages 2>/dev/null
				ipfs files mkdir /$MFS_PAGE_ADDR 2>/dev/null
				local URLTXTCID="$(printf "%s\n%s\n" "URL $(_random_value)" "$URL" | ipfs add --quieter --pin=false)"
				ipfs files cp //ipfs/$URLTXTCID /$MFS_PAGE_ADDR/URL.txt
			else
				_echo_supported_url_prefixes
				return 1
			fi
		fi
		ipfs files mkdir //MiceWeb 2>/dev/null
		ipfs files mkdir //MiceWeb/presents 2>/dev/null
		local DT=$(export TZ=GMT ; date '+%Y%m%dGMT%H%M%S')
		local MFS_PRESENT_ADDR="/MiceWeb/presents/present-$DT"
		ipfs files mkdir /$MFS_PRESENT_ADDR 2>/dev/null
		for I in $(_similar "$URL" 2>/dev/null)
		do
			local SIMHASH=$(_hash "$I")
			if ipfs files cp //MiceWeb/pages/$SIMHASH /$MFS_PRESENT_ADDR/$SIMHASH 2>/dev/null; then
				if [[ "$I" != "$URL0" ]]; then
					SIMURL="$I"
					SIMURLs+=("$I")
					((CNT++))
				fi
				
			fi
		done
		if _has_url_fragment "$URL"; then
			local SIMHASH=$(_hash_string "$URL")
			if ipfs files cp //MiceWeb/pages/$SIMHASH /$MFS_PRESENT_ADDR/$SIMHASH 2>/dev/null; then
				SIMURLs+=("$URL")
				((CNT++))
			fi
		fi
		CID0="$(ipfs files stat --hash /$MFS_PRESENT_ADDR)"
		if [[ $CID0 == "QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn" ]]; then
			_exit_1 echo "Error: unexpected error, try again"
		fi
		CID="$CID0/$HASH"
	else
		local MFS_PRESENT_ADDR="/MiceWeb/pages/"
		CID0="$(ipfs files stat --hash /$MFS_PRESENT_ADDR 2>/dev/null)"
		CID="$CID0"
	fi
	
	if [[ "$CID" != "" ]]; then
		echo "/ipfs/$CID"
		local STAT=""
		local COUNT=0
		if [[ "$HASH" == "" ]]; then
			COUNT=$(ipfs files ls //MiceWeb/pages | grep ^[0-9a-f] | wc -l)
			STAT="NumURLs: $COUNT"
		else
			for I in $(ipfs files ls //MiceWeb/pages/$HASH); do
				if [[ $I != *.* ]]; then
					((COUNT++))
				fi
			done
			STAT="NumVersions: $COUNT"
		fi
		if [ "$1" != "" ]; then
			if [[ $CNT -eq 0 && $COUNT -eq 0 ]]; then
				>&2 echo ""
				>&2 echo "There are no snapshots to view"
				return 0
			fi
			if [ "$GATEWAY" != "" ]; then
				>&2 echo ""
				>&2 _print_with_hyperlink "Open " "http://127.0.0.1:${GATEWAY##*/}/ipfs/$CID" " in a browser on the local machine"
			fi
			if [[ "$REPROVIDING" == "all" ]]; then
				local converted="$(ipfs cid format -v 1 -b base32 $CID0 2>/dev/null)"
				if [[ "$converted" != "" ]]; then
					>&2 _print_with_hyperlink " or " "ipfs://$converted/$HASH" " in an IPFS friendly browser"
				fi
				>&2 _print_with_hyperlink " to view " "$URL0" " snapshots"
			else
				>&2 _print_with_hyperlink " to view " "$URL0" " snapshots"
				>&2 echo ""
				>&2 echo "If you need to publish or view from an other machine,"
				>&2 echo " run 'ipfs pin add $CID0'"
				if [[ "$REPROVIDING" == "roots" ]]; then
					>&2 echo " and 'ipfs config Reprovider.Strategy pinned'"
				fi
			fi
		else
			>&2 echo ""
			>&2 echo "There is a content identifier of current pages of all the MiceWeb Library"
			>&2 echo "It's not recommended to share it because security and other reasons,"
			>&2 echo " however, if you need it, pin $CID0"
			if [[ "$REPROVIDING" == "roots" ]]; then
				>&2 echo " and run 'ipfs config Reprovider.Strategy pinned'"
			fi
			if [ "$GATEWAY" != "" ]; then
				>&2 echo ""
				>&2 _print_with_hyperlink "Open " "http://127.0.0.1:${GATEWAY##*/}/ipfs/$CID" ""
				>&2 echo " in a browser on the local machine to view snapshots"
			fi
		fi
		>&2 echo ""
		if ipfs dag stat QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn --timeout=1s &>/dev/null; then
			ipfs dag stat $CID | awk -v SUFFIX=", $STAT" '{print $0 SUFFIX}' 1>&2
		else
			>&2 echo "$STAT"
		fi
		if [ "$HASH" != "" ]; then
			local PAYATT=""
			if [ $CNT -ge 2 ]; then
				PAYATT="There are similar URLs found in the MiceWeb Library:"
			elif [ $CNT -eq 1 ]; then
				PAYATT="There is a similar URL found in the MiceWeb Library:"
			fi
			if [ "$PAYATT" != "" ]; then
				>&2 echo ""
				>&2 echo $PAYATT
				for I in "${SIMURLs[@]}"; do
					>&2 echo "$I"
				done
			fi
		fi
	else
		#TODO: fix and implement something like >&2 echo "Run 'miceweb save ${@@Q}'"
		return 1
	fi
}

# remove ######################################################################

describe "remove" <<HEREDOC
Usage:
  ${_ME} remove <snapshot>

Description:
  Remove saved snapshot
HEREDOC
remove() {
	_upgrade
	local SNAP="$1"
	if [[ "$SNAP" =~ ^[0-9a-f]{40}/[0-9]{8}GMT[0-9]{6}-. ]]; then
		if [[ "$SNAP" != *.* ]]; then
			local MFS_SNAP_ADDR="/MiceWeb/pages/$SNAP"
			if ! _remove_file $MFS_SNAP_ADDR 2>/dev/null; then
				_remove_dir $MFS_SNAP_ADDR 2>/dev/null
			fi
			if [[ "$SNAP" == *-import ]]; then
				if ! _remove_file "$MFS_SNAP_ADDR"ing 2>/dev/null; then
					_remove_dir "$MFS_SNAP_ADDR"ing 2>/dev/null
				fi
			fi
			_remove_file "$MFS_SNAP_ADDR.log" 2>/dev/null
			return 0
		fi
	fi
	>&2 echo "This command requires snapshot as a parameter"
	return 1
}

# request #####################################################################

describe "request" <<HEREDOC
Usage:
  ${_ME} request <URL>
  ${_ME} request <SHA-1>

Description:
  Request web page snapshots from remote sources
HEREDOC
request() {
	_upgrade
	>&2 echo "Run following commands 'miceweb <parameters>' to get snapshots"
	local URL="$(_url_but_fragment "$1")"
	if [[ "$URL" == "" ]]; then
		>&2 echo "This command requires URL or SHA-1 as a parameter"
		return 1
	fi
	if [[ "$1" =~ ^[0-9a-f]{40}$ ]]; then
		URL=$(url "$1")
		if [[ "$URL" == "" ]]; then
			return 1
		fi
	fi
	if ! _check_url "$URL"; then
		_echo_supported_url_prefixes
		return 1
	fi
	if _command_exists wayback_machine_downloader; then
		if _command_exists jq; then
			if [[ $URL == http://* || $URL == https://* || $URL == ipns://* ]]; then
				>&2 echo ""
				>&2 echo "Requesting snapshots from the Wayback Machine..."
				if [[ "$1" =~ ^[0-9a-f]{40}$ ]]; then
					if [[ $URL == http*://* ]]; then
						local HASH=$1
						for I in $(wayback_machine_downloader -s -e -l "$URL" 2>/dev/null | jq --raw-output '.. | .timestamp? | strings'); do
							echo "miceweb save $HASH/${I:0:8}GMT${I:8:6}-archive"
						done
					fi
				else
					local URL_arc=$URL
					if [[ $URL == http://* ]]; then
						URL_arc="https://${URL#http://}"
					elif [[ $URL == ipns://* ]]; then
						URL_arc="https://${URL#ipns://}"
					fi
					for URL_concrete in $(_similar_concrete $URL_arc)
					do
						if [[ "$URL_concrete" == "$URL_arc" ]]; then
							if [[ $URL == http://* ]]; then
								URL_concrete=$URL
							fi
						fi
						local HASH=$(hash "$URL_concrete")
						for I in $(wayback_machine_downloader -s -e -l "$URL_concrete" 2>/dev/null | jq --raw-output '.. | .timestamp? | strings'); do
							echo "miceweb save $HASH/${I:0:8}GMT${I:8:6}-archive"
						done
					done
				fi
				>&2 echo "Done"
			fi
		else
			>&2 _print_with_hyperlink "Error: jq is not installed (seeing " "https://stedolan.github.io/jq/download/" ")"
		fi
	else
		>&2 echo "Error: wayback_machine_downloader is not installed"
	fi
}

# resolve #####################################################################

describe "resolve" <<HEREDOC
Usage:
  ${_ME} resolve /ipns/<cid-of-libp2p-key>
  ${_ME} resolve /ipns/<domain>
  ${_ME} resolve /zeronet/<domain>
  
Description:
  Resolve dynamic path to direct path
HEREDOC
resolve() {
	_upgrade
	if [[ $1 == /ipns/* ]]; then
		_resolve_ipns "${1#/ipns/}" | awk -v PREFIX="/ipfs/" '{print PREFIX $0}'
		return 0
		#TODO: show history in stderr?
		#local DOMAIN=$(echo "$1" | awk -F/ '{print $1}')
		#for I in $(ipfs files ls //MiceWeb/resolves/ipns/$DOMAIN)
		#do
		#	echo ${I%.txt} $(ipfs files read //MiceWeb/resolves/ipns/$DOMAIN/$I | sed -n 2p)
		#done
	elif [[ $1 == /zeronet/* ]]; then
		_resolve_zeronet "${1#/zeronet/}" | awk -v PREFIX="/zeronet/" '{print PREFIX $0}'
		return 0
	else
		>&2 echo "This command requires IPNS path (e.g., /ipns/ratbrowser.com) as a parameter"
	fi
	return 1
}

# save ########################################################################

describe "save" <<HEREDOC
Usage:
  ${_ME} save <URL>
  ${_ME} save <SHA-1>
  ${_ME} save <snapshot>
  ${_ME} save urls [--grep=<expression>] [<local/ipfs/ipns file path>]

Description:
  Save web page snapshot(s)
HEREDOC
save() {
	_upgrade
	#TODO: --archives={default|none|last|set}
	if [[ "$1" == "urls" ]]; then
		_reprovidingWarning
		if ! _command_exists torsocks; then
			>&2 echo "Error: torsocks is not installed, some web pages might be inaccessible"
		fi
		for I in $("$0" "$@" 2>/dev/null)
		do
			if _check_url "$I"; then
				#TODO: at first, save pages which have no snapshots
				#local VERSIONS_COUNT=$(_versions "$(_url_but_fragment $I)" | grep -e "^.*-wget$" -e "^.*-wget-tor$" -e "^.*-wget-ip.s$" | wc -l)
				#if [ "$VERSIONS_COUNT" -eq 0 ]; then
				if ! _check_free_space_for_temp
				then
					>&2 echo "Free disk space for temporary files and run the command again"
					return 1
				fi
				#TODO: indicate like "Saving $I (50 of 100)"
				local PAGE_HASH=$(hash "$I")
				if [[ "$PAGE_HASH" != "" ]]; then
					>&2 echo -n "Saving $I"
					local rnumber=$((RANDOM%11+5))
					for (( i = 1; i <= $rnumber; i++ )) ; do
						sleep 1
						>&2 echo -n "."
					done
					>&2 echo ""
					save --no-warnings $PAGE_HASH
				fi
			fi
		done
		#TODO: fix and implement something like >&2 echo "Run 'miceweb present $@' to view saved snapshots"
		return 0
	fi
	local SOMETHING=""
	local _arguments=()
	local _warnings=1
	local _val=
	for __arg in "${@:-}"
	do
	case ${__arg} in
	  --no-warnings)
		_warnings=0
		;;
	  -*)
		_exit_1 printf "Unexpected option: %s\\n" "${__arg}"
		;;
	  *)
		if _blank "${SOMETHING}"
		then
		  _val="${__arg}"
		  SOMETHING="$_val"
		else
		  _arguments+=("${__arg}")
		fi
		;;
	esac
	done
	if [[ "$SOMETHING" == "" ]]; then
		>&2 echo "This command requires URL or SHA-1 or snapshot as a parameter"
		return 1
	fi
	local URL="$SOMETHING"
	if [[ "$SOMETHING" =~ ^[0-9a-f]{40}/[0-9]{8}GMT[0-9]{6}-. ]]; then
		if [[ "$SOMETHING" =~ ^[0-9a-f]{40}/[0-9]{8}GMT[0-9]{6}-archive ]]; then
			local SNAP="$SOMETHING"
			local HASH=${SNAP:0:40}
			URL=$(url "$HASH")
			if [[ "$URL" == "" ]]; then
				return 1
			fi
			if _initiate_saving_url $URL; then
				_save_archived_snapshot $URL ${SNAP:41}
			fi
			return $?
		else
			>&2 echo "Only 'archive' snapshot can be specifically saved"
			return 1
		fi
	fi
	if [[ "$SOMETHING" =~ ^[0-9a-f]{40}$ ]]; then
		URL=$(url "$SOMETHING")
		if [[ "$URL" == "" ]]; then
			return 1
		fi
	fi
	if ! _check_url "$URL"; then
		_echo_supported_url_prefixes
		return 1
	fi
	_addToHistory "$URL"
	type -P wget &>/dev/null && ISINST=1 || ISINST=0
	if [ $ISINST -eq 0 ]
	then
		>&2 echo "Error: wget is not installed"
		return 127
	fi
	if [ $_warnings -eq 1 ]; then
		_reprovidingWarning
	fi
	local URL0=$(_url_but_fragment "$URL")
	if _initiate_saving_url $URL; then
		if _check_free_space_for_temp
		then
			PARSEDPATH=$(_parse_path $URL)
			if [[ $URL == ipns://* ]]; then
				if ! _save_wget_ipns "${URL#ipns://}"; then
					if [[ ! "$SOMETHING" =~ ^[0-9a-f]{40}$ ]]; then
						local SIMILAR_HASH=$(hash "http://${URL#ipns://}")
						if [[ "$SIMILAR_HASH" != "" ]]; then
							"$0" save --no-warnings $SIMILAR_HASH #2> >(grep --line-buffered .) # | awk '!a[$0]++; fflush()'
						fi
					fi
				fi
			elif [[ $URL == ipfs://* ]]; then
				_save_wget_ipfs "${URL#ipfs://}"
			elif [[ $URL == gemini://* ]]; then
				if _command_exists gemget; then
					_save_gemget $URL
				else
					>&2 _print_with_hyperlink "Error: " "https://github.com/makeworld-the-better-one/gemget" " is not installed"
				fi
			elif [[ $URL == gopher://* ]]; then
				if ! _save_curl $URL; then
					if _command_exists torsocks; then
						_save_curl_tor $URL
					fi
				fi
			else
				_save_media $URL
				_save_wget $URL
				local WGETERR=$?
				local ININET= ; [[ $URL != http://127.0.0.1:* && $URL != http://localhost:* ]] ; ININET=$?
				if [ $WGETERR -ne 0 ]; then
					if [ $WGETERR -le 4 ]; then
						if [ $ININET -eq 0 ]; then
							if _command_exists torsocks; then
								_save_wget_tor $URL
								local WGETERR_TOR=$?
								if [ $WGETERR_TOR -eq 0 ]; then
									WGETERR=9
								elif [ $WGETERR_TOR -ge 4 ]; then
									WGETERR=$WGETERR_TOR
								fi
							else
								if [ $_warnings -eq 1 ]; then
									>&2 echo "Error: torsocks is not installed"
								fi
							fi
						fi
					fi
					if [[ $URL == http://127.0.0.1:43110/* ]]; then
						if [[ $URL != http://127.0.0.1:43110/raw/* ]]; then
							#local ext=$(_parse_extension "$URL")
							#if [[ "$ext" == "" || $ext == htm || $ext == html || $ext == bit || $ext == yo || $ext == zn || $ext == inf || $ext == yu || $ext == of || $ext == list ]]; then
								_save_zite "${PARSEDPATH#/}"
							#fi
						else
							_save_zite "${PARSEDPATH#/raw/}"
						fi
					fi
					if [ $WGETERR -lt 4 ]; then
						if ! _save_curl $URL; then
							if [ $ININET -eq 0 ]; then
								if _command_exists torsocks; then
									_save_curl_tor $URL
								fi
							fi
						fi
						if [[ $URL == http*://* ]]; then
							if [[ ! "$SOMETHING" =~ ^[0-9a-f]{40}$ ]]; then
								local wos=""
								local SIMILAR_HASH=""
								if [[ $URL == https://* ]]; then
									wos=${URL#https://}
									SIMILAR_HASH=$(hash "http://$wos")
									if [[ "$SIMILAR_HASH" != "" ]]; then
										"$0" save --no-warnings $SIMILAR_HASH #2> >(grep --line-buffered .) | awk '!a[$0]++; fflush()'
									fi
								elif [[ $URL == http://* ]]; then
									wos=${URL#http://}
								fi
								local DOMAIN=$(echo "$wos" | awk -F/ '{print $1}')
								if ipfs name resolve --recursive=false --timeout=5s $DOMAIN &>/dev/null; then
									SIMILAR_HASH=$(hash "ipns://$wos")
									if [[ "$SIMILAR_HASH" != "" ]]; then
										"$0" save --no-warnings $SIMILAR_HASH #2> >(grep .)
									fi
								fi
								if [[ $URL == http://* ]]; then
									if [ $ININET -eq 0 ]; then
										_save_archived $URL
									fi
								fi
							else
								if [ $ININET -eq 0 ]; then
									_save_archived $URL
								fi
							fi
						fi
					fi
					if [[ $URL == http*://*.*/ipfs/* ]]; then
						_save_wget_ipfs "${PARSEDPATH#/ipfs/}"
					elif [[ $URL == http*://*.*/ipns/* ]]; then
						_save_wget_ipns "${PARSEDPATH#/ipns/}"
					fi
				fi				
			fi
			#if [ $_warnings -eq 1 ]; then
			#	>&2 echo ""
			#	>&2 echo "Run 'miceweb present \"$URL0\"' to view saved snapshots"
			#fi
		else
			>&2 echo "Error: insufficient disk space for temporary files"
			return 1
		fi
	else
		return 1
	fi
}

# snapshots ###################################################################

describe "snapshots" <<HEREDOC
Usage:
  ${_ME} snapshots <URL>
  ${_ME} snapshots <SHA-1>

Description:
  List saved versions of web pages (including similar) by URL
HEREDOC
snapshots() {
	if [[ "$1" == "" ]]; then
		>&2 echo "This command requires URL or SHA-1 as a parameter"
		return 1
	fi
	local URL="$1"
	if [[ "$1" =~ ^[0-9a-f]{40}$ ]]; then
		URL=$(url "$1")
		if [[ "$URL" == "" ]]; then
			return 1
		fi
	fi
	for I in $(_similar "$URL" 2>/dev/null)
	do
		_versions "$I"
	done
	if _has_url_fragment "$URL"; then
		_versions "$URL"
	fi
}

# url #########################################################################

describe "url" <<HEREDOC
Usage:
  ${_ME} url <SHA-1>

Description:
  Return URL by SHA-1 hash
HEREDOC
url() {
	_upgrade
	if [[ ! "$1" =~ ^[0-9a-f]{40}$ ]]; then
		>&2 echo "This command requires SHA-1 hash as a parameter"
		return 1
	fi
	local CACHE_FILE="$HOME/.miceweb/cache/urls/$1"
	local URL=$(grep "" "$CACHE_FILE" 2>/dev/null)
	if [[ "$URL" != "" ]]; then
		local HASH=$(_hash "$URL")
		if [[ "$1" == "$HASH" ]]; then
			echo "$URL"
			return 0
		fi
	fi
	URL=$(ipfs files read //MiceWeb/pages/$1/URL.txt | sed -n 2p)
	if [[ "$URL" != "" ]]; then
		local HASH=$(_hash "$URL")
		if [[ "$1" == "$HASH" ]]; then
			echo "$URL" > "$CACHE_FILE"
			echo "$URL"
			return 0
		fi
	fi
	return 1
}

# urls ########################################################################

describe "urls" <<HEREDOC
Usage:
  ${_ME} urls [--grep=<expression>] [<local/ipfs/ipns file path>]
  ${_ME} urls --format={txt|json|htm|html} <local/ipfs/ipns file path>

Description:
  List URLs from file (text or json or html) or from the MiceWeb Library
HEREDOC
urls() {
	_upgrade
	local FIL=""
	local PARAM=""
	local GREP=""
	local BASE=""
	local FORMAT=""
	for I in "$@"; do
		if [[ $I == "--grep" ]]; then
			PARAM="grep"
		elif [[ $I == "--base" ]]; then
			PARAM="base"
		elif [[ $I == "--format" ]]; then
			PARAM="format"
		else
			if [[ $PARAM == "grep" ]]; then
				GREP=$I
			elif [[ $PARAM == "base" ]]; then
				BASE=$I
			elif [[ $PARAM == "format" ]]; then
				FORMAT=$I
			else
				FIL=$I
			fi
			PARAM=""
		fi
	done
	if [[ "$FIL" == "" ]]; then
		>&2 echo "This command takes file path as a parameter:"
		>&2 echo " txt - contain URLs in separate lines"
		>&2 echo " json - contain URLs in text fields"
		>&2 echo " htm(l) - contain URLs in the 'href' attribute"
		>&2 echo ""
		local CID="$(ipfs files stat --hash //MiceWeb/pages/ 2>/dev/null)"
		if [[ "$CID" != "" ]]; then
			local CACHE_DIR="$HOME/.miceweb/cache/urls/"
			mkdir -p "$CACHE_DIR"
			if declare -A URLs; then
				>&2 echo "There are URLs already in the MiceWeb Library (see also 'miceweb history'):"
				local HT="$HOME/.miceweb/cache/urls.hashtable"
				if [ -e "$HT" ]; then
					while read line
					do
						local LINE_ARR=($line)
						local LINE_HASH=${LINE_ARR[0]}
						local LINE_URL=${LINE_ARR[1]}
						if [[ $LINE_HASH != "" && $LINE_URL != "" ]]; then
							URLs["$LINE_HASH"]="$LINE_URL"
						fi
					done < "$HT"
				else
					>&2 echo "Warning: it could be slowly, at first"
				fi
				for I in $(ipfs files ls //MiceWeb/pages/ | grep ^[0-9a-f]); do
					local URL="${URLs[$I]}"
					if [[ "$URL" != "" ]]; then
						echo "$URL"
					else
						URL=$(grep "" "$CACHE_DIR$I" 2>/dev/null)
						if [[ "$URL" == "" ]]; then
							URL=$(ipfs cat $CID/$I/URL.txt 2>/dev/null | sed -n 2p)
						fi
						if [[ "$URL" != "" ]]; then
							echo "$URL"
							printf "%s\t%s\n" "$I" "$URL" >> "$HT"
						fi
					fi
				done | grep "$GREP"
			else
				>&2 echo "Warning: installed Bash v.$BASH_VERSION is too old,"
				>&2 _print_with_hyperlink " seeing " "https://stackoverflow.com/questions/6047648" ","
				>&2 echo " consider to install newer Bash (v.4.0+) to significantly increase performance"
				>&2 echo ""
				>&2 echo "There are URLs already in the MiceWeb Library (see also 'miceweb history'):"
				for I in $(ipfs files ls //MiceWeb/pages/ | grep ^[0-9a-f]); do
					local CACHE_FILE="$CACHE_DIR$I"
					local URL=$(grep "" "$CACHE_FILE" 2>/dev/null)
					if [[ "$URL" != "" ]]; then
						echo "$URL"
					else
						URL=$(ipfs cat $CID/$I/URL.txt 2>/dev/null | sed -n 2p)
						if [[ "$URL" != "" ]]; then
							echo "$URL" > "$CACHE_FILE"
							echo "$URL"
						fi
					fi
				done | grep "$GREP"
			fi
		else
			>&2 echo "The MiceWeb Library has no pages"
		fi
		return
	fi
	if [[ "$FORMAT" == "" ]]; then
		FORMAT=$(_path_extension "$FIL")
	fi
	if [[ $FORMAT == htm || $FORMAT == html ]]; then
		type -P htmlq &>/dev/null && ISINST=1 || ISINST=0
		if [ $ISINST -eq 0 ]
		then
			>&2 _print_with_hyperlink "Error: htmlq is not installed (seeing " "https://github.com/mgdm/htmlq/" ")"
			exit 127
		fi
		if [[ "$BASE" != "" ]]; then
			_cat_file "$FIL" | htmlq --base="$BASE" --attribute href a | grep "$GREP" | awk '!a[$0]++; fflush()'
		else
			>&2 echo "Warning: use '--base' attribute to handle relative links"
			_cat_file "$FIL" | htmlq --detect-base --attribute href a | grep "$GREP" | awk '!a[$0]++; fflush()'
		fi
	elif [[ $FORMAT == json ]]; then
		if [[ "$BASE" != "" ]]; then
			>&2 echo "Attribute --base is only supported for html files"
			exit 1
		fi
		for I in $(_cat_json_file "$FIL" | sed -e 's/\.\ /\ /g' | sed -e 's/\,\ /\ /g' | sed -e 's/\;\ /\ /g'); do
			IFS=' ' read -ra IARR <<< "$I"
			for J in "${IARR[@]}"; do
				if _check_url "$J"; then
					echo "${J%.}"
				fi
			done
		done | grep "$GREP" | awk '!a[$0]++; fflush()'
	else
		if [[ "$BASE" != "" ]]; then
			>&2 echo "Attribute --base is only supported for html files"
			exit 1
		fi
		_cat_file "$FIL" "$GREP" | awk '!a[$0]++; fflush()'
	fi
}

# version #####################################################################

describe "version" <<HEREDOC
Usage:
  ${_ME} version

Description:
  Display the current program version

  To save you the trouble, the current version is ${_VERSION}
HEREDOC
version() {
  printf "%s\\n" "${_VERSION}"
}


###############################################################################
# Run Program
###############################################################################

# Call the `_main` function after everything has been defined.
_main
